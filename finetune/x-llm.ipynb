{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xllm in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (0.1.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (23.2)\n",
      "Requirement already satisfied: psutil in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (5.9.1)\n",
      "Requirement already satisfied: torch>=2.0.1 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (2.1.0)\n",
      "Requirement already satisfied: loguru in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (0.7.2)\n",
      "Requirement already satisfied: peft>=0.5.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (0.6.0.dev0)\n",
      "Requirement already satisfied: wandb in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (0.15.12)\n",
      "Requirement already satisfied: python-dotenv in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (1.0.0)\n",
      "Requirement already satisfied: requests in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (2.31.0)\n",
      "Requirement already satisfied: optimum>=1.12.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (1.14.1)\n",
      "Requirement already satisfied: bitsandbytes>=0.41.1 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (0.41.2.post2)\n",
      "Requirement already satisfied: scipy in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (1.11.3)\n",
      "Requirement already satisfied: transformers in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (4.35.0.dev0)\n",
      "Requirement already satisfied: tqdm in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (4.66.1)\n",
      "Requirement already satisfied: safetensors in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from xllm) (0.4.0)\n",
      "Requirement already satisfied: coloredlogs in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from optimum>=1.12.0->xllm) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from optimum>=1.12.0->xllm) (1.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from optimum>=1.12.0->xllm) (0.17.3)\n",
      "Requirement already satisfied: datasets in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from optimum>=1.12.0->xllm) (2.14.5)\n",
      "Requirement already satisfied: pyyaml in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from peft>=0.5.0->xllm) (6.0.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from peft>=0.5.0->xllm) (0.23.0)\n",
      "Requirement already satisfied: filelock in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (4.8.0)\n",
      "Requirement already satisfied: networkx in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=2.0.1->xllm) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.1->xllm) (12.2.140)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from transformers->xllm) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from transformers->xllm) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from requests->xllm) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from requests->xllm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from requests->xllm) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from requests->xllm) (2023.7.22)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from wandb->xllm) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from wandb->xllm) (3.1.40)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from wandb->xllm) (1.32.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from wandb->xllm) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from wandb->xllm) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from wandb->xllm) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from wandb->xllm) (68.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from wandb->xllm) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from wandb->xllm) (4.24.4)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->xllm) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->xllm) (4.0.10)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum>=1.12.0->xllm) (0.1.99)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from coloredlogs->optimum>=1.12.0->xllm) (10.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from datasets->optimum>=1.12.0->xllm) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from datasets->optimum>=1.12.0->xllm) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from datasets->optimum>=1.12.0->xllm) (2.1.1)\n",
      "Requirement already satisfied: xxhash in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from datasets->optimum>=1.12.0->xllm) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from datasets->optimum>=1.12.0->xllm) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from datasets->optimum>=1.12.0->xllm) (3.8.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from jinja2->torch>=2.0.1->xllm) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from sympy->optimum>=1.12.0->xllm) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from aiohttp->datasets->optimum>=1.12.0->xllm) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from aiohttp->datasets->optimum>=1.12.0->xllm) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from aiohttp->datasets->optimum>=1.12.0->xllm) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from aiohttp->datasets->optimum>=1.12.0->xllm) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from aiohttp->datasets->optimum>=1.12.0->xllm) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from aiohttp->datasets->optimum>=1.12.0->xllm) (1.3.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->xllm) (5.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from pandas->datasets->optimum>=1.12.0->xllm) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from pandas->datasets->optimum>=1.12.0->xllm) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages (from pandas->datasets->optimum>=1.12.0->xllm) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade xllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhetarthvader\u001b[0m (\u001b[33mcomplex_dnn\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X—LLM version: 0.1.7\n",
      "Torch version: 2.1.0+cu121\n",
      "Cuda is available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import xllm\n",
    "\n",
    "cuda_is_available = torch.cuda.is_available()\n",
    "\n",
    "print(f\"X—LLM version: {xllm.__version__}\\nTorch version: {torch.__version__}\\nCuda is available: {cuda_is_available}\")\n",
    "assert cuda_is_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xllm import Config\n",
    "from xllm.datasets import GeneralDataset\n",
    "from xllm.experiments import Experiment\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import IterableDataset\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, logging, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model_path\": \"bigcode/starcoderbase-1b\",\n",
    "    \"dataset_name\": \"ArmelR/stack-exchange-instruction\",\n",
    "    \"subset\": \"data/finetune\",\n",
    "    \"split\": \"train\",\n",
    "    \"size_valid_set\": 1000,\n",
    "    \"streaming\": True,\n",
    "    \"shuffle_buffer\": 5000,  # This value is not provided in the command, so the default value is used\n",
    "    \"input_column_name\": \"input\",\n",
    "    \"output_column_name\": \"output\",\n",
    "    \"seq_length\": 1024,\n",
    "    \"max_steps\": 500,\n",
    "    \"batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 8,\n",
    "    \"eos_token_id\": 49152,  # This value is not provided in the command, so the default value is used\n",
    "    \"lora_r\": 16,  # This value is not provided in the command, so the default value is used\n",
    "    \"lora_alpha\": 32,  # This value is not provided in the command, so the default value is used\n",
    "    \"lora_dropout\": 0.05,  # This value is not provided in the command, so the default value is used\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_warmup_steps\": 10,\n",
    "    \"weight_decay\": 0.05,\n",
    "    \"local_rank\": 0,  # This value is not provided in the command, so the default value is used\n",
    "    \"no_fp16\": False,  # This value is not provided in the command, so the default value is used\n",
    "    \"bf16\": True,  # This value is not provided in the command, so the default value is used\n",
    "    \"no_gradient_checkpointing\": False,  # This value is not provided in the command, so the default value is used\n",
    "    \"seed\": 0,  # This value is not provided in the command, so the default value is used\n",
    "    \"num_workers\": None,  # This value is not provided in the command, so the default value is used\n",
    "    \"output_dir\": \"./checkpoints\",  # This value is not provided in the command, so the default value is used\n",
    "    \"log_freq\": 1,  # This value is not provided in the command, so the default value is used\n",
    "    \"eval_freq\": 1000,  # This value is not provided in the command, so the default value is used\n",
    "    \"save_freq\": 1000  # This value is not provided in the command, so the default value is used\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:656: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/bzd2/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages/datasets/load.py:2089: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=True' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def chars_token_ratio(dataset, tokenizer, input_column_name=\"prompt\", output_column_name=\"completion\", nb_examples=400):\n",
    "    \"\"\"\n",
    "    Estimate the average number of characters per token in the dataset.\n",
    "    \"\"\"\n",
    "    total_characters, total_tokens = 0, 0\n",
    "    for _, example in tqdm(zip(range(nb_examples), iter(dataset)), total=nb_examples):\n",
    "        text = prepare_sample_text(example, input_column_name, output_column_name)\n",
    "        total_characters += len(text)\n",
    "        if tokenizer.is_fast:\n",
    "            total_tokens += len(tokenizer(text).tokens())\n",
    "        else:\n",
    "            total_tokens += len(tokenizer.tokenize(text))\n",
    "\n",
    "    return total_characters / total_tokens\n",
    "\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_sample_text(example, input_column_name=\"prompt\", output_column_name=\"completion\"):\n",
    "    \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n",
    "    text = f\"Question: {example[input_column_name]}\\n\\nAnswer: {example[output_column_name]}\"\n",
    "    return text\n",
    "\n",
    "\n",
    "class ConstantLengthDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    Iterable dataset that returns constant length chunks of tokens from stream of text files.\n",
    "        Args:\n",
    "            tokenizer (Tokenizer): The processor used for proccessing the data.\n",
    "            dataset (dataset.Dataset): Dataset with text files.\n",
    "            infinite (bool): If True the iterator is reset after dataset reaches end else stops.\n",
    "            seq_length (int): Length of token sequences to return.\n",
    "            num_of_sequences (int): Number of token sequences to keep in buffer.\n",
    "            chars_per_token (int): Number of characters per token used to estimate number of tokens in text buffer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        dataset,\n",
    "        infinite=False,\n",
    "        seq_length=1024,\n",
    "        num_of_sequences=1024,\n",
    "        chars_per_token=3.6,\n",
    "        input_column_name=\"prompt\",\n",
    "        output_column_name=\"completion\"\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.concat_token_id = tokenizer.eos_token_id if tokenizer.eos_token_id is not None else args.eos_token_id\n",
    "        self.dataset = dataset\n",
    "        self.seq_length = seq_length\n",
    "        self.infinite = infinite\n",
    "        self.current_size = 0\n",
    "        self.max_buffer_size = seq_length * chars_per_token * num_of_sequences\n",
    "        self.input_column_name = input_column_name\n",
    "        self.output_column_name = output_column_name\n",
    "\n",
    "    def __iter__(self):\n",
    "        iterator = iter(self.dataset)\n",
    "        more_examples = True\n",
    "        while more_examples:\n",
    "            buffer, buffer_len = [], 0\n",
    "            while True:\n",
    "                if buffer_len >= self.max_buffer_size:\n",
    "                    break\n",
    "                try:\n",
    "                    buffer.append(prepare_sample_text(next(iterator), self.input_column_name, self.output_column_name))\n",
    "                    buffer_len += len(buffer[-1])\n",
    "                except StopIteration:\n",
    "                    if self.infinite:\n",
    "                        iterator = iter(self.dataset)\n",
    "                    else:\n",
    "                        more_examples = False\n",
    "                        break\n",
    "            tokenized_inputs = self.tokenizer(buffer, truncation=False)[\"input_ids\"]\n",
    "            all_token_ids = []\n",
    "            for tokenized_input in tokenized_inputs:\n",
    "                all_token_ids.extend(tokenized_input + [self.concat_token_id])\n",
    "            for i in range(0, len(all_token_ids), self.seq_length):\n",
    "                input_ids = all_token_ids[i : i + self.seq_length]\n",
    "                if len(input_ids) == self.seq_length:\n",
    "                    self.current_size += 1\n",
    "                    yield {\n",
    "                        \"input_ids\": torch.LongTensor(input_ids),\n",
    "                        \"labels\": torch.LongTensor(input_ids),\n",
    "                    }\n",
    "\n",
    "\n",
    "def create_datasets(tokenizer, config):\n",
    "    dataset = load_dataset('json', data_files='/home/bzd2/ansible-scraping/data/ftdata.json',\n",
    "        # config[\"dataset_name\"],\n",
    "        # data_dir=config[\"subset\"],\n",
    "        # split=config[\"split\"],\n",
    "        use_auth_token=True,\n",
    "        # num_proc=config[\"num_workers\"] if not config[\"streaming\"] else None,\n",
    "        # streaming=config[\"streaming\"],\n",
    "    )\n",
    "    return dataset \n",
    "    # if config[\"streaming\"]:\n",
    "    #     print(\"Loading the dataset in streaming mode\")\n",
    "    #     valid_data = dataset.take(config[\"size_valid_set\"])\n",
    "    #     train_data = dataset.skip(config[\"size_valid_set\"])\n",
    "    #     for i, sample in enumerate(train_data):\n",
    "    #         print(\"<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "    #         print(sample)\n",
    "    #         if i ==10:\n",
    "    #             break\n",
    "\n",
    "    #     train_data = train_data.shuffle(buffer_size=config[\"shuffle_buffer\"], seed=config[\"seed\"])\n",
    "    # else:\n",
    "    #     train_data = dataset[\"train\"]\n",
    "    #     valid_data = dataset[\"test\"]\n",
    "    #     print(f\"Size of the train set: {len(train_data)}. Size of the validation set: {len(valid_data)}\")\n",
    "\n",
    "    # chars_per_token = chars_token_ratio(train_data, tokenizer, config[\"input_column_name\"], config[\"output_column_name\"])\n",
    "    # print(f\"The character to token ratio of the dataset is: {chars_per_token:.2f}\")\n",
    "\n",
    "    # train_dataset = ConstantLengthDataset(\n",
    "    #     tokenizer,\n",
    "    #     train_data,\n",
    "    #     infinite=True,\n",
    "    #     seq_length=config[\"seq_length\"],\n",
    "    #     chars_per_token=chars_per_token,\n",
    "    #     input_column_name=config[\"input_column_name\"],\n",
    "    #     output_column_name=config[\"output_column_name\"]\n",
    "    # )\n",
    "    # valid_dataset = ConstantLengthDataset(\n",
    "    #     tokenizer,\n",
    "    #     valid_data,\n",
    "    #     infinite=False,\n",
    "    #     seq_length=config[\"seq_length\"],\n",
    "    #     chars_per_token=chars_per_token,\n",
    "    #     input_column_name=config[\"input_column_name\"],\n",
    "    #     output_column_name=config[\"output_column_name\"]\n",
    "    # )\n",
    "    # return train_dataset, valid_dataset\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config[\"model_path\"], use_auth_token=True)\n",
    "dataset=create_datasets(tokenizer, config)\n",
    "# train_dataset, eval_dataset = create_datasets(tokenizer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list()\n",
    "\n",
    "for sample in dataset[\"train\"]:\n",
    "    train_data.append({\"text\": sample[\"input\"].strip() + \"\\n \\n \\n\"+sample['output'.strip()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'name: Cleanup health monitor\\n \\n \\na10.acos_axapi.a10_class_list:\\n  name: a10_class_list\\n  state: absent\\n'},\n",
       " {'text': 'name: Create class list for acos\\n \\n \\na10.acos_axapi.a10_class_list:\\n  name: a10_class_list\\n  ntype: ac\\n  ac_list:\\n  - ac_match_type: contains\\n    ac_key_string: apple.com\\n  - ac_match_type: equals\\n    ac_key_string: logmein123.com\\n  - ac_match_type: ends-with\\n    ac_key_string: office.com\\nregister: class_list\\n'},\n",
       " {'text': 'name: Cleanup a10.acos_axapi.a10_delete_bw_list instance\\n \\n \\na10.acos_axapi.a10_delete_bw_list:\\n  file_name: bw_list.txt\\n'},\n",
       " {'text': 'name: Create a10.acos_axapi.a10_file_bw_list instance\\n \\n \\na10.acos_axapi.a10_file_bw_list:\\n  state: present\\n  file: bw_list.txt\\n  file_path: ../ansible/roles/bw_list/tasks/bw_list.txt\\n  file_handle: bw_list.txt\\n  action: import\\n  dst_file: bw_list.txt\\nregister: bw_list\\n'},\n",
       " {'text': 'name: Cleanup router bgp\\n \\n \\na10.acos_axapi.a10_router_bgp:\\n  as_number: 106\\n  state: absent\\n'},\n",
       " {'text': 'name: Create router bgp for acos\\n \\n \\na10.acos_axapi.a10_router_bgp:\\n  as_number: 106\\nregister: bgp\\n'},\n",
       " {'text': 'name: Create router bgp network ip cidr for acos\\n \\n \\na10.acos_axapi.a10_router_bgp_network_ip_cidr:\\n  network_ipv4_cidr: 20.10.10.0/26\\n  bgp_as_number: 106\\nregister: bgp_network_ip_cidr\\n'},\n",
       " {'text': 'name: (CHECK MODE) - Add health monitor\\n \\n \\na10.acos_axapi.a10_health_monitor:\\n  name: hm1\\ncheck_mode: true\\nregister: hm_resp\\n'},\n",
       " {'text': 'name: (CHECK MODE) - Set health monitor method to tcp\\n \\n \\na10.acos_axapi.a10_health_monitor_method_tcp:\\n  monitor_name: hm1\\n  method_tcp: 1\\n  tcp_port: 80\\n  port_send: ping\\n  port_resp:\\n    port_contains: ping\\ncheck_mode: true\\nregister: hm_tcp\\n'},\n",
       " {'text': \"name: Ensure that health monitor doesn't exist\\n \\n \\nblock:\\n- name: NotFound error expected (Health Monitor)\\n  a10.acos_axapi.a10_health_monitor:\\n    name: hm1\\n    state: noop\\n    get_type: single\\n  register: hm_info\\n\"},\n",
       " {'text': 'name: (CHECK MODE) - Test creation of a virtual server w/ vport\\n \\n \\na10.acos_axapi.a10_slb_virtual_server:\\n  ip_address: 10.0.0.4\\n  netmask: 255.255.255.0\\n  name: vs1\\n  port_list:\\n  - port_number: 80\\n    protocol: tcp\\ncheck_mode: true\\n'},\n",
       " {'text': \"name: Ensure that the virtual server doesn't exist\\n \\n \\nblock:\\n- name: NotFound error expected (Virtual Server)\\n  a10.acos_axapi.a10_slb_virtual_server:\\n    name: vs1\\n    state: noop\\n    get_type: single\\n  register: vs_info\\n\"},\n",
       " {'text': \"name: Ensure that the vport doesn't exist\\n \\n \\nblock:\\n- name: NotFound error expected (Virtual Port)\\n  a10.acos_axapi.a10_slb_virtual_server_port:\\n    virtual_server_name: vs1\\n    port_number: 80\\n    protocol: tcp\\n    state: noop\\n    get_type: single\\n  register: vport_info\\n\"},\n",
       " {'text': 'name: Cleanup virtual server\\n \\n \\na10.acos_axapi.a10_slb_virtual_server:\\n  state: absent\\n  ip_address: 10.0.0.4\\n  netmask: 255.255.255.0\\n  name: vs1\\n  port_list:\\n  - port_number: 80\\n    protocol: tcp\\n'},\n",
       " {'text': 'name: Cleanup service group\\n \\n \\na10.acos_axapi.a10_slb_service_group:\\n  state: absent\\n  name: sg1\\n  protocol: tcp\\n  lb_method: weighted-rr\\n'},\n",
       " {'text': 'name: Cleanup server\\n \\n \\na10.acos_axapi.a10_slb_server:\\n  state: absent\\n  name: sv1\\n  host: 10.0.0.1\\n'},\n",
       " {'text': 'name: Cleanup member server\\n \\n \\na10.acos_axapi.a10_slb_service_group_member:\\n  state: absent\\n  service_group_name: sg1\\n  name: sv1\\n  port: 80\\n'},\n",
       " {'text': 'name: Test creation of a virtual server w/ vport\\n \\n \\na10.acos_axapi.a10_slb_virtual_server:\\n  ip_address: 10.0.0.4\\n  netmask: 255.255.255.255\\n  name: vs1\\n  port_list:\\n  - port_number: 80\\n    protocol: tcp\\nregister: virt_resp\\n'},\n",
       " {'text': 'name: Test update of vport on virtual server\\n \\n \\na10.acos_axapi.a10_slb_virtual_server:\\n  ip_address: 10.0.0.4\\n  netmask: 255.255.255.255\\n  name: vs1\\n  port_list:\\n  - port_number: 80\\n    protocol: tcp\\n    action: disable\\nregister: port_resp\\n'},\n",
       " {'text': 'name: Test service group create\\n \\n \\na10.acos_axapi.a10_slb_service_group:\\n  name: sg1\\n  protocol: tcp\\n  lb_method: weighted-rr\\nregister: sg_resp\\n'},\n",
       " {'text': 'name: Test server create\\n \\n \\na10.acos_axapi.a10_slb_server:\\n  name: sv1\\n  host: 10.0.0.1\\nregister: sv_resp\\n'},\n",
       " {'text': 'name: Test association of member server\\n \\n \\na10.acos_axapi.a10_slb_service_group_member:\\n  service_group_name: sg1\\n  name: sv1\\n  port: 80\\nregister: mem_resp\\n'},\n",
       " {'text': 'name: Create DFG for acos\\n \\n \\na10.acos_axapi.a10_ip_route_rib:\\n  ip_dest_addr: 0.0.0.0\\n  ip_mask: /0\\n  ip_nexthop_ipv4:\\n  - ip_next_hop: 192.168.10.2\\nregister: dfg\\n'},\n",
       " {'text': 'name: Cleanup DFG\\n \\n \\na10.acos_axapi.a10_ip_route_rib:\\n  state: absent\\n  ip_dest_addr: 0.0.0.0\\n  ip_mask: /0\\n  ip_nexthop_ipv4:\\n  - ip_next_hop: 192.168.10.2\\n'},\n",
       " {'text': 'name: Cleanup gslb zone\\n \\n \\na10.acos_axapi.a10_gslb_zone:\\n  name: example.com\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup gslb site 2\\n \\n \\na10.acos_axapi.a10_gslb_site:\\n  site_name: INTERNATIONAL\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup gslb site 1\\n \\n \\na10.acos_axapi.a10_gslb_site:\\n  site_name: DOMESTIC\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup gslb service ip 2\\n \\n \\na10.acos_axapi.a10_gslb_service_ip:\\n  node_name: VIP2\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup gslb service ip 1\\n \\n \\na10.acos_axapi.a10_gslb_service_ip:\\n  node_name: VIP1\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup gslb protocol\\n \\n \\na10.acos_axapi.a10_gslb_protocol:\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup gslb policy\\n \\n \\na10.acos_axapi.a10_gslb_policy:\\n  name: mydomain-policy\\n  state: absent\\n'},\n",
       " {'text': 'name: Test gslb policy create\\n \\n \\na10.acos_axapi.a10_gslb_policy:\\n  name: mydomain-policy\\n  dns:\\n    selected_only: true\\n    selected_only_value: 1\\n    server: true\\n    server_authoritative: 1\\nregister: gslb_policy\\n'},\n",
       " {'text': 'name: Test gslb protocol create\\n \\n \\na10.acos_axapi.a10_gslb_protocol:\\n  enable_list:\\n  - ntype: controller\\n  - ntype: device\\nregister: gslb_protocol\\n'},\n",
       " {'text': 'name: Test gslb service ip 1 create\\n \\n \\na10.acos_axapi.a10_gslb_service_ip:\\n  node_name: VIP1\\n  ip_address: 192.168.0.121\\n  port_list:\\n  - port_num: 80\\n    port_proto: tcp\\n  - port_num: 443\\n    port_proto: tcp\\nregister: gslb_service_ip_1\\n'},\n",
       " {'text': 'name: Test gslb service ip 2 create\\n \\n \\na10.acos_axapi.a10_gslb_service_ip:\\n  node_name: VIP2\\n  ip_address: 192.168.0.122\\n  port_list:\\n  - port_num: 80\\n    port_proto: tcp\\n  - port_num: 443\\n    port_proto: tcp\\nregister: gslb_service_ip_2\\n'},\n",
       " {'text': 'name: Test gslb site 1 create\\n \\n \\na10.acos_axapi.a10_gslb_site:\\n  site_name: DOMESTIC\\n  slb_dev_list:\\n  - device_name: A\\n    ip_address: 10.64.3.183\\n    vip_server:\\n      vip_server_name_list:\\n      - vip_name: VIP1\\nregister: gslb_site_1\\n'},\n",
       " {'text': 'name: Test gslb site 2 create\\n \\n \\na10.acos_axapi.a10_gslb_site:\\n  site_name: INTERNATIONAL\\n  slb_dev_list:\\n  - device_name: B\\n    ip_address: 10.64.3.185\\n    vip_server:\\n      vip_server_name_list:\\n      - vip_name: VIP2\\nregister: gslb_site_2\\n'},\n",
       " {'text': 'name: Test gslb zone create\\n \\n \\na10.acos_axapi.a10_gslb_zone:\\n  name: example.com\\n  policy: mydomain-policy\\n  service_list:\\n  - service_port: 80\\n    service_name: www80\\n    dns_a_record:\\n      dns_a_record_srv_list:\\n      - svrname: VIP1\\n        static: 1\\n      - svrname: VIP2\\n        static: 1\\nregister: gslb_zone\\n'},\n",
       " {'text': 'name: Cleanup health monitor\\n \\n \\na10.acos_axapi.a10_health_monitor:\\n  name: hm1\\n  state: absent\\n'},\n",
       " {'text': 'name: Add health monitor\\n \\n \\na10.acos_axapi.a10_health_monitor:\\n  name: hm1\\nregister: hm_resp\\n'},\n",
       " {'text': 'name: Set health monitor method to tcp\\n \\n \\na10.acos_axapi.a10_health_monitor_method_tcp:\\n  monitor_name: hm1\\n  method_tcp: 1\\n  tcp_port: 80\\n  port_send: ping\\n  port_resp:\\n    port_contains: ping\\nregister: hm_tcp\\n'},\n",
       " {'text': 'name: Cleanup slb template client ssl\\n \\n \\na10.acos_axapi.a10_slb_template_client_ssl:\\n  name: my-client-ssl\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup ssl cert\\n \\n \\na10.acos_axapi.a10_file_ssl_cert:\\n  action: import\\n  file: certificate.pem\\n  file_path: certificate.pem\\n  file_handle: certificate.pem\\n  certificate_type: pem\\n  state: absent\\n'},\n",
       " {'text': 'name: Create ssl cert for acos\\n \\n \\na10.acos_axapi.a10_file_ssl_cert:\\n  action: import\\n  file: certificate.pem\\n  file_path: ../ansible/roles/files/tasks/certificate.pem\\n  file_handle: certificate.pem\\n  certificate_type: pem\\nregister: ssl_cert\\n'},\n",
       " {'text': 'name: Create slb template client ssl for acos\\n \\n \\na10.acos_axapi.a10_slb_template_client_ssl:\\n  name: my-client-ssl\\n  chain_cert: certificate.pem\\n  dh_type: 1024\\n  ec_list:\\n  - ec: secp256r1\\n  - ec: secp384r1\\n  version: 33\\n  dgversion: 33\\nregister: template_client_ssl\\n'},\n",
       " {'text': 'name: Create slb template udp for acos\\n \\n \\na10.acos_axapi.a10_slb_template_udp:\\n  name: temp1\\n  idle_timeout: 180\\n  re_select_if_server_down: 1\\nregister: template_udp\\n'},\n",
       " {'text': 'name: Create class list for acos\\n \\n \\na10.acos_axapi.a10_class_list:\\n  name: a10_ipv4_class_list\\n  ipv4_list:\\n  - ipv4addr: 10.1.0.0/16\\n    lid: 1\\nregister: ipv4_class_list\\n'},\n",
       " {'text': 'name: Create ip nat pool for acos\\n \\n \\na10.acos_axapi.a10_ip_nat_pool:\\n  pool_name: dns_nat_pool\\n  start_address: 10.10.10.112\\n  end_address: 10.10.10.112\\n  netmask: /32\\nregister: ip_nat_pool\\n'},\n",
       " {'text': 'name: Create slb template dns for acos\\n \\n \\na10.acos_axapi.a10_slb_template_dns:\\n  name: template-dns\\n  recursive_dns_resolution:\\n    ipv4_nat_pool: dns_nat_pool\\n  drop: 1\\n  class_list:\\n    name: a10_ipv4_class_list\\n    lid_list:\\n    - lidnum: 1\\n    - conn_rate_limit: 1\\n      per: 600\\n    - over_limit_action: 1\\n      action_value: forward\\n      log: 1\\nregister: template_dns\\n'},\n",
       " {'text': 'name: Cleanup template cipher\\n \\n \\na10.acos_axapi.a10_slb_template_cipher:\\n  name: template-cipher\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup slb template dns\\n \\n \\na10.acos_axapi.a10_slb_template_dns:\\n  name: template-dns\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup ip nat pool\\n \\n \\na10.acos_axapi.a10_ip_nat_pool:\\n  pool_name: dns_nat_pool\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup class list\\n \\n \\na10.acos_axapi.a10_class_list:\\n  name: a10_ipv4_class_list\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup slb template http\\n \\n \\na10.acos_axapi.a10_slb_template_http:\\n  name: template-http\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup slb template tcp\\n \\n \\na10.acos_axapi.a10_slb_template_tcp:\\n  name: tcp1\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup slb template udp\\n \\n \\na10.acos_axapi.a10_slb_template_udp:\\n  name: temp1\\n  state: absent\\n'},\n",
       " {'text': 'name: Cleanup slb template server ssl\\n \\n \\na10.acos_axapi.a10_slb_template_server_ssl:\\n  name: template-server-ssl\\n  state: absent\\n'},\n",
       " {'text': 'name: Create slb template cipher for acos\\n \\n \\na10.acos_axapi.a10_slb_template_cipher:\\n  name: template-cipher\\n  cipher_cfg:\\n  - cipher_suite: TLS1_RSA_AES_128_SHA\\n  - cipher_suite: TLS1_RSA_AES_256_SHA\\n  user_tag: Security,ssli_in\\nregister: template_cipher\\n'},\n",
       " {'text': 'name: Create slb template server ssl for acos\\n \\n \\na10.acos_axapi.a10_slb_template_server_ssl:\\n  name: template-server-ssl\\n  dh_type: 1024\\n  ec_list:\\n  - ec: secp256r1\\n  - ec: secp384r1\\n  version: 33\\n  dgversion: 33\\n  cipher_template: template-cipher\\n  user_tag: Security,ssli_out\\n  enable_tls_alert_logging: 1\\n  alert_type: fatal\\nregister: template_server_ssl\\n'},\n",
       " {'text': 'name: Create slb template http for acos\\n \\n \\na10.acos_axapi.a10_slb_template_http:\\n  name: template-http\\n  request_header_insert_list:\\n  - request_header_insert: X-Protocol-Port:https 443\\n  - request-header-insert: TrackSSL:ON\\n  response_header_insert_list:\\n  - response-header-insert: alt-svc:h3 443\\n  keep_client_alive: 1\\n  compression_content_type:\\n  - content_type: image/jpeg\\n  - content_type: video/mp4\\n  - content_type: audio/mp3\\n  compression_enable: 1\\n  compression_level: 8\\n  compression_keep_accept_encoding: 1\\n  compression_keep_accept_encoding_enable: 1\\nregister: template_http\\n'},\n",
       " {'text': 'name: Create slb template tcp for acos\\n \\n \\na10.acos_axapi.a10_slb_template_tcp:\\n  name: tcp1\\n  force_delete_timeout: 10\\n  del_session_on_server_down: 1\\n  re_select_if_server_down: 1\\n  reset_fwd: 1\\n  reset_rev: 1\\n  idle_timeout: 60\\n  half_close_idle_timeout: 100\\n  initial_window_size: 65535\\nregister: template_tcp\\n'},\n",
       " {'text': 'name: Cleanup vlan\\n \\n \\na10.acos_axapi.a10_network_vlan:\\n  vlan_num: 2\\n  state: absent\\n'},\n",
       " {'text': 'name: Create a10_network_vlan instance\\n \\n \\na10.acos_axapi.a10_network_vlan:\\n  vlan_num: 2\\nregister: net_vlan\\n'},\n",
       " {'text': \"name: create containers dir if doesn't exist\\n \\n \\nfile:\\n  state: directory\\n  path: '{{ containers_path }}'\\n\"},\n",
       " {'text': \"name: add containers conf files\\n \\n \\ntemplate:\\n  src: '{{ item }}.j2'\\n  dest: '{{ containers_path }}/{{ item }}'\\nloop: '{{ containers_configs }}'\\n\"},\n",
       " {'text': 'name: install buildah\\n \\n \\ninclude_tasks: install.yml\\n'},\n",
       " {'text': 'name: configure buildah\\n \\n \\ninclude_tasks: configure.yml\\n'},\n",
       " {'text': \"name: install from source\\n \\n \\ninclude_tasks: installs/src/{{ item }}\\nloop:\\n- '{{ ansible_os_family }}.yml'\\n- source.yml\\nwhen:\\n- install_source is defined\\n- install_source\\n\"},\n",
       " {'text': \"name: install from package manager\\n \\n \\ninclude_tasks: installs/pkg/{{ 'Debian' if 'Pop' in ansible_os_family else ansible_os_family\\n  }}.yml\\nwhen:\\n- (install_source is undefined) or not install_source\\n\"},\n",
       " {'text': 'name: add ppa dependencies\\n \\n \\napt:\\n  state: present\\n  name:\\n  - software-properties-common\\n  - uidmap\\n'},\n",
       " {'text': 'name: add kubic lib container packages\\n \\n \\napt_repository:\\n  state: present\\n  repo: deb http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_{{\\n    ansible_distribution_version }}/ /\\n  filename: kubic\\n'},\n",
       " {'text': 'name: remove docker-ce if installed\\n \\n \\napt:\\n  state: absent\\n  name:\\n  - docker-ce\\n  - containerd.io\\n  - runc\\n'},\n",
       " {'text': 'name: install dependencies\\n \\n \\napt:\\n  update_cache: true\\n  state: present\\n  name:\\n  - gpg\\n'},\n",
       " {'text': \"name: set version of containers repo\\n \\n \\nset_fact:\\n  buildah_distribution: '{{ ''Debian'' if ansible_distribution == ''Debian'' else\\n    ''xUbuntu'' }}'\\n\"},\n",
       " {'text': 'name: install apt key\\n \\n \\napt_key:\\n  url: https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/{{\\n    buildah_distribution }}_{{ ansible_distribution_version }}/Release.key\\n  state: present\\n'},\n",
       " {'text': 'name: install container repository\\n \\n \\napt_repository:\\n  repo: deb http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/{{\\n    buildah_distribution }}_{{ ansible_distribution_version }}/ /\\n  filename: devel:kubic:libcontainers:stable\\n  state: present\\n  update_cache: true\\n'},\n",
       " {'text': 'name: install buildah and podman tools\\n \\n \\napt:\\n  update_cache: true\\n  state: present\\n  name:\\n  - buildah\\n  - podman\\n  - skopeo\\n  - containernetworking-plugins\\n'},\n",
       " {'text': 'name: install buildah and podman tools\\n \\n \\nzypper:\\n  state: present\\n  name:\\n  - buildah\\n  - podman\\n  - skopeo\\n'},\n",
       " {'text': 'name: install buildah and podman tools\\n \\n \\npackage:\\n  state: present\\n  name:\\n  - buildah\\n  - skopeo\\n  - podman\\n'},\n",
       " {'text': \"name: add ppa\\n \\n \\ninclude_tasks: '{{ role_path }}/tasks/installs/ppa.yml'\\n\"},\n",
       " {'text': 'name: install dependencies\\n \\n \\napt:\\n  state: present\\n  name:\\n  - bats\\n  - btrfs-tools\\n  - git\\n  - libapparmor-dev\\n  - libdevmapper-dev\\n  - libglib2.0-dev\\n  - libgpgme11-dev\\n  - libostree-dev\\n  - libseccomp-dev\\n  - libselinux1-dev\\n  - skopeo-containers\\n  - go-md2man\\n  - golang-1.10\\n'},\n",
       " {'text': 'name: install dependencies\\n \\n \\nzypper:\\n  state: present\\n  name:\\n  - go\\n  - git\\n  - golang\\n  - runc\\n  - bzip2\\n  - libgpgme-devel\\n  - libseccomp-devel\\n  - device-mapper-devel\\n  - libbtrfs-devel\\n  - go-md2man\\n'},\n",
       " {'text': 'name: install go from snap\\n \\n \\nsnap:\\n  name: go\\n  classic: true\\n  state: present\\n'},\n",
       " {'text': \"name: create GOPATH dir if doesn't exist\\n \\n \\nfile:\\n  path: '{{ go_path }}'\\n  state: directory\\n\"},\n",
       " {'text': \"name: clone buildah\\n \\n \\ngit:\\n  dest: '{{ buildah_src_path }}'\\n  repo: https://github.com/containers/buildah\\n\"},\n",
       " {'text': 'name: make buildah\\n \\n \\nmake:\\n  chdir: \\'{{ buildah_src_path }}\\'\\nwhen: ansible_os_family != \"Debian\"\\n'},\n",
       " {'text': 'name: make buildah\\n \\n \\nmake:\\n  chdir: \\'{{ buildah_src_path }}\\'\\n  params:\\n    PATH: /usr/lib/go-1.10/bin:$PATH\\n    SECURITYTAGS: apparmor seccomp\\nwhen: ansible_os_family == \"Debian\"\\n'},\n",
       " {'text': \"name: install buildah\\n \\n \\nmake:\\n  chdir: '{{ buildah_src_path }}'\\n  target: install\\n\"},\n",
       " {'text': 'name: install fedora dependencies\\n \\n \\ndnf:\\n  state: present\\n  name:\\n  - make\\n  - golang\\n  - bats\\n  - btrfs-progs-devel\\n  - device-mapper-devel\\n  - glib2-devel\\n  - gpgme-devel\\n  - libassuan-devel\\n  - libseccomp-devel\\n  - ostree-devel\\n  - git\\n  - bzip2\\n  - go-md2man\\n  - runc\\n  - containers-common\\nwhen: ansible_distribution == \"Fedora\"\\n'},\n",
       " {'text': 'name: install rhel dependencies\\n \\n \\nyum:\\n  state: present\\n  name:\\n  - make\\n  - golang\\n  - bats\\n  - btrfs-progs-devel\\n  - device-mapper-devel\\n  - glib2-devel\\n  - gpgme-devel\\n  - libassuan-devel\\n  - libseccomp-devel\\n  - ostree-devel\\n  - git\\n  - bzip2\\n  - go-md2man\\n  - runc\\n  - skopeo-containers\\nwhen: ansible_distribution != \"Fedora\"\\n'},\n",
       " {'text': 'name: Set firewalld rules for docker\\n \\n \\ninclude_tasks: firewalld.yml\\nwhen:\\n- using_firewalld is defined\\n- using_firewalld\\n'},\n",
       " {'text': \"name: configure docker\\n \\n \\ncopy:\\n  content: '{{ docker_config_content | to_nice_json }}'\\n  dest: '{{ docker_config_file }}'\\n\"},\n",
       " {'text': 'name: restart snap docker\\n \\n \\ncommand: snap restart docker\\nwhen: ansible_distribution in [\"Ubuntu\", \"Pop!_OS\"]\\n'},\n",
       " {'text': 'name: restart docker\\n \\n \\nservice:\\n  state: restarted\\n  name: docker\\nwhen: (not ansible_distribution in [\"Ubuntu\", \"Pop!_OS\"])\\n'},\n",
       " {'text': 'name: Install docker and dependencies\\n \\n \\ninclude_tasks: os_family/{{ ansible_os_family }}.yml\\n'},\n",
       " {'text': 'name: Configure docker\\n \\n \\ninclude_tasks: configuration.yml\\n'},\n",
       " {'text': \"name: set new zone for docker\\n \\n \\nfirewalld:\\n  state: present\\n  permanent: true\\n  zone: '{{ docker_zone }}'\\n\"},\n",
       " {'text': 'name: set network bridge\\n \\n \\ncommand: \\'{% raw %}\\n\\n  docker network inspect -f \"{{range .IPAM.Config }}{{ .Subnet }}{{end}}\" bridge\\n\\n  {% endraw %}\\n\\n  \\'\\nregister: docker_network\\n'},\n",
       " {'text': \"name: set source for docker zone\\n \\n \\nfirewalld:\\n  state: enabled\\n  permanent: true\\n  zone: '{{ docker_zone }}'\\n  source: '{{ docker_network.stdout }}'\\n\"},\n",
       " {'text': \"name: set firewall rules for default docker network\\n \\n \\nfirewalld:\\n  state: enabled\\n  permanent: true\\n  zone: '{{ docker_zone }}'\\n  interface: docker0\\n\"},\n",
       " {'text': \"name: set firewall rules for docker port\\n \\n \\nfirewalld:\\n  state: enabled\\n  permanent: true\\n  zone: '{{ docker_zone }}'\\n  port: '{{ item }}'\\nloop:\\n- 8443/tcp\\n- 53/udp\\n- 8053/udp\\n\"},\n",
       " {'text': 'name: make sure docker from distro is not installed\\n \\n \\nyum:\\n  state: absent\\n  name:\\n  - docker\\n  - docker-common\\n  - container-selinux\\n  - docker-selinux\\n  - docker-engine\\n'},\n",
       " {'text': \"name: append Docker EE url\\n \\n \\nshell: echo {{ item }}\\nwith_items:\\n- '{{ ee.url }} > /etc/yum/vars/dockerurl'\\n- '{{ ee.version }} > /etc/yum/vars/dockerosversion'\\n\"},\n",
       " {'text': 'name: install yum-utils\\n \\n \\nyum:\\n  name: yum-utils\\n  state: present\\n'},\n",
       " {'text': 'name: install docker repository\\n \\n \\ncommand: yum-config-manager --add-repo \"{{ ee.url }}/docker-ee.repo\"\\n'},\n",
       " {'text': 'name: Install docker\\n \\n \\nyum:\\n  state: present\\n  name:\\n  - docker-ce\\n  - python3-docker\\n'},\n",
       " {'text': 'name: making sure pip installed\\n \\n \\nshell: curl -sSL https://bootstrap.pypa.io/get-pip.py | python\\n'},\n",
       " {'text': 'name: install yum-utils\\n \\n \\nyum:\\n  state: present\\n  name: yum-utils\\n'},\n",
       " {'text': 'name: install docker repository\\n \\n \\ncommand: yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\\n'},\n",
       " {'text': 'name: make sure docker from distro is not installed\\n \\n \\nyum:\\n  state: absent\\n  name:\\n  - docker\\n  - docker-common\\n  - container-selinux\\n  - docker-selinux\\n  - docker-engine\\n'},\n",
       " {'text': 'name: Install docker\\n \\n \\nyum:\\n  state: latest\\n  name:\\n  - docker-ce\\n'},\n",
       " {'text': 'name: making sure pip installed\\n \\n \\nshell: curl -sSL https://bootstrap.pypa.io/get-pip.py | python\\n'},\n",
       " {'text': 'name: remove old docker\\n \\n \\napt:\\n  state: absent\\n  name:\\n  - docker-ce\\n'},\n",
       " {'text': 'name: extra packages for Ubuntu\\n \\n \\napt:\\n  state: present\\n  name:\\n  - snapd\\n  - python3-docker\\n'},\n",
       " {'text': 'name: install docker\\n \\n \\ncommunity.general.snap:\\n  name: docker\\n  state: present\\nignore_errors: true\\n'},\n",
       " {'text': 'name: create docker group if not already available\\n \\n \\ngroup:\\n  system: true\\n  state: present\\n  name: docker\\n'},\n",
       " {'text': 'name: install the required\\n \\n \\napk:\\n  state: present\\n  name:\\n  - docker\\n  - py3-pip\\n'},\n",
       " {'text': 'name: install python things\\n \\n \\npip:\\n  state: present\\n  name:\\n  - docker\\n'},\n",
       " {'text': 'name: remove old docker\\n \\n \\napt:\\n  state: absent\\n  name:\\n  - docker\\n  - docker-engine\\n  - docker.io\\n'},\n",
       " {'text': \"name: install debian dependencies\\n \\n \\ninclude_tasks: Ubuntu.yml\\nwhen: ansible_distribution == 'Ubuntu' or ansible_distribution == 'Pop!_OS'\\n\"},\n",
       " {'text': \"name: install debian dependencies\\n \\n \\ninclude_tasks: Deb.yml\\nwhen:\\n- ansible_distribution != 'Ubuntu'\\n- ansible_distribution != 'Pop!_OS'\\n\"},\n",
       " {'text': 'name: Install docker\\n \\n \\nzypper:\\n  state: present\\n  name:\\n  - docker\\n  - python3-docker\\n'},\n",
       " {'text': 'name: install the required\\n \\n \\npacman:\\n  state: present\\n  name:\\n  - docker\\n  - python-docker-py\\n'},\n",
       " {'text': 'name: make sure dnf-plugins.core installed\\n \\n \\ndnf:\\n  name: dnf-plugins-core\\n  state: present\\n'},\n",
       " {'text': 'name: install docker repository\\n \\n \\ncommand: dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo\\n'},\n",
       " {'text': 'name: make sure docker from distro is not installed\\n \\n \\nyum:\\n  state: absent\\n  name:\\n  - docker\\n  - docker-common\\n  - container-selinux\\n  - docker-selinux\\n  - docker-engine\\n'},\n",
       " {'text': 'name: install docker\\n \\n \\ndnf:\\n  state: present\\n  name:\\n  - docker-ce\\n  - python3-docker\\n'},\n",
       " {'text': 'name: Run the Fedora based install\\n \\n \\ninclude: Fedora.yml\\nwhen: ansible_distribution == \"Fedora\"\\n'},\n",
       " {'text': 'name: Run the Centos based install\\n \\n \\ninclude: CentOS.yml\\nwhen: ansible_distribution != \"CentOS\"\\n'},\n",
       " {'text': 'name: Install dependencies\\n \\n \\napt:\\n  name:\\n  - python3\\n  - curl\\n  - apt-transport-https\\n  - ca-certificates\\n  - gnupg2\\n  - software-properties-common\\n  state: present\\n'},\n",
       " {'text': 'name: add key id\\n \\n \\napt_key:\\n  url: https://download.docker.com/linux/{{ ansible_distribution | lower }}/gpg\\n  state: present\\n'},\n",
       " {'text': 'name: add docker repository\\n \\n \\napt_repository:\\n  repo: deb [arch=amd64] https://download.docker.com/linux/{{ ansible_distribution\\n    | lower }} {{ ansible_distribution_release | lower }} stable\\n  filename: docker\\n  state: present\\n'},\n",
       " {'text': 'name: install docker\\n \\n \\napt:\\n  name: docker-ce\\n  update_cache: true\\n  state: present\\n'},\n",
       " {'text': 'name: install pip\\n \\n \\nshell: curl -sSL https://bootstrap.pypa.io/get-pip.py | python3\\n'},\n",
       " {'text': \"name: make configured data_dir\\n \\n \\nfile:\\n  dest: '{{ item }}'\\n  state: directory\\n  recurse: true\\n  owner: '{{ nomad_user }}'\\n  group: '{{ nomad_group }}'\\nloop:\\n- '{{ nomad_config_path }}'\\n- '{{ nomad_node_path }}'\\n- '{{ nomad_plugin_path }}'\\n- '{{ nomad_alloc_path }}'\\n- '{{ nomad_server_path }}'\\n- '{{ nomad_client_path }}'\\n- '{{ nomad_job_path }}'\\n\"},\n",
       " {'text': \"name: make sure path exist\\n \\n \\nfile:\\n  dest: '{{ systemd_unit_path }}'\\n  state: directory\\n  recurse: true\\n\"},\n",
       " {'text': \"name: add most node.d settings generated\\n \\n \\ncopy:\\n  content: '{{ item.content | to_json }}'\\n  dest: '{{ nomad_node_path }}/{{ item.name }}.json'\\n  owner: '{{ nomad_user }}'\\n  group: '{{ nomad_group }}'\\nloop: '{{ nomad_node_settings }}'\\nwhen:\\n- item.node_type is undefined\\n- not 'acl' in item.name\\n\"},\n",
       " {'text': \"name: add node.d settings generated\\n \\n \\ncopy:\\n  content: '{{ item.content | to_json }}'\\n  dest: '{{ nomad_node_path }}/{{ item.name }}.json'\\n  owner: '{{ nomad_user }}'\\n  group: '{{ nomad_group }}'\\nwhen:\\n- item.node_type is defined\\n- item.node_type == node_type\\nloop: '{{ nomad_node_settings }}'\\n\"},\n",
       " {'text': \"name: gather mhz info\\n \\n \\ncpu_mhz_info:\\n  fmt: max\\nregister: mhz_info\\nwhen: node_type == 'client'\\n\"},\n",
       " {'text': \"name: set reserved limits for client node\\n \\n \\ncopy:\\n  content: '{{ content | to_json }}'\\n  dest: '{{ nomad_node_path }}/50-reserved.json'\\n  owner: '{{ nomad_user }}'\\n  group: '{{ nomad_group }}'\\n  mode: 416\\nvars:\\n  content:\\n    client:\\n      enabled: true\\n      reserved:\\n        cpu: '{{ (mhz_info.maximum | int * 0.10) | int }}'\\n        memory: '{{ (ansible_memtotal_mb | int * 0.10) | int }}'\\n        reserved_ports: '{{ nomad_reserved_ports | join('','') }}'\\nwhen: node_type == 'client'\\n\"},\n",
       " {'text': \"name: add nomad service\\n \\n \\ntemplate:\\n  src: nomad.service.j2\\n  dest: '{{ systemd_unit_path }}/nomad.service'\\nnotify:\\n- enable nomad\\n\"},\n",
       " {'text': \"name: add most node.d settings generated\\n \\n \\ncopy:\\n  content: '{{ item.content | to_json }}'\\n  dest: '{{ nomad_node_path }}/{{ item.name }}.json'\\n  owner: '{{ nomad_user }}'\\n  group: '{{ nomad_group }}'\\nloop: '{{ nomad_node_settings }}'\\nwhen:\\n- item.node_type is undefined\\n- ('acl' in item.name)\\n\"},\n",
       " {'text': 'name: install dependencies\\n \\n \\npackage:\\n  state: present\\n  name:\\n  - unzip\\n'},\n",
       " {'text': \"name: get platform\\n \\n \\nset_fact:\\n  nomad_arch: '{{ ansible_architecture | abaez.hashicluster.to_go_arch }}'\\n\"},\n",
       " {'text': 'name: extract and install nomad\\n \\n \\nunarchive:\\n  src: https://releases.hashicorp.com/nomad/{{ nomad_version }}/nomad_{{ nomad_version\\n    }}_linux_{{ nomad_arch }}.zip\\n  dest: /tmp/\\n  remote_src: true\\n'},\n",
       " {'text': \"name: copy nomad version to bin path\\n \\n \\ncopy:\\n  remote_src: true\\n  src: /tmp/nomad\\n  dest: '{{ nomad_bin_path }}/nomad-{{ nomad_version }}'\\n  mode: 493\\n\"},\n",
       " {'text': \"name: set nomad version to use\\n \\n \\nalternatives:\\n  name: nomad\\n  path: '{{ nomad_bin_path }}/nomad-{{ nomad_version }}'\\n  link: '{{ nomad_bin_path }}/nomad'\\n  priority: 1\\n\"},\n",
       " {'text': \"name: create nomad group\\n \\n \\ngroup:\\n  name: '{{ nomad_group }}'\\n  gid: '{{ nomad_group_id | default(8500) }}'\\n  state: present\\n\"},\n",
       " {'text': \"name: create nomad user\\n \\n \\nuser:\\n  name: '{{ nomad_user }}'\\n  group: '{{ nomad_group }}'\\n  home: '{{ nomad_config_path }}'\\n  system: true\\n  shell: /bin/false\\n  uid: '{{ nomad_user_id | default(4646) }}'\\n  state: present\\nwhen: nomad_user != 'root'\\n\"},\n",
       " {'text': 'name: install nomad\\n \\n \\ninclude_tasks: install.yml\\n'},\n",
       " {'text': 'name: configure nomad\\n \\n \\nimport_tasks: configuration.yml\\n'},\n",
       " {'text': 'name: secure nomad\\n \\n \\nimport_tasks: security.yml\\nwhen: use_acl\\n'},\n",
       " {'text': \"name: import acl variables\\n \\n \\ninclude_vars: '{{ consul_vars_acl_settings }}'\\n\"},\n",
       " {'text': 'name: secure consul\\n \\n \\nimport_tasks: security.yml\\n'},\n",
       " {'text': \"name: include policies\\n \\n \\ninclude_vars: '{{ consul_vars_acl_policies }}'\\n\"},\n",
       " {'text': \"name: set up default policy fact\\n \\n \\nset_fact:\\n  consul_acl_policy_default: '{{ consul_acl_policies | selectattr(''name'', ''contains'',\\n    ''default-policy'') | first  }}'\\n\"},\n",
       " {'text': \"name: add specific node acl settings generated\\n \\n \\ncopy:\\n  content: '{{ item.content | to_json }}'\\n  dest: '{{ consul_acl_path }}/{{ item.name }}.json'\\n  owner: '{{ consul_user }}'\\n  group: '{{ consul_group }}'\\nwhen:\\n- item.node_type is defined\\n- item.node_type == node_type\\nloop: '{{ consul_acl_settings }}'\\n\"},\n",
       " {'text': 'name: started consul\\n \\n \\nservice:\\n  state: started\\n  name: consul\\nwhen: ansible_user_id != consul_user\\n'},\n",
       " {'text': \"name: wait for acl bootstrap\\n \\n \\nwait_for:\\n  path: '{{ consul_http_addr | replace(''unix://'', '''') }}'\\n  delay: 60\\n\"},\n",
       " {'text': \"name: create policies from rules\\n \\n \\nconsul_acl_policy:\\n  management_token: '{{ consul_acl_master_token }}'\\n  address: '{{ consul_api_address }}'\\n  state: present\\n  rules: '{% if item.hcl is defined and item.hcl %}{{ item.rules }}{% else %}{{ item.rules\\n    | to_json }}{% endif %}'\\n  description: '{{ item.description }}'\\n  name: '{{ item.name }}'\\nloop: '{{ consul_acl_policies }}'\\n\"},\n",
       " {'text': \"name: create server agent role\\n \\n \\nconsul_acl_role:\\n  management_token: '{{ consul_acl_master_token }}'\\n  address: '{{ consul_api_address }}'\\n  state: present\\n  name: '{{ consul_node_name }}'\\n  description: Grants write access to {{ node_type }} agent {{ consul_node_name }}\\n  policies: '{{ consul_acl_policies | map(attribute=''name'') | abaez.hashicluster.key_hash_list\\n    }}'\\nregister: response_acl_role_agent_server\\nwhen: node_type == 'server'\\n\"},\n",
       " {'text': \"name: create client agent role\\n \\n \\nconsul_acl_role:\\n  management_token: '{{ consul_acl_master_token }}'\\n  address: '{{ consul_api_address }}'\\n  state: present\\n  name: '{{ consul_node_name }}'\\n  description: Grants write access to {{ node_type }} agent {{ consul_node_name }}\\n  policies:\\n  - Name: '{{ consul_acl_policy_default.name }}'\\n  - Name: agent-policy-client-{{ consul_node_name }}\\nregister: response_acl_role_agent_client\\nwhen: node_type == 'client'\\n\"},\n",
       " {'text': \"name: create default token\\n \\n \\nconsul_acl_token:\\n  management_token: '{{ consul_acl_master_token }}'\\n  address: '{{ consul_api_address }}'\\n  state: present\\n  description: '{{ consul_acl_policy_default.description }}'\\n  secret_id: '{{ consul_acl_default_token }}'\\n  accessor_id: '{{ consul_acl_policy_default.name | to_uuid }}'\\n  policies:\\n  - Name: '{{ consul_acl_policy_default.name }}'\\nregister: response_acl_token_default\\nwhen: node_type == 'server'\\n\"},\n",
       " {'text': \"name: create token for agent\\n \\n \\nconsul_acl_token:\\n  management_token: '{{ consul_acl_master_token }}'\\n  address: '{{ consul_api_address }}'\\n  state: present\\n  description: '{{ node_type | title }} token for node {{ consul_node_name }}\\n\\n    '\\n  secret_id: '{{ consul_acl_agent_token }}'\\n  accessor_id: '{{ consul_node_name | to_uuid }}'\\n  roles:\\n  - Name: '{{ consul_node_name }}'\\nregister: response_acl_token_agent\\n\"},\n",
       " {'text': 'name: add acl token to environment of node\\n \\n \\nlineinfile:\\n  create: true\\n  path: /etc/environment\\n  state: present\\n  regexp: ^CONSUL_HTTP_TOKEN\\n  line: CONSUL_HTTP_TOKEN={{ consul_acl_agent_token }}\\nwhen: ansible_user_id != consul_user\\n'},\n",
       " {'text': 'name: install dependencies\\n \\n \\npackage:\\n  state: present\\n  name:\\n  - unzip\\n  - python3-pip\\n'},\n",
       " {'text': \"name: install pip dependencies\\n \\n \\npip:\\n  executable: pip3\\n  state: present\\n  name: '{{ consul_pip_requirements }}'\\n\"},\n",
       " {'text': \"name: get platform\\n \\n \\nset_fact:\\n  consul_arch: '{{ ansible_architecture | abaez.hashicluster.to_go_arch }}'\\n\"},\n",
       " {'text': 'name: extract and install consul\\n \\n \\nunarchive:\\n  src: https://releases.hashicorp.com/consul/{{ consul_version }}/consul_{{ consul_version\\n    }}_linux_{{ consul_arch }}.zip\\n  dest: /tmp/\\n  remote_src: true\\n'},\n",
       " {'text': \"name: copy consul version to bin path\\n \\n \\ncopy:\\n  remote_src: true\\n  src: /tmp/consul\\n  dest: '{{ consul_bin_path }}/consul-{{ consul_version }}'\\n  mode: 493\\n\"},\n",
       " {'text': \"name: set consul version to use\\n \\n \\nalternatives:\\n  name: consul\\n  path: '{{ consul_bin_path }}/consul-{{ consul_version }}'\\n  link: '{{ consul_bin_path }}/consul'\\n  priority: 100\\n\"},\n",
       " {'text': \"name: create consul group\\n \\n \\ngroup:\\n  name: '{{ consul_group }}'\\n  gid: '{{ consul_group_id | default(8500) }}'\\n  state: present\\n\"},\n",
       " {'text': \"name: create consul user\\n \\n \\nuser:\\n  name: '{{ consul_user }}'\\n  group: '{{ consul_group }}'\\n  home: '{{ consul_config_path }}'\\n  system: true\\n  shell: /bin/false\\n  uid: '{{ consul_user_id | default(8500) }}'\\n  state: present\\n\"},\n",
       " {'text': \"name: make configured data_dir\\n \\n \\nfile:\\n  dest: '{{ item }}'\\n  state: directory\\n  recurse: true\\n  owner: '{{ consul_user }}'\\n  group: '{{ consul_group }}'\\nloop:\\n- '{{ consul_config_path }}'\\n- '{{ consul_run_path }}'\\n- '{{ consul_node_path }}'\\n- '{{ consul_service_path }}'\\n- '{{ consul_data_path }}'\\n- '{{ consul_acl_path }}'\\n\"},\n",
       " {'text': 'name: set /var/run tmpfiles generation\\n \\n \\ntemplate:\\n  src: consul.conf.j2\\n  dest: /usr/lib/tmpfiles.d/consul.conf\\n'},\n",
       " {'text': \"name: make systemd directory if not already\\n \\n \\nfile:\\n  dest: '{{ item }}'\\n  state: directory\\n  recurse: true\\nloop:\\n- '{{ systemd_unit_path }}'\\n- '{{ systemd_resolved_path }}'\\n- '{{ systemd_consul_path }}'\\n\"},\n",
       " {'text': \"name: set consul environment variables\\n \\n \\nblockinfile:\\n  create: true\\n  state: present\\n  path: /etc/environment\\n  block: 'CONSUL_HTTP_ADDR={{ consul_http_addr }}\\n\\n    CONSUL_HTTPS_ADDR={{ consul_https_addr }}\\n\\n    CONSUL_GRPC_ADDR={{ consul_grpc_addr }}\\n\\n    '\\nwhen: (not consul_connect_enabled)\\n\"},\n",
       " {'text': \"name: apply systemd-resolved for consul\\n \\n \\ntemplate:\\n  src: resolved.conf.j2\\n  dest: '{{ systemd_resolved_path }}/10-consul.conf'\\n  owner: '{{ consul_user }}'\\n\"},\n",
       " {'text': \"name: apply systemd service file\\n \\n \\ntemplate:\\n  src: consul.service.j2\\n  dest: '{{ systemd_unit_path }}/consul.service'\\nnotify: enable consul\\n\"},\n",
       " {'text': 'name: install consul\\n \\n \\ninclude_tasks: install.yml\\n'},\n",
       " {'text': 'name: configure consul\\n \\n \\ninclude_tasks: configure.yml\\n'},\n",
       " {'text': \"name: include vars for provision or runtime settings\\n \\n \\ninclude_vars: '{{ consul_vars_settings }}'\\n\"},\n",
       " {'text': 'name: provision tasks\\n \\n \\ninclude_tasks: provision.yml\\nwhen: (not is_runtime)\\n'},\n",
       " {'text': 'name: generate provision settings\\n \\n \\ninclude_tasks: generate.yml\\n'},\n",
       " {'text': 'name: runtime tasks\\n \\n \\ninclude_tasks: runtime.yml\\nwhen: is_runtime\\n'},\n",
       " {'text': \"name: add most node.d settings generated\\n \\n \\ncopy:\\n  content: '{{ item.content | to_json }}'\\n  dest: '{{ consul_node_path }}/{{ item.name }}.json'\\n  owner: '{{ consul_user }}'\\n  group: '{{ consul_group }}'\\nwhen: item.node_type is undefined\\nloop: '{{ consul_node_settings }}'\\n\"},\n",
       " {'text': \"name: add client/server node.d settings generated\\n \\n \\ncopy:\\n  content: '{{ item.content | to_json }}'\\n  dest: '{{ consul_node_path }}/{{ item.name }}.json'\\n  owner: '{{ consul_user }}'\\n  group: '{{ consul_group }}'\\nwhen:\\n- item.node_type is defined\\n- node_type == item.node_type\\nloop: '{{ consul_node_settings }}'\\n\"},\n",
       " {'text': 'name: Fetch variables from other roles\\n \\n \\ntags:\\n- create_dirs\\n- includevars\\nblock:\\n- name: Include vars from Elastic\\n  ansible.builtin.include_vars:\\n    file: ../../elasticsearch/defaults/main.yml\\n- name: Include vars from Kibana\\n  ansible.builtin.include_vars:\\n    file: ../../kibana/defaults/main.yml\\n- name: Include vars from Logstash\\n  ansible.builtin.include_vars:\\n    file: ../../logstash/defaults/main.yml\\n'},\n",
       " {'text': 'name: Import createdirs\\n \\n \\nansible.builtin.include_tasks:\\n  file: createdirs.yml\\n  apply:\\n    tags: create_dirs\\ntags: create_dirs\\n'},\n",
       " {'text': 'name: Import generatetemplates\\n \\n \\nansible.builtin.include_tasks: generatetemplates.yml\\n'},\n",
       " {'text': 'name: Import synccerts\\n \\n \\nansible.builtin.include_tasks: synccerts.yml\\n'},\n",
       " {'text': 'name: Import metricbeat_podman\\n \\n \\nansible.builtin.include_tasks: metricbeat_podman.yml\\n'},\n",
       " {'text': 'name: Deploy Metricbeat in a pod\\n \\n \\nvars:\\n  pod_name: \\'{{ metricbeat_pod_name }}.{{ inventory_hostname_short }}.metricbeat_{{\\n    metricbeat.instance_name }}\\'\\nblock:\\n- name: Create pod for metricbeat\\n  containers.podman.podman_pod:\\n    name: \\'{{ pod_name }}\\'\\n    hostname: \\'{{ inventory_hostname_short }}.metricbeat_{{ metricbeat.instance_name\\n      }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ metricbeat_pod_network }}\\'\\n  when: metricbeat_pod_network != \"bridge\"\\n- name: Create pod for metricbeat\\n  containers.podman.podman_pod:\\n    name: \\'{{ pod_name }}\\'\\n    hostname: \\'{{ inventory_hostname_short }}.metricbeat_{{ metricbeat.instance_name\\n      }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ metricbeat_pod_network }}\\'\\n    publish: \\'{{ metricbeat.ports }}\\'\\n  when: metricbeat_pod_network == \"bridge\"\\n- name: Run Metricbeat container - setup\\n  containers.podman.podman_container:\\n    name: \\'{{ inventory_hostname_short }}.metricbeat_{{ metricbeat.instance_name }}\\'\\n    pod: \\'{{ pod_name }}\\'\\n    image: \\'{{ metricbeat_image }}:{{ metricbeat_version }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ metricbeat_pod_network }}\\'\\n    label: process=metricbeat\\n    memory: \\'{{ metricbeat.memory_limit }}\\'\\n    cpus: \\'{{ metricbeat.cpu_limit }}\\'\\n    env:\\n      TZ: \\'{{ timezone }}\\'\\n      ELASTICSEARCH_HOSTS: \\'{{ metricbeat.monitoring_cluster_url }}\\'\\n      ELASTICSEARCH_USERNAME: \\'{{ metricbeat.monitoring_write_user_name }}\\'\\n      ELASTICSEARCH_PASSWORD: \\'{{ metricbeat.monitoring_write_user_pass }}\\'\\n    volume:\\n    - \\'{{ metricbeat_config }}/config/metricbeat.docker.yml:/usr/share/metricbeat/metricbeat.yml:z\\'\\n    - \\'{{ metricbeat_config }}/certs/transport_ca.crt:/usr/share/metricbeat/transport_ca.crt:ro,z\\'\\n    command: setup -e --index-management --pipelines --dashboards\\n  register: result\\n  until: result is success\\n  retries: 3\\n  delay: 5\\n  run_once: true\\n  environment: \\'{{ proxy_env }}\\'\\n- name: Run Metricbeat container\\n  containers.podman.podman_container:\\n    name: \\'{{ inventory_hostname_short }}.metricbeat_{{ metricbeat.instance_name }}\\'\\n    pod: \\'{{ pod_name }}\\'\\n    image: \\'{{ metricbeat_image }}:{{ metricbeat_version }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ metricbeat_pod_network }}\\'\\n    label: process=metricbeat\\n    expose: \\'{{ metricbeat.ports }}\\'\\n    memory: \\'{{ metricbeat.memory_limit }}\\'\\n    cpus: \\'{{ metricbeat.cpu_limit }}\\'\\n    env:\\n      TZ: \\'{{ timezone }}\\'\\n      ELASTICSEARCH_HOSTS: \\'{{ metricbeat.monitoring_cluster_url }}\\'\\n      ELASTICSEARCH_USERNAME: \\'{{ metricbeat.monitoring_write_user_name }}\\'\\n      ELASTICSEARCH_PASSWORD: \\'{{ metricbeat.monitoring_write_user_pass }}\\'\\n    user: root\\n    volume:\\n    - \\'{{ metricbeat_config }}/config/metricbeat.docker.yml:/usr/share/metricbeat/metricbeat.yml:z\\'\\n    - \\'{{ metricbeat_config }}/certs/transport_ca.crt:/usr/share/metricbeat/transport_ca.crt:ro,z\\'\\n    - \\'{{ metricbeat_config }}/certs/kibana_signing_ca.crt:/usr/share/metricbeat/kibana_signing_ca.crt:ro,z\\'\\n  register: result\\n  until: result is success\\n  retries: 3\\n  delay: 5\\n- name: Open up firewalld ports\\n  ansible.posix.firewalld:\\n    port: \\'{{ item }}/tcp\\'\\n    permanent: true\\n    immediate: true\\n    state: enabled\\n    zone: \\'{{ firewalld_zone }}\\'\\n  loop: \\'{{ metricbeat.ports }}\\'\\n  when:\\n  - metricbeat_pod_network == \"host\"\\n  - firewalld_enabled | bool\\n- name: Hand over pod and container mgmt to systemd\\n  vars:\\n    container_name: \\'{{ pod_name }}\\'\\n    type: pod\\n  ansible.builtin.import_role:\\n    name: podman_systemd_simple\\n'},\n",
       " {'text': \"name: Copy the certificates for Metricbeat\\n \\n \\nansible.builtin.copy:\\n  content: '{{ item.source }}'\\n  dest: '{{ metricbeat_config }}/certs/{{ item.file }}'\\n  mode: '0440'\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\nloop:\\n- file: transport_ca.crt\\n  source: '{{ xpack_transport_ca }}'\\n- file: kibana_signing_ca.crt\\n  source: '{{ server_ssl_ca }}'\\nno_log: true\\n\"},\n",
       " {'text': \"name: Generating metricbeat config and placing into config directory\\n \\n \\nansible.builtin.template:\\n  src: '{{ item }}.j2'\\n  dest: '{{ metricbeat_config }}/config/{{ item }}'\\n  mode: '0644'\\n  owner: root\\n  group: root\\nloop:\\n- metricbeat.docker.yml\\n\"},\n",
       " {'text': \"name: Create persistent directories for Metricbeat\\n \\n \\nansible.builtin.file:\\n  path: '{{ item }}'\\n  state: directory\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\n  mode: '0755'\\nloop:\\n- '{{ metricbeat_config }}/certs'\\n- '{{ metricbeat_config }}/config'\\ntags:\\n- create_dirs\\n\"},\n",
       " {'text': 'name: Import createdirs\\n \\n \\nansible.builtin.include_tasks:\\n  file: createdirs.yml\\n  apply:\\n    tags: create_dirs\\ntags: create_dirs\\n'},\n",
       " {'text': 'name: Include generatetemplates\\n \\n \\nansible.builtin.include_tasks: generatetemplates.yml\\n'},\n",
       " {'text': 'name: Include synccerts\\n \\n \\nansible.builtin.include_tasks: synccerts.yml\\n'},\n",
       " {'text': 'name: Include kibana_podman\\n \\n \\nansible.builtin.include_tasks: kibana_podman.yml\\n'},\n",
       " {'text': \"name: Copy the certificate used to issue the Elasticsearch node certificates to Kibana\\n \\n \\n  servers\\nansible.builtin.copy:\\n  content: '{{ item.source }}'\\n  dest: '{{ kibana_config }}/certs/{{ item.file }}'\\n  mode: '0440'\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\nloop:\\n- file: elastic_ca.crt\\n  source: '{{ elasticsearch_ssl_ca }}'\\n- file: kibana_signing_ca.crt\\n  source: '{{ server_ssl_ca }}'\\n- file: ssl.crt\\n  source: '{{ server_ssl_cert }}'\\n- file: ssl.key\\n  source: '{{ server_ssl_key }}'\\n- file: ssl.p12\\n  source: '{{ server_ssl_keystore }}'\\nno_log: true\\n\"},\n",
       " {'text': 'name: Deploy Kibana in a pod\\n \\n \\nvars:\\n  pod_name: \\'{{ kibana_pod_name }}.{{ inventory_hostname_short }}.kibana_{{ kibana.instance_name\\n    }}\\'\\nblock:\\n- name: Create pod for kibana\\n  containers.podman.podman_pod:\\n    name: \\'{{ pod_name }}\\'\\n    hostname: \\'{{ inventory_hostname_short }}.kibana_{{ kibana.instance_name }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ kibana_pod_network }}\\'\\n  when: kibana_pod_network != \"bridge\"\\n- name: Create pod for kibana\\n  containers.podman.podman_pod:\\n    name: \\'{{ pod_name }}\\'\\n    hostname: \\'{{ inventory_hostname_short }}.kibana_{{ kibana.instance_name }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ kibana_pod_network }}\\'\\n    publish: \\'{{ kibana.ports }}\\'\\n  when: kibana_pod_network == \"bridge\"\\n- name: Run Kibana container\\n  containers.podman.podman_container:\\n    name: \\'{{ inventory_hostname_short }}.kibana_{{ kibana.instance_name }}\\'\\n    pod: \\'{{ pod_name }}\\'\\n    image: \\'{{ kibana_image }}:{{ kibana_version }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ kibana_pod_network }}\\'\\n    label: process=kibana traefik.enable=true traefik.http.routers.kibana-www-router.entrypoints=\"websecure\"\\n      traefik.http.routers.kibana-www-router.rule=Host(`{{ kibana_fqdn }}`) traefik.http.routers.kibana-www-router.tls=true\\n      traefik.http.routers.kibana-www-router.service=kibana-www-service traefik.http.services.kibana-www-service.loadbalancer.server.scheme=https\\n      traefik.http.services.kibana-www-service.loadbalancer.server.port={{ kibana.ports[0]\\n      }}\\n    expose: \\'{{ kibana.ports }}\\'\\n    memory: \\'{{ kibana.memory_limit }}\\'\\n    cpus: \\'{{ kibana.cpu_limit }}\\'\\n    volume:\\n    - \\'{{ kibana_data }}/logs:/var/log/kibana:z\\'\\n    - \\'{{ kibana_config }}/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,z\\'\\n    - \\'{{ kibana_config }}/certs:/usr/share/kibana/config/certs:ro,z\\'\\n  register: result\\n  until: result is success\\n  retries: 3\\n  delay: 5\\n  environment: \\'{{ proxy_env }}\\'\\n- name: Open up firewalld ports\\n  ansible.posix.firewalld:\\n    port: \\'{{ item }}/tcp\\'\\n    permanent: true\\n    immediate: true\\n    state: enabled\\n    zone: \\'{{ firewalld_zone }}\\'\\n  loop: \\'{{ kibana.ports }}\\'\\n  when:\\n  - kibana_pod_network == \"host\"\\n  - firewalld_enabled | bool\\n- name: Hand over pod and container mgmt to systemd\\n  vars:\\n    container_name: \\'{{ pod_name }}\\'\\n    type: pod\\n  ansible.builtin.import_role:\\n    name: podman_systemd_simple\\n'},\n",
       " {'text': \"name: Generating kibana config and placing into config directory\\n \\n \\nansible.builtin.template:\\n  src: '{{ item }}.j2'\\n  dest: '{{ kibana_config }}/config/{{ item }}'\\n  mode: '0644'\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\nloop:\\n- kibana.yml\\ntags: security\\n\"},\n",
       " {'text': \"name: Create persistent directories for Kibana\\n \\n \\nansible.builtin.file:\\n  path: '{{ item }}'\\n  state: directory\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\n  mode: '0755'\\nloop:\\n- '{{ kibana_config }}/config'\\n- '{{ kibana_config }}/certs'\\n- '{{ kibana_data }}/logs'\\n\"},\n",
       " {'text': 'name: Import createdirs\\n \\n \\nansible.builtin.include_tasks:\\n  file: createdirs.yml\\n  apply:\\n    tags: create_dirs\\ntags: create_dirs\\n'},\n",
       " {'text': 'name: Include generatetemplates\\n \\n \\nansible.builtin.include_tasks: generatetemplates.yml\\n'},\n",
       " {'text': 'name: Include synccerts\\n \\n \\nansible.builtin.include_tasks: synccerts.yml\\n'},\n",
       " {'text': 'name: Include logstash_podman\\n \\n \\nansible.builtin.include_tasks: logstash_podman.yml\\n'},\n",
       " {'text': \"name: Copy certificates to Logstash servers\\n \\n \\nansible.builtin.copy:\\n  content: '{{ item.source }}'\\n  dest: '{{ logstash_config }}/certs/{{ item.file }}'\\n  mode: '0440'\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\nloop:\\n- file: http_ca.crt\\n  source: '{{ xpack_http_ca }}'\\n- file: ssl_cert.crt\\n  source: '{{ logstash_server_ssl_cert }}'\\n- file: ssl_cert.key\\n  source: '{{ logstash_server_ssl_key }}'\\nno_log: true\\n\"},\n",
       " {'text': 'name: Deploy Logstash in a pod\\n \\n \\nvars:\\n  pod_name: \\'{{ logstash_pod_name }}.{{ inventory_hostname_short }}.logstash_{{ logstash.instance_name\\n    }}\\'\\nblock:\\n- name: Create pod for logstash\\n  containers.podman.podman_pod:\\n    name: \\'{{ pod_name }}\\'\\n    hostname: \\'{{ inventory_hostname_short }}.logstash_{{ logstash.instance_name }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ logstash_pod_network }}\\'\\n  when: logstash_pod_network != \"bridge\"\\n- name: Create pod for logstash\\n  containers.podman.podman_pod:\\n    name: \\'{{ pod_name }}\\'\\n    hostname: \\'{{ inventory_hostname_short }}.logstash_{{ logstash.instance_name }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ logstash_pod_network }}\\'\\n    publish: \\'{{ logstash.ports }}\\'\\n  when: logstash_pod_network == \"bridge\"\\n- name: Run Logstash container\\n  containers.podman.podman_container:\\n    name: \\'{{ inventory_hostname_short }}.logstash_{{ logstash.instance_name }}\\'\\n    pod: \\'{{ pod_name }}\\'\\n    image: \\'{{ logstash_image }}:{{ logstash_version }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ logstash_pod_network }}\\'\\n    label:\\n      process: logstash\\n    memory: \\'{{ logstash.memory_limit }}\\'\\n    cpus: \\'{{ logstash.cpu_limit }}\\'\\n    expose: \\'{{ logstash.ports }}\\'\\n    env:\\n      TZ: \\'{{ timezone }}\\'\\n      LS_JAVA_OPTS: \\'{{ logstash.java_opts }}\\'\\n      NO_PROXY: \\'{{ no_proxy }}\\'\\n    volume:\\n    - \\'{{ logstash_config }}/certs:/usr/share/logstash/certs:ro,z\\'\\n    - \\'{{ logstash_config }}/config/log4j2.properties:/usr/share/logstash/config/log4j2.properties:z\\'\\n    - \\'{{ logstash_config }}/config/logstash.yml:/usr/share/logstash/config/logstash.yml:z\\'\\n    - \\'{{ logstash_config }}/config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:z\\'\\n    - \\'{{ logstash_config }}/pipelines:/usr/share/logstash/pipeline:z\\'\\n    - \\'{{ logstash_data }}/data:/usr/share/logstash/data:Z\\'\\n    - \\'{{ logstash_data }}/logs:/usr/share/logstash/logs:z\\'\\n  register: result\\n  until: result is success\\n  retries: 3\\n  delay: 5\\n  environment: \\'{{ proxy_env }}\\'\\n- name: Open up firewalld ports\\n  ansible.posix.firewalld:\\n    port: \\'{{ item }}/tcp\\'\\n    permanent: true\\n    immediate: true\\n    state: enabled\\n    zone: \\'{{ firewalld_zone }}\\'\\n  loop: \\'{{ logstash.ports }}\\'\\n  when:\\n  - logstash_pod_network == \"host\"\\n  - firewalld_enabled | bool\\n- name: Hand over pod and container mgmt to systemd\\n  vars:\\n    container_name: \\'{{ pod_name }}\\'\\n    type: pod\\n  ansible.builtin.import_role:\\n    name: podman_systemd_simple\\n'},\n",
       " {'text': \"name: Generate the configuration files of Logstash from templates\\n \\n \\nansible.builtin.template:\\n  src: '{{ item.source }}'\\n  dest: '{{ logstash_config }}/{{ item.file }}'\\n  mode: '0644'\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\nloop:\\n- file: config/logstash.yml\\n  source: logstash.yml.j2\\n- file: config/pipelines.yml\\n  source: pipelines.yml.j2\\n\"},\n",
       " {'text': \"name: Generate pipeline configs\\n \\n \\nansible.builtin.template:\\n  src: '{{ item.type }}.conf.j2'\\n  dest: '{{ logstash_config }}/pipelines/{{ item.name }}_{{ item.id }}.conf'\\n  mode: '0644'\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\nwhen: item.enabled\\nloop: '{{ logstash_pipelines }}'\\n\"},\n",
       " {'text': \"name: Generate log4j2.properties for Logstash node\\n \\n \\nansible.builtin.copy:\\n  src: log4j2.properties\\n  dest: '{{ logstash_config }}/config/log4j2.properties'\\n  group: '{{ group_uid }}'\\n  owner: '{{ owner_uid }}'\\n  mode: '0644'\\n\"},\n",
       " {'text': \"name: Create persistent directories for Logstash\\n \\n \\nansible.builtin.file:\\n  path: '{{ item }}'\\n  state: directory\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\n  mode: '0755'\\nloop:\\n- '{{ logstash_data }}/data'\\n- '{{ logstash_data }}/data/queue'\\n- '{{ logstash_data }}/logs'\\n- '{{ logstash_config }}/certs'\\n- '{{ logstash_config }}/config'\\n- '{{ logstash_config }}/pipelines'\\n\"},\n",
       " {'text': 'name: Include task sysctlsetup.yml\\n \\n \\nansible.builtin.include_tasks: sysctlsetup.yml\\n'},\n",
       " {'text': 'name: Import createdirs\\n \\n \\nansible.builtin.include_tasks:\\n  file: createdirs.yml\\n  apply:\\n    tags: create_dirs\\ntags: create_dirs\\n'},\n",
       " {'text': 'name: Include task generatetemplates.yml\\n \\n \\nansible.builtin.include_tasks: generatetemplates.yml\\n'},\n",
       " {'text': 'name: Include task synccerts.yml\\n \\n \\nansible.builtin.include_tasks: synccerts.yml\\n'},\n",
       " {'text': 'name: Include task elastic_stack_podman.yml\\n \\n \\nansible.builtin.include_tasks: elastic_stack_podman.yml\\n'},\n",
       " {'text': \"name: Create roles and users\\n \\n \\ntags: security\\nrun_once: true\\nwhen: not ansible_check_mode\\nblock:\\n- name: Include custom roles from inventory\\n  ansible.builtin.set_fact:\\n    es_roles: '{{ es_roles | combine(es_roles_custom, recursive=True) }}'\\n  when: es_roles_custom is defined\\n- name: Include custom users from inventory\\n  ansible.builtin.set_fact:\\n    es_users: '{{ es_users | combine(es_users_custom, recursive=True) }}'\\n  when: es_users_custom is defined\\n- name: Wait for Elasticsearch API to be available (timeout 300 sec)\\n  ansible.builtin.wait_for:\\n    host: '{{ es_api_host }}'\\n    port: 9200\\n    delay: 30\\n    state: started\\n    timeout: 300\\n- name: Wait for cluster state to be YELLOW or GREEN (timeout 300 sec)\\n  ansible.builtin.uri:\\n    url: '{{ es_api_uri }}/_cat/health'\\n    return_content: true\\n    validate_certs: '{{ es_validate_certs }}'\\n    user: '{{ es_api_basic_auth_username }}'\\n    password: '{{ es_api_basic_auth_password }}'\\n    force_basic_auth: true\\n  register: response\\n  until: '''red'' not in response.content and ((response.content.find(''yellow'')\\n    != -1) or (response.content.find(''green'') != -1))'\\n  delay: 5\\n  retries: 60\\n- name: Include task elasticsearch-security-native.yml\\n  ansible.builtin.include_tasks:\\n    file: elasticsearch-security-native.yml\\n    apply:\\n      tags: security\\n\"},\n",
       " {'text': 'name: Deploy Elasticsearch in a pod\\n \\n \\nvars:\\n  pod_name: \\'{{ elastic_pod_name }}.{{ inventory_hostname_short }}.es_{{ elastic.instance_name\\n    }}\\'\\nblock:\\n- name: Create pod for elasticsearch\\n  containers.podman.podman_pod:\\n    name: \\'{{ pod_name }}\\'\\n    hostname: \\'{{ inventory_hostname_short }}.es_{{ elastic.instance_name }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ elastic_pod_network }}\\'\\n  when: elastic_pod_network != \"bridge\"\\n- name: Create pod for elasticsearch\\n  containers.podman.podman_pod:\\n    name: \\'{{ pod_name }}\\'\\n    hostname: \\'{{ inventory_hostname_short }}.es_{{ elastic.instance_name }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ elastic_pod_network }}\\'\\n    publish:\\n    - \\'{{ elastic.ip_address }}:{{ elastic.ports[0] }}:{{ elastic.ports[0] }}\\'\\n    - \\'{{ elastic.ip_address }}:{{ elastic.ports[1] }}:{{ elastic.ports[1] }}\\'\\n  when: elastic_pod_network == \"bridge\"\\n- name: Run Elastic container\\n  containers.podman.podman_container:\\n    name: \\'{{ inventory_hostname_short }}.es_{{ elastic.instance_name }}\\'\\n    pod: \\'{{ pod_name }}\\'\\n    image: \\'{{ elastic_image }}:{{ elastic_version }}\\'\\n    state: started\\n    stop_timeout: 90\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ elastic_pod_network }}\\'\\n    label:\\n      process: elasticsearch\\n    ulimit:\\n    - memlock=-1:-1\\n    expose: \\'{{ elastic.ports }}\\'\\n    memory: \\'{{ elastic.memory_limit }}\\'\\n    cpus: \\'{{ elastic.cpu_limit }}\\'\\n    env:\\n      TZ: \\'{{ timezone }}\\'\\n      ES_HEAP_SIZE: \\'{{ elastic.heap_size }}\\'\\n      ES_JAVA_OPTS: \\'{{ elastic.java_opts }}\\'\\n      ELASTIC_PASSWORD: \\'{{ elastic_password }}\\'\\n      HTTP_PROXY: \\'{{ http_proxy }}\\'\\n      HTTPS_PROXY: \\'{{ https_proxy }}\\'\\n    volume:\\n    - \\'{{ elastic_data }}/logs:/usr/share/elasticsearch/logs:z\\'\\n    - \\'{{ elastic_data }}/data:/usr/share/elasticsearch/data:z\\'\\n    - \\'{{ elastic_data }}/snapshots:{{ elastic_snapshot_repository }}\\'\\n    - \\'{{ elastic_config }}/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,z\\'\\n    - \\'{{ elastic_config }}/config/log4j2.properties:/usr/share/elasticsearch/config/log4j2.properties:ro,z\\'\\n    - \\'{{ elastic_config }}/certs:/usr/share/elasticsearch/config/certificates:ro,z\\'\\n  register: result\\n  until: result is success\\n  retries: 3\\n  delay: 5\\n  environment: \\'{{ proxy_env }}\\'\\n- name: Open up firewalld ports\\n  ansible.posix.firewalld:\\n    port: \\'{{ item }}/tcp\\'\\n    permanent: true\\n    immediate: true\\n    state: enabled\\n    zone: \\'{{ firewalld_zone }}\\'\\n  loop: \\'{{ elastic.ports }}\\'\\n  when:\\n  - elastic_pod_network == \"host\"\\n  - firewalld_enabled | bool\\n- name: Hand over pod and container mgmt to systemd\\n  vars:\\n    container_name: \\'{{ pod_name }}\\'\\n    type: pod\\n  ansible.builtin.import_role:\\n    name: podman_systemd_simple\\n'},\n",
       " {'text': 'name: Set fact change_api_password to false\\n \\n \\nansible.builtin.set_fact: change_api_password=false\\n'},\n",
       " {'text': 'name: Set fact manage_native_users to false\\n \\n \\nansible.builtin.set_fact: manage_native_users=false\\n'},\n",
       " {'text': 'name: Set fact manage_native_users to true\\n \\n \\nansible.builtin.set_fact: manage_native_users=true\\nwhen: es_users is defined and es_users.native is defined and es_users.native.keys()\\n  | list | length > 0\\n'},\n",
       " {'text': 'name: Set fact manage_native_role to false\\n \\n \\nansible.builtin.set_fact: manage_native_roles=false\\n'},\n",
       " {'text': 'name: Set fact manage_native_roles to true\\n \\n \\nansible.builtin.set_fact: manage_native_roles=true\\nwhen: es_roles is defined and es_roles.native is defined and es_roles.native.keys()\\n  | list | length > 0\\n'},\n",
       " {'text': \"name: List Native Users\\n \\n \\nansible.builtin.uri:\\n  url: '{{ es_api_uri }}/{{ es_security_api }}/user'\\n  method: GET\\n  user: '{{ es_api_basic_auth_username }}'\\n  password: '{{ es_api_basic_auth_password }}'\\n  force_basic_auth: true\\n  status_code: 200\\n  validate_certs: '{{ es_validate_certs }}'\\nregister: user_list_response\\nwhen: manage_native_users\\ncheck_mode: false\\n\"},\n",
       " {'text': 'name: Set fact reserved_users equals user_list_response.json\\n \\n \\nansible.builtin.set_fact: reserved_users={{ user_list_response.json | abalage.elasticstack_podman.filter_reserved\\n  }}\\nwhen: manage_native_users\\n'},\n",
       " {'text': 'name: Set fact current_users equals user_list_response.json.keys not including reserved\\n \\n \\nansible.builtin.set_fact: current_users={{ user_list_response.json.keys() | list |\\n  difference(reserved_users) }}\\nwhen: manage_native_users\\n'},\n",
       " {'text': 'name: Set fact native_users\\n \\n \\nansible.builtin.set_fact: native_users={{ es_users.native }}\\nwhen: manage_native_users\\n'},\n",
       " {'text': 'name: Set fact change_api_password to true\\n \\n \\nansible.builtin.set_fact: change_api_password=true\\nwhen: manage_native_users and es_api_basic_auth_username in native_users and native_users[es_api_basic_auth_username].password\\n  is defined\\n'},\n",
       " {'text': 'name: Update API User Password\\n \\n \\nansible.builtin.uri:\\n  url: \\'{{ es_api_uri }}/{{ es_security_api }}/user/{{ es_api_basic_auth_username\\n    }}/_password\\'\\n  method: POST\\n  body_format: json\\n  body: \\'{ \"password\":\"{{ native_users[es_api_basic_auth_username].password }}\" }\\'\\n  status_code: 200\\n  user: \\'{{ es_api_basic_auth_username }}\\'\\n  password: \\'{{ es_api_basic_auth_password }}\\'\\n  force_basic_auth: true\\n  validate_certs: \\'{{ es_validate_certs }}\\'\\nwhen: change_api_password\\n'},\n",
       " {'text': 'name: Set fact es_api_basic_auth_password\\n \\n \\nansible.builtin.set_fact: es_api_basic_auth_password={{ native_users[es_api_basic_auth_username].password\\n  }}\\nwhen: change_api_password\\n'},\n",
       " {'text': 'name: Set fact users_to_remove\\n \\n \\nansible.builtin.set_fact: users_to_remove={{ current_users | difference(native_users.keys()\\n  | list) }}\\nwhen: manage_native_users\\n'},\n",
       " {'text': \"name: Delete Native Users\\n \\n \\nansible.builtin.uri:\\n  url: '{{ es_api_uri }}/{{ es_security_api }}/user/{{ item }}'\\n  method: DELETE\\n  status_code: 200\\n  user: '{{ es_api_basic_auth_username }}'\\n  password: '{{ es_api_basic_auth_password }}'\\n  force_basic_auth: true\\n  validate_certs: '{{ es_validate_certs }}'\\nwhen: manage_native_users and es_delete_unmanaged_native\\nwith_items: '{{ users_to_remove | default([]) }}'\\n\"},\n",
       " {'text': 'name: Set fact users_to_ignore\\n \\n \\nansible.builtin.set_fact: users_to_ignore={{ native_users.keys() | list | intersect(reserved_users)\\n  }}\\nwhen: manage_native_users\\n'},\n",
       " {'text': \"name: Debug message\\n \\n \\nansible.builtin.debug:\\n  msg: 'WARNING: YOU CAN ONLY CHANGE THE PASSWORD FOR RESERVED USERS IN THE NATIVE\\n    REALM. ANY ROLE CHANGES WILL BE IGNORED: {{ users_to_ignore }}'\\nwhen: manage_native_users and users_to_ignore | length > 0\\n\"},\n",
       " {'text': 'name: Update Reserved User Passwords\\n \\n \\nansible.builtin.uri:\\n  url: \\'{{ es_api_uri }}/{{ es_security_api }}/user/{{ item | urlencode }}/_password\\'\\n  method: POST\\n  body_format: json\\n  body: \\'{ \"password\":\"{{ native_users[item].password }}\" }\\'\\n  status_code: 200\\n  user: \\'{{ es_api_basic_auth_username }}\\'\\n  password: \\'{{ es_api_basic_auth_password }}\\'\\n  force_basic_auth: true\\n  validate_certs: \\'{{ es_validate_certs }}\\'\\nwhen: native_users[item].password is defined\\nno_log: true\\nwith_items: \\'{{ users_to_ignore | default([]) }}\\'\\n'},\n",
       " {'text': 'name: Set fact users_to_modify\\n \\n \\nansible.builtin.set_fact: users_to_modify={{ native_users.keys() | list | difference(reserved_users)\\n  }}\\nwhen: manage_native_users\\n'},\n",
       " {'text': \"name: Update Non-Reserved Native User Details\\n \\n \\nansible.builtin.uri:\\n  url: '{{ es_api_uri }}/{{ es_security_api }}/user/{{ item | urlencode }}'\\n  method: POST\\n  body_format: json\\n  body: '{{ native_users[item] | to_json }}'\\n  status_code: 200\\n  user: '{{ es_api_basic_auth_username }}'\\n  password: '{{ es_api_basic_auth_password }}'\\n  force_basic_auth: true\\n  validate_certs: '{{ es_validate_certs }}'\\nwhen: manage_native_users\\nno_log: true\\nwith_items: '{{ users_to_modify | default([]) }}'\\n\"},\n",
       " {'text': \"name: List Native Roles\\n \\n \\nansible.builtin.uri:\\n  url: '{{ es_api_uri }}/{{ es_security_api }}/role'\\n  method: GET\\n  user: '{{ es_api_basic_auth_username }}'\\n  password: '{{ es_api_basic_auth_password }}'\\n  force_basic_auth: true\\n  status_code: 200\\n  validate_certs: '{{ es_validate_certs }}'\\nregister: role_list_response\\nwhen: manage_native_roles\\ncheck_mode: false\\n\"},\n",
       " {'text': 'name: Set fact reserved roles\\n \\n \\nansible.builtin.set_fact: reserved_roles={{ role_list_response.json | abalage.elasticstack_podman.filter_reserved\\n  }}\\nwhen: manage_native_roles\\n'},\n",
       " {'text': 'name: Set fact current roles\\n \\n \\nansible.builtin.set_fact: current_roles={{ role_list_response.json.keys() | list |\\n  difference(reserved_roles) }}\\nwhen: manage_native_roles\\n'},\n",
       " {'text': 'name: Set fact roles to ignore\\n \\n \\nansible.builtin.set_fact: roles_to_ignore={{ es_roles.native.keys() | list | intersect(reserved_roles)\\n  | default([]) }}\\nwhen: manage_native_roles\\n'},\n",
       " {'text': \"name: Debug message\\n \\n \\nansible.builtin.debug:\\n  msg: 'WARNING: YOU CANNOT CHANGE RESERVED ROLES. THE FOLLOWING WILL BE IGNORED:\\n    {{ roles_to_ignore }}'\\nwhen: manage_native_roles and roles_to_ignore | length > 0\\n\"},\n",
       " {'text': 'name: Set fact roles_to_remove\\n \\n \\nansible.builtin.set_fact: roles_to_remove={{ current_roles | difference(es_roles.native.keys()\\n  | list) }}\\nwhen: manage_native_roles\\n'},\n",
       " {'text': \"name: Delete Native Roles\\n \\n \\nansible.builtin.uri:\\n  url: '{{ es_api_uri }}/{{ es_security_api }}/role/{{ item | urlencode }}'\\n  method: DELETE\\n  status_code: 200\\n  user: '{{ es_api_basic_auth_username }}'\\n  password: '{{ es_api_basic_auth_password }}'\\n  force_basic_auth: true\\n  validate_certs: '{{ es_validate_certs }}'\\nwhen: manage_native_roles  and es_delete_unmanaged_native\\nwith_items: '{{ roles_to_remove | default([]) }}'\\n\"},\n",
       " {'text': 'name: Set fact roles_to_modify\\n \\n \\nansible.builtin.set_fact: roles_to_modify={{ es_roles.native.keys() | list | difference(reserved_roles)\\n  }}\\nwhen: manage_native_roles\\n'},\n",
       " {'text': \"name: Update Native Roles\\n \\n \\nansible.builtin.uri:\\n  url: '{{ es_api_uri }}/{{ es_security_api }}/role/{{ item | urlencode }}'\\n  method: POST\\n  body_format: json\\n  body: '{{ es_roles.native[item] | to_json }}'\\n  status_code: 200\\n  user: '{{ es_api_basic_auth_username }}'\\n  password: '{{ es_api_basic_auth_password }}'\\n  force_basic_auth: true\\n  validate_certs: '{{ es_validate_certs }}'\\nwhen: manage_native_roles\\nwith_items: '{{ roles_to_modify | default([]) }}'\\n\"},\n",
       " {'text': \"name: Copy the X.509 certificates for transport and http security\\n \\n \\nansible.builtin.copy:\\n  content: '{{ item.source }}'\\n  dest: '{{ elastic_config }}/certs/{{ item.file }}'\\n  mode: '0440'\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\nloop:\\n- file: transport_ca.crt\\n  source: '{{ xpack_transport_ca }}'\\n- file: instance.crt\\n  source: '{{ xpack_transport_ssl_cert }}'\\n- file: instance.key\\n  source: '{{ xpack_transport_ssl_key }}'\\n- file: instance.p12\\n  source: '{{ xpack_transport_ssl_keystore }}'\\n- file: http_ca.crt\\n  source: '{{ xpack_http_ca }}'\\n- file: http.crt\\n  source: '{{ xpack_http_ssl_cert }}'\\n- file: http.key\\n  source: '{{ xpack_http_ssl_key }}'\\n- file: http.p12\\n  source: '{{ xpack_http_ssl_keystore }}'\\nno_log: true\\n\"},\n",
       " {'text': 'name: Adding sysctl config\\n \\n \\nansible.builtin.template:\\n  src: sysctl.j2\\n  dest: /etc/sysctl.d/elastic.conf\\n  owner: root\\n  group: root\\n  mode: 420\\nnotify: Reload sysctl\\n'},\n",
       " {'text': \"name: Generate elasticsearch.yml for node\\n \\n \\nansible.builtin.template:\\n  src: '{{ item }}.j2'\\n  dest: '{{ elastic_config }}/config/{{ item }}'\\n  mode: '0644'\\n  group: '{{ group_uid }}'\\n  owner: '{{ owner_uid }}'\\nloop:\\n- elasticsearch.yml\\n\"},\n",
       " {'text': \"name: Place elasticsearch logging config into the config directory\\n \\n \\nansible.builtin.copy:\\n  src: '{{ item }}'\\n  dest: '{{ elastic_config }}/config/{{ item }}'\\n  mode: '0644'\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\nloop:\\n- log4j2.properties\\n\"},\n",
       " {'text': \"name: Create persistent directories for Elasticsearch\\n \\n \\nansible.builtin.file:\\n  path: '{{ item }}'\\n  state: directory\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\n  mode: '0755'\\nloop:\\n- '{{ elastic_data }}/data'\\n- '{{ elastic_data }}/logs'\\n- '{{ elastic_data }}/snapshots'\\n- '{{ elastic_config }}/certs'\\n- '{{ elastic_config }}/config'\\n\"},\n",
       " {'text': 'name: Create systemd service unit file for pod or container\\n \\n \\nvars:\\n  prefix: \\'{{ type }}\\'\\n  service_unit: \\'{{ prefix }}-{{ container_name }}.service\\'\\nblock:\\n- name: Generate systemd units by podman\\n  ansible.builtin.command:\\n    cmd: podman generate systemd -f -n -t \"{{ container_stop_timeout }}\" \"{{ container_name\\n      }}\"\\n    chdir: \\'{{ service_files_dir }}\\'\\n- name: Check that generated service unit exists\\n  ansible.builtin.stat:\\n    path: \\'{{ service_files_dir }}/{{ service_unit }}\\'\\n  register: stat_result\\n- name: Enable systemd service unit\\n  ansible.builtin.systemd:\\n    name: \\'{{ service_unit }}\\'\\n    state: \\'{{ service_state }}\\'\\n    daemon_reload: true\\n    enabled: \\'{{ service_enabled }}\\'\\n  when: stat_result.stat.exists\\n'},\n",
       " {'text': 'name: Fetch variables from other roles\\n \\n \\ntags:\\n- create_dirs\\n- includevars\\nblock:\\n- name: Include vars from Elastic\\n  ansible.builtin.include_vars:\\n    file: ../../elasticsearch/defaults/main.yml\\n- name: Include vars from Kibana\\n  ansible.builtin.include_vars:\\n    file: ../../kibana/defaults/main.yml\\n- name: Include vars from Logstash\\n  ansible.builtin.include_vars:\\n    file: ../../logstash/defaults/main.yml\\n'},\n",
       " {'text': 'name: Import createdirs\\n \\n \\nansible.builtin.include_tasks:\\n  file: createdirs.yml\\n  apply:\\n    tags: create_dirs\\ntags: create_dirs\\n'},\n",
       " {'text': 'name: Import generatetemplates\\n \\n \\nansible.builtin.include_tasks: generatetemplates.yml\\n'},\n",
       " {'text': 'name: Import synccerts\\n \\n \\nansible.builtin.include_tasks: synccerts.yml\\n'},\n",
       " {'text': 'name: Import filebeat_podman\\n \\n \\nansible.builtin.include_tasks: filebeat_podman.yml\\n'},\n",
       " {'text': \"name: Copy the certificate for Filebeat\\n \\n \\nansible.builtin.copy:\\n  content: '{{ item.source }}'\\n  dest: '{{ filebeat_config }}/certs/{{ item.file }}'\\n  mode: '0440'\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\nloop:\\n- file: http_ca.crt\\n  source: '{{ xpack_http_ca }}'\\n- file: kibana_signing_ca.crt\\n  source: '{{ server_ssl_ca }}'\\nno_log: true\\n\"},\n",
       " {'text': \"name: Generate filebeat.yml for Filebeat node\\n \\n \\nansible.builtin.template:\\n  src: filebeat.yml.j2\\n  dest: '{{ filebeat_config }}/config/filebeat.yml'\\n  group: root\\n  owner: root\\n  mode: '0644'\\n\"},\n",
       " {'text': 'name: Deploy Filebeat in a pod\\n \\n \\nvars:\\n  pod_name: \\'{{ filebeat_pod_name }}.{{ inventory_hostname_short }}.filebeat_{{ filebeat.instance_name\\n    }}\\'\\nblock:\\n- name: Create pod for filebeat\\n  containers.podman.podman_pod:\\n    name: \\'{{ pod_name }}\\'\\n    hostname: \\'{{ inventory_hostname_short }}.filebeat_{{ filebeat.instance_name }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ filebeat_pod_network }}\\'\\n  when: filebeat_pod_network != \"bridge\"\\n- name: Create pod for filebeat\\n  containers.podman.podman_pod:\\n    name: \\'{{ pod_name }}\\'\\n    hostname: \\'{{ inventory_hostname_short }}.filebeat_{{ filebeat.instance_name }}\\'\\n    state: \\'{{ state }}\\'\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ filebeat_pod_network }}\\'\\n    publish: \\'{{ filebeat.ports }}\\'\\n  when: filebeat_pod_network == \"bridge\"\\n- name: Run Filebeat-setup container to perform initial setup. It will exit when it\\'s\\n    done.\\n  containers.podman.podman_container:\\n    name: \\'{{ inventory_hostname_short }}.filebeat_{{ filebeat.instance_name }}\\'\\n    pod: \\'{{ pod_name }}\\'\\n    image: \\'{{ filebeat_image }}:{{ filebeat_version }}\\'\\n    command: setup -e --index-management --pipelines --dashboards\\n    state: \\'{{ state }}\\'\\n    user: root\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ filebeat_pod_network }}\\'\\n    label:\\n      process: filebeat-setup\\n    expose: \\'{{ filebeat.ports }}\\'\\n    memory: \\'{{ filebeat.memory_limit }}\\'\\n    cpus: \\'{{ filebeat.cpu_limit }}\\'\\n    env:\\n      TZ: \\'{{ timezone }}\\'\\n      NO_PROXY: \\'{{ no_proxy }}\\'\\n    volume:\\n    - \\'{{ filebeat_config }}/certs/http_ca.crt:/usr/share/filebeat/config/http_ca.crt:ro,z\\'\\n    - \\'{{ filebeat_config }}/certs/kibana_signing_ca.crt:/usr/share/filebeat/config/kibana_signing_ca.crt:ro,z\\'\\n    - \\'{{ filebeat_config }}/config/filebeat.yml:/usr/share/filebeat/filebeat.yml:z\\'\\n    - \\'{{ filebeat_data }}/logs:/var/log/filebeat:z\\'\\n  run_once: true\\n  register: result\\n  until: result is success\\n  retries: 3\\n  delay: 5\\n  environment: \\'{{ proxy_env }}\\'\\n- name: Run Filebeat container\\n  containers.podman.podman_container:\\n    name: \\'{{ inventory_hostname_short }}.filebeat_{{ filebeat.instance_name }}\\'\\n    pod: \\'{{ pod_name }}\\'\\n    image: \\'{{ filebeat_image }}:{{ filebeat_version }}\\'\\n    state: \\'{{ state }}\\'\\n    user: root\\n    recreate: \\'{{ recreate }}\\'\\n    network: \\'{{ filebeat_pod_network }}\\'\\n    label: process=filebeat\\n    expose: \\'{{ filebeat.ports }}\\'\\n    memory: \\'{{ filebeat.memory_limit }}\\'\\n    cpus: \\'{{ filebeat.cpu_limit }}\\'\\n    env:\\n      TZ: \\'{{ timezone }}\\'\\n    volume:\\n    - \\'{{ filebeat_config }}/certs/http_ca.crt:/usr/share/filebeat/config/http_ca.crt:ro,z\\'\\n    - \\'{{ filebeat_config }}/certs/kibana_signing_ca.crt:/usr/share/filebeat/config/kibana_signing_ca.crt:ro,z\\'\\n    - \\'{{ filebeat_config }}/config/filebeat.yml:/usr/share/filebeat/filebeat.yml:z\\'\\n    - \\'{{ filebeat_data }}/logs:/var/log/filebeat:z\\'\\n    - \\'{{ elastic_data }}/logs:/var/log/elasticsearch:ro,z\\'\\n    - \\'{{ logstash_data }}/logs:/var/log/logstash:ro,z\\'\\n    - \\'{{ kibana_data }}/logs:/var/log/kibana:ro,z\\'\\n  register: result\\n  until: result is success\\n  retries: 3\\n  delay: 5\\n  environment: \\'{{ proxy_env }}\\'\\n- name: Open up firewalld ports\\n  ansible.posix.firewalld:\\n    port: \\'{{ item }}/tcp\\'\\n    permanent: true\\n    immediate: true\\n    state: enabled\\n    zone: \\'{{ firewalld_zone }}\\'\\n  loop: \\'{{ filebeat.ports }}\\'\\n  when:\\n  - filebeat_pod_network == \"host\"\\n  - firewalld_enabled | bool\\n- name: Hand over pod and container mgmt to systemd\\n  vars:\\n    container_name: \\'{{ pod_name }}\\'\\n    type: pod\\n  ansible.builtin.import_role:\\n    name: podman_systemd_simple\\n'},\n",
       " {'text': \"name: Create persistent directories for Filebeat\\n \\n \\nansible.builtin.file:\\n  path: '{{ item }}'\\n  state: directory\\n  owner: '{{ owner_uid }}'\\n  group: '{{ group_uid }}'\\n  mode: '0755'\\nloop:\\n- '{{ filebeat_data }}/logs'\\n- '{{ filebeat_config }}/certs'\\n- '{{ filebeat_config }}/config'\\n\"},\n",
       " {'text': \"name: Create placeholder directories for monitored components\\n \\n \\nansible.builtin.file:\\n  path: '{{ item }}'\\n  state: directory\\n  owner: root\\n  group: root\\n  mode: '0755'\\nloop:\\n- '{{ elastic_data }}/logs'\\n- '{{ logstash_data }}/logs'\\n- '{{ kibana_data }}/logs'\\n\"},\n",
       " {'text': 'name: install multiple package on amazon\\n \\n \\nwhen: ansible_facts[\\'distribution\\'] == \"Amazon\"\\nansible.builtin.package:\\n  name:\\n  - httpd\\n  - php-{{ php_version }}\\n  - php-mysql-{{ php_version }}\\n  - telnet\\n  - wget\\n  state: present\\nnotify: Start web server\\n'},\n",
       " {'text': 'name: Download wordpress\\n \\n \\nwhen: ansible_facts[\\'distribution\\'] == \"Amazon\"\\nansible.builtin.get_url:\\n  url: https://wordpress.org/wordpress-{{ wordpress_version }}.tar.gz\\n  dest: /tmp/\\n'},\n",
       " {'text': 'name: Extract wordpress.tgz into /tmp\\n \\n \\nwhen: ansible_facts[\\'distribution\\'] == \"Amazon\"\\nansible.builtin.unarchive:\\n  src: /tmp/wordpress-{{ wordpress_version }}.tar.gz\\n  dest: /tmp/\\n  remote_src: true\\n'},\n",
       " {'text': 'name: Host Wordpress\\n \\n \\nwhen: ansible_facts[\\'distribution\\'] == \"Amazon\"\\nshell: cp -r /tmp/wordpress/* /var/www/html/\\nignore_errors: true\\n'},\n",
       " {'text': 'name: install multiple package on amazon\\n \\n \\nwhen: ansible_facts[\\'distribution\\'] == \"Amazon\"\\nansible.builtin.package:\\n  name:\\n  - httpd\\n  - php-{{ php_version }}\\n  - php-mysql-{{ php_version }}\\n  - telnet\\n  - wget\\n  state: present\\nnotify: Start web server\\n'},\n",
       " {'text': 'name: Download wordpress\\n \\n \\nwhen: ansible_facts[\\'distribution\\'] == \"Amazon\"\\nansible.builtin.get_url:\\n  url: https://wordpress.org/wordpress-{{ wordpress_version }}.tar.gz\\n  dest: /tmp/\\n'},\n",
       " {'text': 'name: Extract wordpress.tgz into /tmp\\n \\n \\nwhen: ansible_facts[\\'distribution\\'] == \"Amazon\"\\nansible.builtin.unarchive:\\n  src: /tmp/wordpress-{{ wordpress_version }}.tar.gz\\n  dest: /tmp/\\n  remote_src: true\\n'},\n",
       " {'text': 'name: Host Wordpress\\n \\n \\nwhen: ansible_facts[\\'distribution\\'] == \"Amazon\"\\nshell: cp -r /tmp/wordpress/* /var/www/html/\\nignore_errors: true\\n'},\n",
       " {'text': 'name: Install webserver and tools on amazon\\n \\n \\nwhen:\\n- ansible_facts[\\'distribution\\'] == \"Amazon\"\\n- ansible_facts[\\'distribution_version\\'] == \"2\"\\nansible.builtin.package:\\n  name: \\'{{ item }}\\'\\n  state: present\\nwith_items:\\n- httpd\\n- php-{{ php_version }}\\n- php-mysql-{{ php_version }}\\n- wget\\nnotify: Amazon-Webserver\\n'},\n",
       " {'text': 'name: Download wordpress\\n \\n \\nwhen:\\n- ansible_facts[\\'distribution\\'] == \"Amazon\"\\n- ansible_facts[\\'distribution_version\\'] == \"2\"\\nget_url:\\n  url: https://wordpress.org/wordpress-{{ wordpress_version }}.tar.gz\\n  dest: /tmp/wordpress-{{ wordpress_version }}.tar.gz\\n  mode: \\'0440\\'\\n'},\n",
       " {'text': 'name: Extract wordpress\\n \\n \\nwhen:\\n- ansible_facts[\\'distribution\\'] == \"Amazon\"\\n- ansible_facts[\\'distribution_version\\'] == \"2\"\\nansible.builtin.unarchive:\\n  src: /tmp/wordpress-{{ wordpress_version }}.tar.gz\\n  dest: /tmp/\\n  remote_src: true\\n'},\n",
       " {'text': 'name: Host Wordpress\\n \\n \\nwhen:\\n- ansible_facts[\\'distribution\\'] == \"Amazon\"\\n- ansible_facts[\\'distribution_version\\'] == \"2\"\\nshell: cp -rf /tmp/wordpress/* /var/www/html/\\nignore_errors: true\\n'},\n",
       " {'text': 'name: Install webserver on ubuntu\\n \\n \\nwhen:\\n- ansible_facts[\\'distribution\\'] == \"Ubuntu\"\\n- ansible_facts[\\'distribution_version\\'] == \"16.04\"\\nansible.builtin.package:\\n  name: apache2\\n  state: present\\nnotify: Ubuntu-Webserver\\n'},\n",
       " {'text': 'name: Repository for Docker for [RedHat/CentOS/Fedora]\\n \\n \\nyum_repository:\\n  name: docker\\n  description: Docker Repo\\n  baseurl: https://download.docker.com/linux/centos/7/x86_64/stable\\n  gpgcheck: false\\nwhen: ansible_facts[\\'distribution\\'] == \"RedHat\" or ansible_facts[\\'distribution\\'] ==\\n  \"CentOS\" or  ansible_facts[\\'distribution\\'] == \"Fedora\"\\n'},\n",
       " {'text': 'name: Adding the GPG key for the official Docker Repository for [Debian/Ubuntu]\\n \\n \\nshell: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -\\nwhen: ansible_facts[\\'distribution\\'] == \"Debian\" or ansible_facts[\\'distribution\\'] ==\\n  \"Ubuntu\"\\n'},\n",
       " {'text': 'name: Add specified repository into sources list using specified filename for [Debian/Ubuntu]\\n \\n \\napt_repository:\\n  repo: deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\\n  state: present\\n  filename: docker\\nwhen: ansible_facts[\\'distribution\\'] == \"Debian\" or ansible_facts[\\'distribution\\'] ==\\n  \"Ubuntu\"\\n'},\n",
       " {'text': 'name: Installing containerd.io in [RedHat/CentOS/Fedora]\\n \\n \\npackage:\\n  name: https://download.docker.com/linux/centos/7/x86_64/stable/Packages/containerd.io-1.4.3-3.1.el7.x86_64.rpm\\n  state: present\\n  disable_gpg_check: true\\nwhen: ansible_facts[\\'distribution\\'] == \"RedHat\" or ansible_facts[\\'distribution\\'] ==\\n  \"CentOS\"   or  ansible_facts[\\'distribution\\'] == \"Fedora\"\\n'},\n",
       " {'text': 'name: Installing docker\\n \\n \\npackage:\\n  name: docker-ce\\n  state: present\\nwhen: ansible_facts[\\'distribution\\'] != \"Amazon\"\\n'},\n",
       " {'text': 'name: Installing docker in Amazon linux\\n \\n \\npackage:\\n  name: docker\\n  state: present\\nwhen: ansible_facts[\\'distribution\\'] == \"Amazon\"\\n'},\n",
       " {'text': 'name: Starting Docker Service\\n \\n \\nservice:\\n  name: docker\\n  state: started\\n  enabled: true\\n'},\n",
       " {'text': 'name: Configure Docker Driver as systemd\\n \\n \\ntemplate:\\n  dest: /etc/docker/daemon.json\\n  src: daemon.json\\n'},\n",
       " {'text': 'name: Restarting Docker Sevice\\n \\n \\nservice:\\n  name: docker\\n  state: restarted\\n  enabled: true\\n'},\n",
       " {'text': 'name: Configure Repository For Kubernetes for[Redhat/CentOS/Fedora]\\n \\n \\nyum_repository:\\n  name: kubernetes\\n  description: Kubernetes\\n  baseurl: https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\\n  gpgcheck: false\\nwhen: ansible_facts[\\'distribution\\'] == \"RedHat\" or ansible_facts[\\'distribution\\'] ==\\n  \"CentOS\"  or   ansible_facts[\\'distribution\\'] == \"Fedora\"  or  ansible_facts[\\'distribution\\']\\n  == \"Amazon\"\\n'},\n",
       " {'text': 'name: Adding the GPG key for the Kubernetes Repository for [Debian/Ubuntu]\\n \\n \\nshell: curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key\\n  add\\nwhen: ansible_facts[\\'distribution\\'] == \"Debian\" or ansible_facts[\\'distribution\\'] ==\\n  \"Ubuntu\"\\n'},\n",
       " {'text': 'name: Configure apt-repo for Kubernetes for [Debian/Ubuntu]\\n \\n \\napt_repository:\\n  repo: deb http://apt.kubernetes.io/ kubernetes-xenial main\\n  state: present\\n  filename: kubernetes\\nwhen: ansible_facts[\\'distribution\\'] == \"Debian\" or ansible_facts[\\'distribution\\'] ==\\n  \"Ubuntu\"\\n'},\n",
       " {'text': 'name: Installing All Required Packages for K8S Cluster in [Redhat/CentOS/Fedora]\\n \\n \\npackage:\\n  name: \\'{{ item }}\\'\\n  state: present\\nloop:\\n- kubeadm\\n- kubelet\\n- kubectl\\n- iproute-tc\\nwhen: ansible_facts[\\'distribution\\'] == \"RedHat\" or ansible_facts[\\'distribution\\'] ==\\n  \"CentOS\"  or  ansible_facts[\\'distribution\\'] == \"Fedora\"  or   ansible_facts[\\'distribution\\']\\n  == \"Amazon\"\\n'},\n",
       " {'text': 'name: Installing All Required Packages for K8S Cluster in [Debian/Ubuntu]\\n \\n \\npackage:\\n  name: \\'{{ item }}\\'\\n  state: present\\nloop:\\n- kubeadm\\n- kubelet\\n- kubectl\\n- iproute2\\nwhen: ansible_facts[\\'distribution\\'] == \"Debian\" or ansible_facts[\\'distribution\\'] ==\\n  \"Ubuntu\"\\n'},\n",
       " {'text': 'name: Starting and Enabling kubelet Service\\n \\n \\nservice:\\n  name: kubelet\\n  state: started\\n  enabled: true\\n'},\n",
       " {'text': 'name: Installing Docker\\n \\n \\ninclude_tasks: docker.yml\\n'},\n",
       " {'text': 'name: Configure kubernetes Repo and Install Required Softwares for Cluster\\n \\n \\ninclude_tasks: kubernetes.yml\\n'},\n",
       " {'text': 'name: Pulling Required Docker Images\\n \\n \\nshell: kubeadm config images pull\\n'},\n",
       " {'text': 'name: Configuring The Network\\n \\n \\ntemplate:\\n  dest: /etc/sysctl.d/k8s.conf\\n  src: k8s.conf\\n'},\n",
       " {'text': 'name: Starting sysctl service\\n \\n \\nshell: sysctl --system\\n'},\n",
       " {'text': 'name: Check If kubeadm Has Already Run or Not\\n \\n \\nstat:\\n  path: /etc/kubernetes/pki/ca.key\\nregister: kubeadm_check\\nignore_errors: true\\n'},\n",
       " {'text': 'name: Initializing kubeadm and ignoring RAM and CPU errors\\n \\n \\nshell: kubeadm init --pod-network-cidr=10.244.0.0/16 --ignore-preflight-errors=NumCPU\\n  --ignore-preflight-errors=Mem\\nwhen: not kubeadm_check.stat.exists\\n'},\n",
       " {'text': 'name: Create Kubernetes config directory\\n \\n \\nfile:\\n  path: $HOME/.kube/\\n  state: directory\\n'},\n",
       " {'text': \"name: Copy admin.conf to Home directory and changing the Ownership\\n \\n \\ncopy:\\n  dest: $HOME/.kube/config\\n  src: /etc/kubernetes/admin.conf\\n  owner: '{{ ansible_user | default(ansible_user_id) }}'\\n  group: '{{ ansible_user | default(ansible_user_id) }}'\\n  mode: 493\\n  remote_src: true\\n\"},\n",
       " {'text': 'name: Setting up Overlay Network Using Flannel\\n \\n \\nshell: kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\\n'},\n",
       " {'text': 'name: Repository for Docker for [RedHat/CentOS/Fedora]\\n \\n \\nyum_repository:\\n  name: docker\\n  description: Docker Repo\\n  baseurl: https://download.docker.com/linux/centos/7/x86_64/stable\\n  gpgcheck: false\\nwhen: ansible_facts[\\'distribution\\'] == \"RedHat\" or ansible_facts[\\'distribution\\'] ==\\n  \"CentOS\" or  ansible_facts[\\'distribution\\'] == \"Fedora\"\\n'},\n",
       " {'text': 'name: Adding the GPG key for the official Docker Repository for [Debian/Ubuntu]\\n \\n \\nshell: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -\\nwhen: ansible_facts[\\'distribution\\'] == \"Debian\" or ansible_facts[\\'distribution\\'] ==\\n  \"Ubuntu\"\\n'},\n",
       " {'text': 'name: Add specified repository into sources list using specified filename for [Debian/Ubuntu]\\n \\n \\napt_repository:\\n  repo: deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\\n  state: present\\n  filename: docker\\nwhen: ansible_facts[\\'distribution\\'] == \"Debian\" or ansible_facts[\\'distribution\\'] ==\\n  \"Ubuntu\"\\n'},\n",
       " {'text': 'name: Installing containerd.io in [RedHat/CentOS/Fedora]\\n \\n \\npackage:\\n  name: https://download.docker.com/linux/centos/7/x86_64/stable/Packages/containerd.io-1.4.3-3.1.el7.x86_64.rpm\\n  state: present\\n  disable_gpg_check: true\\nwhen: ansible_facts[\\'distribution\\'] == \"RedHat\" or ansible_facts[\\'distribution\\'] ==\\n  \"CentOS\"   or  ansible_facts[\\'distribution\\'] == \"Fedora\"\\n'},\n",
       " {'text': 'name: Installing docker\\n \\n \\npackage:\\n  name: docker-ce\\n  state: present\\nwhen: ansible_facts[\\'distribution\\'] != \"Amazon\"\\n'},\n",
       " {'text': 'name: Installing docker in Amazon linux\\n \\n \\npackage:\\n  name: docker\\n  state: present\\nwhen: ansible_facts[\\'distribution\\'] == \"Amazon\"\\n'},\n",
       " {'text': 'name: Starting Docker Service\\n \\n \\nservice:\\n  name: docker\\n  state: started\\n  enabled: true\\n'},\n",
       " {'text': 'name: Configure Docker Driver as systemd\\n \\n \\ntemplate:\\n  dest: /etc/docker/daemon.json\\n  src: daemon.json\\n'},\n",
       " {'text': 'name: Restarting Docker Sevice\\n \\n \\nservice:\\n  name: docker\\n  state: restarted\\n  enabled: true\\n'},\n",
       " {'text': 'name: Configure Repository For Kubernetes for[Redhat/CentOS/Fedora]\\n \\n \\nyum_repository:\\n  name: kubernetes\\n  description: Kubernetes\\n  baseurl: https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\\n  gpgcheck: false\\nwhen: ansible_facts[\\'distribution\\'] == \"RedHat\" or ansible_facts[\\'distribution\\'] ==\\n  \"CentOS\"  or   ansible_facts[\\'distribution\\'] == \"Fedora\"  or  ansible_facts[\\'distribution\\']\\n  == \"Amazon\"\\n'},\n",
       " {'text': 'name: Adding the GPG key for the Kubernetes Repository for [Debian/Ubuntu]\\n \\n \\nshell: curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key\\n  add\\nwhen: ansible_facts[\\'distribution\\'] == \"Debian\" or ansible_facts[\\'distribution\\'] ==\\n  \"Ubuntu\"\\n'},\n",
       " {'text': 'name: Configure apt-repo for Kubernetes for [Debian/Ubuntu]\\n \\n \\napt_repository:\\n  repo: deb http://apt.kubernetes.io/ kubernetes-xenial main\\n  state: present\\n  filename: kubernetes\\nwhen: ansible_facts[\\'distribution\\'] == \"Debian\" or ansible_facts[\\'distribution\\'] ==\\n  \"Ubuntu\"\\n'},\n",
       " {'text': 'name: Installing All Required Packages for K8S Cluster in [Redhat/CentOS/Fedora]\\n \\n \\npackage:\\n  name: \\'{{ item }}\\'\\n  state: present\\nloop:\\n- kubeadm\\n- kubelet\\n- kubectl\\n- iproute-tc\\nwhen: ansible_facts[\\'distribution\\'] == \"RedHat\" or ansible_facts[\\'distribution\\'] ==\\n  \"CentOS\"  or  ansible_facts[\\'distribution\\'] == \"Fedora\"  or   ansible_facts[\\'distribution\\']\\n  == \"Amazon\"\\n'},\n",
       " {'text': 'name: Installing All Required Packages for K8S Cluster in [Debian/Ubuntu]\\n \\n \\npackage:\\n  name: \\'{{ item }}\\'\\n  state: present\\nloop:\\n- kubeadm\\n- kubelet\\n- kubectl\\n- iproute2\\nwhen: ansible_facts[\\'distribution\\'] == \"Debian\" or ansible_facts[\\'distribution\\'] ==\\n  \"Ubuntu\"\\n'},\n",
       " {'text': 'name: Starting and Enabling kubelet Service\\n \\n \\nservice:\\n  name: kubelet\\n  state: started\\n  enabled: true\\n'},\n",
       " {'text': 'name: Installing Docker\\n \\n \\ninclude_tasks: docker.yml\\n'},\n",
       " {'text': 'name: Configure Kubernetes Repo and Install Required Softwares For Cluster\\n \\n \\ninclude_tasks: kubernetes.yml\\n'},\n",
       " {'text': 'name: Configuring The Network\\n \\n \\ntemplate:\\n  dest: /etc/sysctl.d/k8s.conf\\n  src: k8s.conf\\n'},\n",
       " {'text': 'name: Starting sysctl service\\n \\n \\nshell: sysctl --system\\n'},\n",
       " {'text': \"name: printing join command\\n \\n \\ncommand: kubeadm token create --print-join-command\\nregister: x\\nwhen: inventory_hostname in groups['tag_name_k8s_master']\\n\"},\n",
       " {'text': \"name: joining the worker node\\n \\n \\ncommand: '{{ hostvars[item][''x''][''stdout''] }}'\\nwith_items: '{{ groups[''tag_name_k8s_master''] }}'\\nwhen:\\n- inventory_hostname in groups['tag_name_k8s_worker']\\n- not check.stat.exists\\n\"},\n",
       " {'text': \"name: launching master instance over the aws\\n \\n \\nec2:\\n  region: us-east-1\\n  image: ami-03219e2002a236fb5\\n  instance_type: t2.micro\\n  assign_public_ip: true\\n  vpc_subnet_id: subnet-05a6421b137ef40bd\\n  group: mysecuritygroup\\n  key_name: mykeyaws\\n  instance_tags:\\n    name: hadoop_master\\n  state: present\\n  aws_access_key: '{{ access_key }}'\\n  aws_secret_key: '{{ secret_key }}'\\n\"},\n",
       " {'text': \"name: launching 2 worker nodes over the aws\\n \\n \\nec2:\\n  region: us-east-1\\n  image: ami-03219e2002a236fb5\\n  instance_type: t2.micro\\n  assign_public_ip: true\\n  vpc_subnet_id: subnet-05a6421b137ef40bd\\n  group: mysecuritygroup\\n  key_name: mykeyaws\\n  instance_tags:\\n    name: hadoop_worker\\n  state: present\\n  count: 2\\n  aws_access_key: '{{ access_key }}'\\n  aws_secret_key: '{{ secret_key }}'\\n\"},\n",
       " {'text': \"name: launching jobtracker instance over the aws\\n \\n \\nec2:\\n  region: us-east-1\\n  image: ami-03219e2002a236fb5\\n  instance_type: t2.micro\\n  assign_public_ip: true\\n  vpc_subnet_id: subnet-05a6421b137ef40bd\\n  group: mysecuritygroup\\n  key_name: mykeyaws\\n  instance_tags:\\n    name: jobtracker\\n  state: present\\n  aws_access_key: '{{ access_key }}'\\n  aws_secret_key: '{{ secret_key }}'\\n\"},\n",
       " {'text': \"name: launching 2 tasktracker nodes over the aws\\n \\n \\nec2:\\n  region: us-east-1\\n  image: ami-03219e2002a236fb5\\n  instance_type: t2.micro\\n  assign_public_ip: true\\n  vpc_subnet_id: subnet-05a6421b137ef40bd\\n  group: mysecuritygroup\\n  key_name: mykeyaws\\n  instance_tags:\\n    name: tasktracker\\n  state: present\\n  count: 2\\n  aws_access_key: '{{ access_key }}'\\n  aws_secret_key: '{{ secret_key }}'\\n\"},\n",
       " {'text': \"name: launching client\\n \\n \\nec2:\\n  region: us-east-1\\n  image: ami-03219e2002a236fb5\\n  instance_type: t2.micro\\n  assign_public_ip: true\\n  vpc_subnet_id: subnet-05a6421b137ef40bd\\n  group: mysecuritygroup\\n  key_name: mykeyaws\\n  instance_tags:\\n    name: client\\n  state: present\\n  count: 1\\n  aws_access_key: '{{ access_key }}'\\n  aws_secret_key: '{{ secret_key }}'\\n\"},\n",
       " {'text': 'name: check | Initialize\\n \\n \\nset_fact:\\n  scale_obj_nodes_list: []\\n'},\n",
       " {'text': 'name: check | Check if object is enabled\\n \\n \\nassert:\\n  that:\\n  - scale_protocols.object|bool\\n  fail_msg: OBJECT is not enabled\\nrun_once: true\\n'},\n",
       " {'text': \"name: check | Collect all object nodes\\n \\n \\nset_fact:\\n  scale_obj_nodes_list: '{{ scale_obj_nodes_list + [hostvars[item][''ansible_fqdn'']]\\n    }}'\\nwhen: hostvars[item]['is_protocol_node'] is defined and hostvars[item]['is_protocol_node']|bool\\nwith_items:\\n- '{{ ansible_play_hosts }}'\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': 'name: check | Check if at least one obj node is configured\\n \\n \\nassert:\\n  that:\\n  - scale_obj_nodes_list|length > 0\\n  fail_msg: No object nodes configured\\n'},\n",
       " {'text': \"name: check | Check for supported operating system\\n \\n \\nassert:\\n  that:\\n  - hostvars[item]['ansible_distribution'] in scale_rhel_distribution\\n  - hostvars[item]['ansible_distribution_major_version'] == '8'\\n  msg: Object is only supported for Rhel 8 and higher!\\nwith_items:\\n- '{{ ansible_play_hosts }}'\\nwhen: hostvars[item]['is_protocol_node'] is defined and hostvars[item]['is_protocol_node']|bool\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': 'name: check | Set default\\n \\n \\nset_fact:\\n  scale_ces_dynamic_obj: false\\nwhen: scale_ces_dynamic_obj is undefined\\n'},\n",
       " {'text': 'name: check | Check enable_s3 is define\\n \\n \\nassert:\\n  that:\\n  - scale_ces_obj.enable_s3 is defined\\n  fail_msg: scale_ces_obj.enable_s3 is not defined as True or False.\\nrun_once: true\\n'},\n",
       " {'text': 'name: check | Check local_keystone is define\\n \\n \\nassert:\\n  that:\\n  - scale_ces_obj.local_keystone is defined\\n  fail_msg: scale_ces_obj.local_keystone is not defined as True or False.\\nrun_once: true\\n'},\n",
       " {'text': 'name: check | Check enable_file_access is define\\n \\n \\nassert:\\n  that:\\n  - scale_ces_obj.enable_file_access is defined\\n  fail_msg: scale_ces_obj.enable_file_access is not defined as True or False.\\nrun_once: true\\n'},\n",
       " {'text': 'name: check | Check endpoint_hostname is define\\n \\n \\nassert:\\n  that:\\n  - scale_ces_obj.endpoint_hostname is defined\\n  - scale_ces_obj.endpoint_hostname|length >0\\n  fail_msg: scale_ces_obj.endpoint_hostname is not defined or empty.\\nrun_once: true\\n'},\n",
       " {'text': 'name: check | Check object_fileset is define\\n \\n \\nassert:\\n  that:\\n  - scale_ces_obj.object_fileset is defined\\n  - scale_ces_obj.object_fileset|length >0\\n  fail_msg: scale_ces_obj.object_fileset is not defined or empty.\\nrun_once: true\\n'},\n",
       " {'text': 'name: check | Check admin_user is define\\n \\n \\nassert:\\n  that:\\n  - scale_ces_obj.admin_user is defined\\n  - scale_ces_obj.admin_user|length >0\\n  fail_msg: scale_ces_obj.admin_user is not defined or empty.\\nrun_once: true\\n'},\n",
       " {'text': 'name: check | Check admin_pwd is define\\n \\n \\nassert:\\n  that:\\n  - scale_ces_obj.admin_pwd is defined\\n  - scale_ces_obj.admin_pwd|length >0\\n  fail_msg: scale_ces_obj.admin_pwd is not defined or empty.\\nrun_once: true\\n'},\n",
       " {'text': 'name: check | Check database_pwd is define\\n \\n \\nassert:\\n  that:\\n  - scale_ces_obj.database_pwd is defined\\n  - scale_ces_obj.database_pwd|length >0\\n  fail_msg: scale_ces_obj.database_pwd is not defined or empty.\\nrun_once: true\\n'},\n",
       " {'text': 'name: check | Check filesystem is define\\n \\n \\nassert:\\n  that:\\n  - scale_protocols.filesystem is defined\\n  - scale_protocols.filesystem|length >0\\n  fail_msg: scale_protocols.filesystem is not defined or empty.\\nrun_once: true\\n'},\n",
       " {'text': 'name: check | Check mountpoint is define\\n \\n \\nassert:\\n  that:\\n  - scale_protocols.mountpoint is defined\\n  - scale_protocols.mountpoint|length >0\\n  fail_msg: scale_protocols.mountpoint is not defined or empty.\\nrun_once: true\\n'},\n",
       " {'text': 'name: check | Initialize\\n \\n \\nset_fact:\\n  scale_ece_nodes_list: []\\n'},\n",
       " {'text': \"name: check | Collect all ece nodes\\n \\n \\nset_fact:\\n  scale_ece_nodes_list: '{{ scale_ece_nodes_list + [hostvars[item][''inventory_hostname'']]\\n    }}'\\nwhen: hostvars[item]['scale_out_node'] is defined and hostvars[item]['scale_out_node']|bool\\nwith_items:\\n- '{{ ansible_play_hosts }}'\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': 'name: check | Check if number of ece node is greater than or equal to 4\\n \\n \\nassert:\\n  that:\\n  - scale_ece_nodes_list|length >= 4\\n  fail_msg: Number of ece nodes is less than 4\\nrun_once: true\\n'},\n",
       " {'text': \"name: check | Check if ece node is not protocol node\\n \\n \\nassert:\\n  that:\\n  - not hostvars[item]['is_protocol_node']|bool\\n  fail_msg: ECE node cannot be protocol node\\nwhen: hostvars[item]['is_protocol_node'] is defined\\nwith_items:\\n- '{{ scale_ece_nodes_list }}'\\nrun_once: true\\nany_errors_fatal: true\\n\"},\n",
       " {'text': \"name: check | Check if ece node is not gui node\\n \\n \\nassert:\\n  that:\\n  - not hostvars[item]['scale_cluster_gui']|bool\\n  fail_msg: ECE node cannot be gui node\\nwhen: hostvars[item]['scale_cluster_gui'] is defined\\nwith_items:\\n- '{{ scale_ece_nodes_list }}'\\nrun_once: true\\nany_errors_fatal: true\\n\"},\n",
       " {'text': \"name: check | Check if ece node is not nsd node\\n \\n \\nassert:\\n  that:\\n  - not hostvars[item]['is_nsd_server']|bool\\n  fail_msg: ECE node cannot be nsd server\\nwhen: hostvars[item]['is_nsd_server'] is defined\\nwith_items:\\n- '{{ scale_ece_nodes_list }}'\\nrun_once: true\\nany_errors_fatal: true\\n\"},\n",
       " {'text': 'name: check | Initialize\\n \\n \\nset_fact:\\n  scale_smb_node_list: []\\n'},\n",
       " {'text': \"name: check | Collect all smb nodes\\n \\n \\nset_fact:\\n  scale_smb_node_list: '{{ scale_smb_node_list + [hostvars[item][''ansible_fqdn'']]\\n    }}'\\nwhen: hostvars[item]['is_protocol_node'] is defined and hostvars[item]['is_protocol_node']|bool\\nwith_items:\\n- '{{ ansible_play_hosts }}'\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': 'name: check | Check if atleast one smb node is configured\\n \\n \\nassert:\\n  that:\\n  - scale_smb_node_list|length > 0\\n  fail_msg: No smb nodes configured\\n'},\n",
       " {'text': 'name: check | Check if nfs or smb is enabled\\n \\n \\nassert:\\n  that:\\n  - scale_protocols.smb|bool or scale_protocols.nfs|bool\\n  fail_msg: SMB and NFS is not enabled\\nrun_once: true\\n'},\n",
       " {'text': 'name: check | Check if service smb is running\\n \\n \\nassert:\\n  that:\\n  - ansible_facts.services[\"smb\"].state != \"running\"\\n  fail_msg: Service smb found running on {{ ansible_hostname }}. Which conflicts with\\n    the installation of SMB.SUGGESTTED ACTION- Run commands to stop (systemctl stop\\n    smb) and disable (systemctl disable smb) this service on node {{ ansible_hostname\\n    }}\\nwhen: ansible_fqdn in scale_smb_node_list and ansible_facts.services[\"smb\"].state\\n  is defined\\nany_errors_fatal: true\\n'},\n",
       " {'text': 'name: check | Check if service smbd is running\\n \\n \\nassert:\\n  that:\\n  - ansible_facts.services[\"smbd\"].state != \"running\"\\n  fail_msg: Service smbd found running on {{ ansible_hostname }}. Which conflicts\\n    with the installation of SMB.SUGGESTTED ACTION- Run commands to stop (systemctl\\n    stop smbd) and disable (systemctl disable smbd) this service on node {{ ansible_hostname\\n    }}\\nwhen: ansible_fqdn in scale_smb_node_list and ansible_facts.services[\"smbd\"].state\\n  is defined\\nany_errors_fatal: true\\n'},\n",
       " {'text': 'name: check | Check if service winbind is running\\n \\n \\nassert:\\n  that:\\n  - ansible_facts.services[\"winbind\"].state != \"running\"\\n  fail_msg: Service smb found running on {{ ansible_hostname }}. Which conflicts with\\n    the installation of SMB.SUGGESTTED ACTION- Run commands to stop (systemctl stop\\n    winbind) and disable (systemctl disable winbind) this service on node {{ ansible_hostname\\n    }}\\nwhen: ansible_fqdn in scale_smb_node_list and ansible_facts.services[\"winbind\"].state\\n  is defined\\nany_errors_fatal: true\\n'},\n",
       " {'text': 'name: check | Check if service winbindd is running\\n \\n \\nassert:\\n  that:\\n  - ansible_facts.services[\"winbindd\"].state != \"running\"\\n  fail_msg: Service winbindd found running on {{ ansible_hostname }}. Which conflicts\\n    with the installation of SMB.SUGGESTTED ACTION- Run commands to stop (systemctl\\n    stop winbindd) and disable (systemctl disable winbindd) this service on node {{\\n    ansible_hostname }}\\nwhen: ansible_fqdn in scale_smb_node_list and ansible_facts.services[\"winbindd\"].state\\n  is defined\\nany_errors_fatal: true\\n'},\n",
       " {'text': 'name: check | Check if service ctdb is running\\n \\n \\nassert:\\n  that:\\n  - ansible_facts.services[\"ctdb\"].state != \"running\"\\n  fail_msg: Service ctdb found running on {{ ansible_hostname }}. Which conflicts\\n    with the installation of SMB.SUGGESTTED ACTION- Run commands to stop (systemctl\\n    stop ctdb) and disable (systemctl disable ctdb) this service on node {{ ansible_hostname\\n    }}\\nwhen: ansible_fqdn in scale_smb_node_list and ansible_facts.services[\"ctdb\"].state\\n  is defined\\nany_errors_fatal: true\\n'},\n",
       " {'text': 'name: check | Check if service ctdbd is running\\n \\n \\nassert:\\n  that:\\n  - ansible_facts.services[\"ctdbd\"].state != \"running\"\\n  fail_msg: Service ctdbd found running on {{ ansible_hostname }}. Which conflicts\\n    with the installation of SMB.SUGGESTTED ACTION- Run commands to stop (systemctl\\n    stop ctdbd) and disable (systemctl disable ctdbd) this service on node {{ ansible_hostname\\n    }}\\nwhen: ansible_fqdn in scale_smb_node_list and ansible_facts.services[\"ctdbd\"].state\\n  is defined\\nany_errors_fatal: true\\n'},\n",
       " {'text': \"name: install| Creates default directory\\n \\n \\nfile:\\n  path: '{{ scale_extracted_path }}'\\n  state: directory\\n  mode: a+x\\n  recurse: true\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path | basename\\n    }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: upgrade | Extract installation package\\n \\n \\nset_fact:\\n  dir_path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path |\\n    basename }}'\\n\"},\n",
       " {'text': \"name: upgrade | gpfs base path\\n \\n \\nset_fact:\\n  gpfs_path_url: '{{ dir_path }}'\\nwhen: scale_install_directory_pkg_path is defined\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: upgrade | Extract installation package\\n \\n \\nvars:\\n  localpkg: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\ncommand: '{{ localpkg + '' --silent'' }}'\\nargs:\\n  creates: '{{ scale_gpfs_path_url }}'\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: upgrade | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_packagedir.stat.exists\\n  - scale_install_gpfs_packagedir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the local\\n    installation package!\\n\"},\n",
       " {'text': \"name: upgrade | Delete installation package from node\\n \\n \\nfile:\\n  path: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\n  state: absent\\n\"},\n",
       " {'text': 'name: upgrade | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/rhel/\\nwhen: ansible_distribution in scale_rhel_distribution\\n'},\n",
       " {'text': 'name: upgrade | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution\\n'},\n",
       " {'text': 'name: upgrade | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/rhel/\\nwhen: ansible_distribution in scale_sles_distribution\\n'},\n",
       " {'text': 'name: upgrade | Initialize list of packages\\n \\n \\nset_fact:\\n  scale_install_all_packages: []\\n'},\n",
       " {'text': \"name: upgrade | Initialize\\n \\n \\nset_fact:\\n  scale_fal_url: ''\\n  scale_kafaka_url: ''\\n  package_installed: false\\n\"},\n",
       " {'text': 'name: upgrade | file audit logging path\\n \\n \\nset_fact:\\n  scale_kafaka_url: gpfs_rpms/rhel/\\nwhen: ansible_distribution in scale_rhel_distribution\\n'},\n",
       " {'text': \"name: install | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/rhel7/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '7'\\n\"},\n",
       " {'text': \"name: install | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/rhel8/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '8'\\n\"},\n",
       " {'text': 'name: upgrade | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution\\n'},\n",
       " {'text': 'name: upgrade | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/sles15/\\nwhen: ansible_distribution in scale_sles_distribution\\n'},\n",
       " {'text': \"name: upgrade | Configure GPFS Java YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-gpfs-java\\n  description: IBM Spectrum Scale (GPFS Java)\\n  baseurl: '{{ scale_install_repository_url }}gpfs_rpms/'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: upgrade | Configure GPFS Java APT repository\\n \\n \\napt_repository:\\n  filename: spectrum-scale-gpfs-java-debs\\n  repo: deb [trusted=yes] {{ scale_install_repository_url }}gpfs_debs/ ./\\n  validate_certs: false\\n  state: present\\n  update_cache: true\\n  codename: IBM Spectrum Scale (gpfs java debs)\\n  mode: 511\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: upgrade | Configure GPFS Java repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-gpfs-java\\n  description: IBM Spectrum Scale (GPFS java)\\n  repo: '{{ scale_install_repository_url }}gpfs_rpms/'\\n  disable_gpg_check: true\\n  state: present\\n  overwrite_multiple: true\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: upgrade | Configure fal YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-fal\\n  description: IBM Spectrum Scale (FAL)\\n  baseurl: '{{ scale_install_repository_url }}{{ scale_fal_url }}'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: upgrade | Configure fal APT repository\\n \\n \\napt_repository:\\n  filename: spectrum-scale-fal-debs\\n  repo: deb [trusted=yes] {{ scale_install_repository_url }}{{ scale_fal_url }} ./\\n  validate_certs: false\\n  state: present\\n  update_cache: true\\n  codename: IBM Spectrum Scale (FAL debs)\\n  mode: 511\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: upgrade | Configure fal repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-fal-sles\\n  description: IBM Spectrum Scale (FAL)\\n  repo: '{{ scale_install_repository_url }}{{ scale_fal_url }}'\\n  disable_gpg_check: false\\n  state: present\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS file audit logging packages to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_auditlogging_packages }}'\\nwhen: (scale_fileauditlogging_enable | bool)\\n\"},\n",
       " {'text': \"name: upgrade | Stat remote installation package\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  checksum_algorithm: md5\\nregister: scale_install_remotepkg\\n\"},\n",
       " {'text': \"name: upgrade | Check remote installation package\\n \\n \\nassert:\\n  that: scale_install_remotepkg.stat.exists\\n  msg: Please set the variable 'scale_install_remotepkg_path' to point to the remote\\n    installation package (accessible on Ansible managed node)!\\n\"},\n",
       " {'text': \"name: upgrade | Stat checksum file\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}.md5'\\nregister: scale_install_md5_file\\n\"},\n",
       " {'text': 'name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: /usr/lpp/mmfs/{{ scale_version }}/gpfs_rpms\\nregister: scale_install_gpfs_rpmdir\\n'},\n",
       " {'text': \"name: upgrade | Make installation package executable\\n \\n \\nfile:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  mode: a+x\\nwhen: not scale_install_gpfs_rpmdir.stat.exists\\n\"},\n",
       " {'text': \"name: upgrade | Extract installation package\\n \\n \\ncommand: '{{ scale_install_remotepkg_path + '' --silent'' }}'\\nargs:\\n  creates: /usr/lpp/mmfs/{{ scale_version }}/gpfs_rpms\\n\"},\n",
       " {'text': 'name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: /usr/lpp/mmfs/{{ scale_version }}/gpfs_rpms\\nregister: scale_install_gpfs_rpmdir\\n'},\n",
       " {'text': \"name: upgrade | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the remote\\n    installation package!\\n\"},\n",
       " {'text': 'name: upgrade | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/rhel/\\nwhen: ansible_distribution in scale_rhel_distribution\\n'},\n",
       " {'text': 'name: upgrade | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution\\n'},\n",
       " {'text': 'name: upgrade | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/rhel/\\nwhen: ansible_distribution in scale_sles_distribution\\n'},\n",
       " {'text': \"name: upgrade | Upgrade GPFS file audit logging packages\\n \\n \\nyum:\\n  name: '{{ scale_install_all_packages }}'\\n  state: latest\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\nwhen:\\n- ansible_pkg_mgr == 'yum'\\n- librdkafka_installed is not defined\\n\"},\n",
       " {'text': \"name: upgrade | Upgrade GPFS file audit logging packages\\n \\n \\nyum:\\n  name: '{{ scale_install_all_packages }}'\\n  state: latest\\n  update_only: true\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\nwhen:\\n- ansible_pkg_mgr == 'yum'\\n- librdkafka_installed is defined and librdkafka_installed | bool\\n\"},\n",
       " {'text': \"name: upgrade | Upgrade GPFS file audit logging packages\\n \\n \\ndnf:\\n  name: '{{ scale_install_all_packages }}'\\n  state: latest\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\nwhen: ansible_pkg_mgr == 'dnf'\\n\"},\n",
       " {'text': \"name: postcheck | Check if SMB is running\\n \\n \\nshell:\\n  cmd: '{{ scale_command_path }}mmces service list|grep SMB'\\nregister: scale_smb_status\\nwhen: ansible_fqdn in scale_smb_node_list\\nignore_errors: true\\nfailed_when: false\\n\"},\n",
       " {'text': 'name: postcheck | Check if SMB is running\\n \\n \\nassert:\\n  that:\\n  - scale_smb_status.rc == 0\\n  fail_msg: SMB is not active on {{ ansible_hostname }}\\nwhen: ansible_fqdn in scale_smb_node_list\\n'},\n",
       " {'text': \"name: postcheck | Check if OBJ is running\\n \\n \\nshell:\\n  cmd: '{{ scale_command_path }}mmces service list|grep OBJ'\\nregister: scale_obj_status\\nwhen: ansible_fqdn in scale_obj_nodes_list\\nfailed_when: false\\n\"},\n",
       " {'text': 'name: postcheck | Check if OBJ is running\\n \\n \\nassert:\\n  that:\\n  - scale_obj_status.rc == 0\\n  fail_msg: OBJ is not active on {{ ansible_hostname }}\\nwhen: ansible_fqdn in scale_obj_nodes_list\\n'},\n",
       " {'text': 'name: check | Initialize\\n \\n \\nset_fact:\\n  scale_nfs_nodes_list: []\\n'},\n",
       " {'text': 'name: check | Check if nfs or smb is enabled\\n \\n \\nassert:\\n  that:\\n  - scale_protocols.nfs|bool or scale_protocols.smb|bool\\n  fail_msg: NFS and SMB is not enabled\\n'},\n",
       " {'text': \"name: check | Collect all nfs nodes\\n \\n \\nset_fact:\\n  scale_nfs_nodes_list: '{{ scale_nfs_nodes_list + [hostvars[item][''ansible_fqdn'']]\\n    }}'\\nwhen: hostvars[item]['is_protocol_node'] is defined and hostvars[item]['is_protocol_node']|bool\\nwith_items:\\n- '{{ ansible_play_hosts }}'\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': 'name: check | Check if atleast one nfs node is configured\\n \\n \\nassert:\\n  that:\\n  - scale_nfs_nodes_list|length > 0\\n  fail_msg: No nfs nodes configured\\n'},\n",
       " {'text': 'name: check | Collect status of native nfs\\n \\n \\nshell:\\n  cmd: systemctl status nfs-server\\nregister: scale_nfs_status\\nwhen: ansible_fqdn in scale_nfs_nodes_list\\nignore_errors: true\\nfailed_when: false\\n'},\n",
       " {'text': 'name: check | Check if native nfs is running\\n \\n \\nassert:\\n  that:\\n  - scale_nfs_status.rc > 0\\n  fail_msg: Service nfs found running on {{ ansible_hostname }}. Which conflicts with\\n    the installation of NFS. SUGGESTTED ACTION- Run commands to stop (systemctl stop\\n    nfs) and disable (systemctl disable nfs) this service on node {{ ansible_hostname\\n    }}\\nwhen: ansible_fqdn in scale_nfs_nodes_list\\nany_errors_fatal: true\\n'},\n",
       " {'text': 'name: check | Collect status of service nfs-kernel-server\\n \\n \\nshell:\\n  cmd: systemctl status nfs-kernel-server\\nregister: scale_nfs_status\\nwhen: ansible_fqdn in scale_nfs_nodes_list\\nignore_errors: true\\nfailed_when: false\\n'},\n",
       " {'text': 'name: check | Check if native nfs-kernel-server is running\\n \\n \\nassert:\\n  that:\\n  - scale_nfs_status.rc > 0\\n  fail_msg: Service nfs-kernel-server found running on {{ ansible_hostname }}. Which\\n    conflicts with the installation of NFS. SUGGESTTED ACTION Run commands to stop\\n    (systemctl stop nfs-kernel-server) and disable (systemctl disable nfs-kernel-server)\\n    this service on node {{ ansible_hostname }}\\nwhen: ansible_fqdn in scale_nfs_nodes_list\\nany_errors_fatal: true\\n'},\n",
       " {'text': 'name: check | Collect status of service knfs-server\\n \\n \\nshell:\\n  cmd: systemctl status knfs-server\\nregister: scale_nfs_status\\nwhen: ansible_fqdn in scale_nfs_nodes_list\\nignore_errors: true\\nfailed_when: false\\n'},\n",
       " {'text': 'name: check | Check if native knfs-server is running\\n \\n \\nassert:\\n  that:\\n  - scale_nfs_status.rc > 0\\n  fail_msg: Service knfs-kernel-server found running on {{ ansible_hostname }}. Which\\n    conflicts with the installation of NFS. SUGGESTTED ACTION Run commands to stop\\n    (systemctl stop knfs-server) and disable (systemctl disable knfs-server) this\\n    service on node {{ ansible_hostname }}\\nwhen: ansible_fqdn in scale_nfs_nodes_list\\nany_errors_fatal: true\\n'},\n",
       " {'text': 'name: EMAIL | Check if e-mail notifications is allready enabled\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/lsemailserver\\nregister: scale_gui_conf_email_notifications_check\\nrun_once: true\\nfailed_when: false\\nchanged_when: false\\n'},\n",
       " {'text': \"name: EMAIL | Check if e-mail notifications is allready enabled - Output\\n \\n \\nrun_once: true\\ndebug:\\n  msg: '{{ scale_gui_conf_email_notifications_check.stdout }}'\\n  verbosity: 2\\n\"},\n",
       " {'text': 'name: EMAIL | Configure E-Mail notifications\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/mkemailserver \"{{ scale_gui_email.name }}\" --address\\n  \"{{ scale_gui_email.ipaddress }}\" --port \"{{ scale_gui_email.ipport }}\" --reply\\n  \"{{ scale_gui_email.replay_email_address }}\" --contact \"{{ scale_gui_email.contact_name\\n  }}\" --subject \"{{ scale_gui_email.subject }}\"  --login \"{{ scale_gui_email.sender_login_id\\n  }}\" --password \"{{ scale_gui_email.password }}\" --header \"{{ scale_gui_email.headertext\\n  | default() }}\" --footer \"{{ scale_gui_email.footertext | default() }}\"\\nregister: scale_gui_conf_email_notifications\\nrun_once: true\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_conf_email_notifications.stdout\\'\\nignore_errors: true\\nwhen:\\n- \\' \\'\\'EFSSG0100I\\'\\' in scale_gui_conf_email_notifications_check.stdout or scale_gui_email.name\\n  not in scale_gui_conf_email_notifications_check.stdout\\'\\n'},\n",
       " {'text': \"name: EMAIL | Recipients - Check if E-mail recipients is allready created\\n \\n \\nshell: /usr/lpp/mmfs/gui/cli/lsemailuser -Y | grep -v HEADER | cut -d ':' -f 7\\nregister: scale_gui_conf_email_recipient_check\\nrun_once: true\\nfailed_when: false\\nchanged_when: false\\n\"},\n",
       " {'text': \"name: EMAIL | Recipients - Check if e-mail recipients is allready created - Output\\n \\n \\nrun_once: true\\ndebug:\\n  msg: '{{ scale_gui_conf_email_recipient_check.stdout }}'\\n  verbosity: 2\\n\"},\n",
       " {'text': 'name: EMAIL | Recipients - Add E-mail recipients\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/mkemailuser \"{{ scale_gui_email_recipients.name }}\"\\n  --address \"{{ scale_gui_email_recipients.address }}\" --components \"{{ scale_gui_email_recipients.components_security_level\\n  }}\" --reports \"{{ scale_gui_email_recipients.reports }}\" \"{{ scale_gui_email_recipients.quotaNotification\\n  }}\" --quotathreshold \"{{ scale_gui_email_recipients.quotathreshold }}\"\\nregister: scale_gui_conf_email_recipient\\nrun_once: true\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_conf_email_recipient.stdout\\'\\nignore_errors: true\\nwhen:\\n- scale_gui_email_recipients.name is defined\\n- \\'  ( scale_gui_email_recipients.name ) not in scale_gui_conf_email_recipient_check.stdout\\'\\n'},\n",
       " {'text': \"name: hasi_vault_user | Hasicorp Vault - Local admin users - Check if local admin\\n \\n \\n  user is allready created\\nshell: /usr/lpp/mmfs/gui/cli/lsuser -Y | grep -v HEADER | cut -d ':' -f 7\\nregister: scale_gui_vault_admin_check\\nrun_once: true\\nfailed_when: false\\nchanged_when: false\\n\"},\n",
       " {'text': \"name: hasi_vault_user | Hasicorp Vault - Local admin users - Check if local admin\\n \\n \\n  user is allready created - output\\nrun_once: true\\ndebug:\\n  msg: '{{ scale_gui_vault_admin_check.stdout.split(''\\n\\n    '') }}'\\n  verbosity: 2\\n\"},\n",
       " {'text': 'name: hasi_vault_user | Hasicorp Vault - Create local admin user and write password\\n \\n \\n  to Vault\\nshell: \\'vault kv put secret/private/{{ computed.name | default(AdminGUI) }}/gui gui_admin_pwd=$(vault\\n  write -field=\\'\\'value\\'\\' gen/password length=12 symbols=0)\\n\\n  /usr/lpp/mmfs/gui/cli/mkuser \"{{ scale_gui_admin_hc_vault_user }}\" -g \"{{ scale_gui_admin_hc_vault_role\\n  }}\" -p $(vault kv get -field=\\'\\'gui_admin_pwd\\'\\' secret/private/{{ computed.name |\\n  default(AdminGUI) }}/gui)\\n\\n  \\'\\nrun_once: true\\nignore_errors: true\\nwhen:\\n- \\' ( scale_gui_admin_hc_vault_user ) not in scale_gui_vault_admin_check.stdout\\'\\n'},\n",
       " {'text': \"name: hasi_vault_certificate  | Find existing cluster\\n \\n \\nshell: /usr/lpp/mmfs/bin/mmlscluster -Y | grep -v HEADER | grep clusterSummary | cut\\n  -d ':' -f 7\\nregister: scale_gui_scale_clustername\\nrun_once: true\\nchanged_when: false\\nfailed_when: false\\n\"},\n",
       " {'text': 'name: hasi_vault_certificate | Verify if GUI have allready imported GUI certficate\\n \\n \\nshell: /usr/lpp/mmfs/gui/cli/lshttpskeystore -c {{ scale_gui_scale_cluster_clustername.stdout\\n  }}\\nregister: scale_gui_certificate_lshttpskeystore_verify\\nrun_once: true\\nchanged_when: false\\nignore_errors: true\\n'},\n",
       " {'text': \"name: hasi_vault_certificate | Verify if GUI have allready imported GUI certficate\\n \\n \\n  - output\\nrun_once: true\\ndebug:\\n  msg: '{{ scale_gui_certificate_lshttpskeystore_verify.stdout }}'\\n  verbosity: 2\\n\"},\n",
       " {'text': 'name: chpasswdpolicy | Change default password Policy\\n \\n \\nshell: /usr/lpp/mmfs/gui/cli/chpasswordpolicy  --minLength \"{{ scale_gui_password_policy_minLength\\n  | default(6) }}\" --maxAge \"{{ scale_gui_password_policy_maxAge | default(90) }}\"\\n  --minAge \"{{ scale_gui_password_policy_minAge | default(0) }}\" --remember \"{{ scale_gui_password_policy_remember\\n  | default(3) }}\" --minUpperChars \"{{ scale_gui_password_policy_minUpperChars | default(0)\\n  }}\" --minLowerChars \"{{ scale_gui_password_policy_minLowerChars | default(0) }}\"\\n  --minSpecialChars \"{{ scale_gui_password_policy_minSpecialChars | default(0) }}\"\\n  --minDigits \"{{ scale_gui_password_policy_minDigits | default(0) }}\" --maxRepeat\\n  \"{{ scale_gui_password_policy_maxRepeat | default(0) }}\" --minDiff \"{{ scale_gui_password_policy_minDiff\\n  | default(1) }}\" \"{{ scale_gui_password_policy_rejectOrAllowUserName | default(\\'--rejectUserName\\')\\n  }}\"\\nregister: scale_gui_conf_password_policy\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_conf_password_policy.stdout\\'\\nrun_once: true\\n'},\n",
       " {'text': \"name: users | Check if local user is allready created\\n \\n \\nshell: /usr/lpp/mmfs/gui/cli/lsuser -Y | grep -v HEADER | cut -d ':' -f 7\\nregister: scale_gui_conf_gui_user_check\\nrun_once: true\\nfailed_when: false\\nchanged_when: false\\nwhen:\\n- scale_gui_admin_user is defined\\n\"},\n",
       " {'text': \"name: users | Check if local admin user is allready created - output\\n \\n \\nrun_once: true\\ndebug:\\n  msg: '{{ scale_gui_conf_gui_user_check.stdout.split(''\\n\\n    '') }}'\\n  verbosity: 2\\nwhen:\\n- scale_gui_admin_user is defined\\n\"},\n",
       " {'text': 'name: users | Create local Admin user for GUI\\n \\n \\nshell: /usr/lpp/mmfs/gui/cli/mkuser \"{{ scale_gui_admin_user }}\" -g \"{{ scale_gui_admin_role\\n  }}\" -p \"{{ scale_gui_admin_password }}\"\\nrun_once: true\\nregister: scale_gui_conf_createadmin\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_conf_createadmin.stdout\\'\\nignore_errors: true\\nwhen:\\n- scale_gui_admin_user is defined\\n- \\' ( scale_gui_admin_user ) not in scale_gui_conf_gui_user_check.stdout\\'\\n'},\n",
       " {'text': 'name: users | Create local user for GUI\\n \\n \\nshell: /usr/lpp/mmfs/gui/cli/mkuser \"{{ scale_gui_user_username }}\" -g \"{{ scale_gui_user_role\\n  }}\" -p \"{{ scale_gui_user_password }}\"\\nrun_once: true\\nregister: scale_gui_conf_create_gui_user\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_conf_create_gui_user.stdout\\'\\nignore_errors: true\\nwhen:\\n- scale_gui_user_username is defined\\n- \\' ( scale_gui_user_username ) not in scale_gui_conf_gui_user_check.stdout\\'\\n'},\n",
       " {'text': \"name: SNMP | Find collector nodes\\n \\n \\nadd_host:\\n  name: '{{ item }}'\\n  groups: scale_gui_collectors\\nwhen: hostvars[item].scale_cluster_gui | bool\\nwith_items: '{{ ansible_play_hosts }}'\\nchanged_when: false\\n\"},\n",
       " {'text': \"name: SNMP | Check if SNMP notifications is allready enabled\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/lssnmpserver\\nvars:\\n  collector_nodes: '{{ groups[''scale_gui_collectors''] | map(''extract'', hostvars,\\n    ''scale_daemon_nodename'') | list }}'\\nregister: scale_gui_conf_snmp_notifications_check\\nrun_once: true\\nfailed_when: false\\nchanged_when: false\\n\"},\n",
       " {'text': \"name: SNMP | Check if SNMP notifications is allready enabled - Output\\n \\n \\nvars:\\n  collector_nodes: '{{ groups[''scale_gui_collectors''] | map(''extract'', hostvars,\\n    ''scale_daemon_nodename'') | list }}'\\nrun_once: true\\ndebug:\\n  msg: '{{ scale_gui_conf_snmp_notifications_check.stdout.split(''\\n\\n    '') }}'\\n  verbosity: 2\\n\"},\n",
       " {'text': 'name: SNMP | Configure SNMP notifications\\n \\n \\nvars:\\n  collector_nodes: \\'{{ groups[\\'\\'scale_gui_collectors\\'\\'] | map(\\'\\'extract\\'\\', hostvars,\\n    \\'\\'scale_daemon_nodename\\'\\') | list }}\\'\\ncommand: /usr/lpp/mmfs/gui/cli/mksnmpserver SNMP_1 --ip \"{{ scale_gui_snmp_server.ip_adress\\n  }}\" --port \"{{ scale_gui_snmp_server.ip_port }}\" --community \"{{ scale_gui_snmp_server.community\\n  }}\"\\nregister: scale_gui_conf_snmp_notifications\\nrun_once: true\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_conf_snmp_notifications.stdout\\'\\nignore_errors: true\\nwhen:\\n- \\' \\'\\'EFSSG0100I\\'\\' in scale_gui_conf_snmp_notifications_check.stdout\\'\\n'},\n",
       " {'text': 'name: LDAP | Check if GUI is allready ldap integrated.\\n \\n \\nshell: /usr/lpp/mmfs/gui/cli/lsldap -filter\\nregister: scale_gui_conf_lsldap\\nrun_once: true\\nfailed_when: false\\nchanged_when: false\\n'},\n",
       " {'text': \"name: LDAP | Check if GUI is allready ldap integrated - Output\\n \\n \\nrun_once: true\\ndebug:\\n  msg: '{{ scale_gui_conf_lsldap.stdout.split(''\\n\\n    '') }}'\\n  verbosity: 2\\n\"},\n",
       " {'text': 'name: LDAP | Integrate GUI with LDAP\\n \\n \\nshell: \\'/usr/lpp/mmfs/gui/cli/mkldap \"{{ scale_gui_ldap.name }}\" --host \"{{ scale_gui_ldap.host\\n  }}\" --bindDn \"{{ scale_gui_ldap.bindDn }}\" --bindPassword \"{{ scale_gui_ldap.bindPassword\\n  }}\" --baseDn \"{{ scale_gui_ldap.baseDn }}\" --port \"{{ scale_gui_ldap.port | default(389)\\n  }}\" --type \"{{ scale_gui_ldap.type | default(\\'\\'Microsoft Active Directory\\'\\') }}\"\\n\\n  \\'\\nenvironment:\\n  JAVA_HOME: /usr/lpp/mmfs/java/jre\\nrun_once: true\\nignore_errors: true\\nno_log: false\\nwhen:\\n- scale_gui_ldap_secure.keystore is not defined\\n- \\' \\'\\'EFSSG0100I\\'\\' in scale_gui_conf_lsldap.stdout \\'\\n'},\n",
       " {'text': 'name: LDAP | Secure LDAP Integrate GUI\\n \\n \\nshell: \\'/usr/lpp/mmfs/gui/cli/mkldap \"{{ scale_gui_ldap.name }}\" --host \"{{ scale_gui_ldap.host\\n  }}\" --bindDn \"{{ scale_gui.ldap.bindDn }}\" --bindPassword \"{{ scale_gui.ldap.bindPassword\\n  }}\" --baseDn \"{{ scale_gui_ldap.baseDn }}\" --port \"{{ scale_gui_ldap.secureport\\n  | default(636) }}\" --type \"{{ scale_gui_ldap.type | default(Microsoft Active Directory)\\n  }}\" --keystore \"{{ scale_gui_ldap.securekeystore }}\"\\n\\n  \\'\\nenvironment:\\n  JAVA_HOME: /usr/lpp/mmfs/java/jre\\nrun_once: true\\nignore_errors: true\\nwhen:\\n- scale_gui_ldap_secure.keystore is defined\\n- \\' \\'\\'EFSSG0100I\\'\\' in scale_gui_conf_lsldap.stdout \\'\\n'},\n",
       " {'text': \"name: LDAP | Check if GUI have created user groups and roles for LDAP\\n \\n \\nshell: /usr/lpp/mmfs/gui/cli/lsusergrp -Y | grep -v HEADER |cut -d ':' -f 7\\nregister: scale_gui_conf_lsusergrp\\nfailed_when: false\\nchanged_when: false\\nrun_once: true\\n\"},\n",
       " {'text': \"name: LDAP | Check if GUI have created user groups and roles for LDAP - output\\n \\n \\nrun_once: true\\ndebug:\\n  msg: '{{ scale_gui_conf_lsusergrp.stdout.split(''\\n\\n    '') }}'\\n  verbosity: 2\\n\"},\n",
       " {'text': 'name: LDAP | Map roles to LDAP groups - Role administrator\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/mkusergrp \"{{ scale_gui_groups.administrator }}\" --role\\n  admin\\nenvironment:\\n  JAVA_HOME: /usr/lpp/mmfs/java/jre\\nrun_once: true\\nregister: scale_gui_ldap_role_mapping_administrator\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_ldap_role_mapping_administrator.stdout\\'\\nignore_errors: true\\nwhen:\\n- scale_gui_groups.administrator is defined\\n- \\' scale_gui_groups.administrator not in scale_gui_conf_lsusergrp.stdout\\'\\n'},\n",
       " {'text': 'name: LDAP | Map roles to LDAP groups - Role UserAdmin\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/mkusergrp \"{{ scale_gui_groups.useradmin }}\" --role\\n  useradmin\\nenvironment:\\n  JAVA_HOME: /usr/lpp/mmfs/java/jre\\nrun_once: true\\nregister: scale_gui_ldap_role_mapping_useradmin\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_ldap_role_mapping_useradmin.stdout\\'\\nignore_errors: true\\nwhen:\\n- scale_gui_groups.useradmin is defined\\n- \\' scale_gui_groups.useradmin not in scale_gui_conf_lsusergrp.stdout\\'\\n'},\n",
       " {'text': 'name: LDAP | Map roles to LDAP groups - Role Securityadmin\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/mkusergrp \"{{ scale_gui_groups.securityadmin }}\" --role\\n  securityadmin\\nenvironment:\\n  JAVA_HOME: /usr/lpp/mmfs/java/jre\\nrun_once: true\\nregister: scale_gui_ldap_role_mapping_securityadmin\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_ldap_role_mapping_securityadmin.stdout\\'\\nignore_errors: true\\nwhen:\\n- scale_gui_groups.securityadmin is defined\\n- \\' scale_gui_groups.securityadmin not in scale_gui_conf_lsusergrp.stdout\\'\\n'},\n",
       " {'text': 'name: ldap | Map roles to LDAP groups - Role Storageadmin\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/mkusergrp \"{{ scale_gui_groups.storageadmin }}\" --role\\n  storageadmin\\nenvironment:\\n  JAVA_HOME: /usr/lpp/mmfs/java/jre\\nrun_once: true\\nregister: scale_gui_ldap_role_mapping_storageadmin\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_ldap_role_mapping_storageadmin.stdout\\'\\nignore_errors: true\\nwhen:\\n- scale_gui_groups.storageadmin is defined\\n- \\' scale_gui_groups.storageadmin not in scale_gui_conf_lsusergrp.stdout\\'\\n'},\n",
       " {'text': 'name: LDAP | Map roles to LDAP groups - Role SnapAdmin\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/mkusergrp \"{{ scale_gui_groups.snapadmin }}\" --role\\n  snapadmin\\nenvironment:\\n  JAVA_HOME: /usr/lpp/mmfs/java/jre\\nrun_once: true\\nregister: scale_gui_ldap_role_mapping_snapadmin\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_ldap_role_mapping_snapadmin.stdout\\'\\nignore_errors: true\\nwhen:\\n- scale_gui_groups.snapadmin is defined\\n- \\' scale_gui_groups.snapadmin not in scale_gui_conf_lsusergrp.stdout\\'\\n'},\n",
       " {'text': 'name: LDAP | Map roles to LDAP groups - Role Data Access\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/mkusergrp \"{{ scale_gui_groups.data_access }}\" --role\\n  dataaccess\\nenvironment:\\n  JAVA_HOME: /usr/lpp/mmfs/java/jre\\nrun_once: true\\nregister: scale_gui_ldap_role_mapping_data_access\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_ldap_role_mapping_data_access.stdout\\'\\nignore_errors: true\\nwhen:\\n- scale_gui_groups.data_access is defined\\n- \\' scale_gui_groups.data_access not in scale_gui_conf_lsusergrp.stdout\\'\\n'},\n",
       " {'text': 'name: LDAP | Map roles to LDAP groups - Role Monitor\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/mkusergrp \"{{ scale_gui_groups.monitor }}\" --role monitor\\nenvironment:\\n  JAVA_HOME: /usr/lpp/mmfs/java/jre\\nrun_once: true\\nregister: scale_gui_ldap_role_mapping_monitor\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_ldap_role_mapping_monitor.stdout\\'\\nignore_errors: true\\nwhen:\\n- scale_gui_groups.monitor is defined\\n- \\' scale_gui_groups.monitor not in scale_gui_conf_lsusergrp.stdout\\'\\n'},\n",
       " {'text': 'name: LDAP | Map roles to LDAP groups - Role ProtocolAdmin\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/mkusergrp \"{{ scale_gui_groups.protocoladmin }}\" --role\\n  ProtocolAdmin\\nenvironment:\\n  JAVA_HOME: /usr/lpp/mmfs/java/jre\\nrun_once: true\\nregister: scale_gui_ldap_role_mapping_protocoladmin\\nfailed_when: \\' \\'\\'EFSSG1000I\\'\\' not in scale_gui_ldap_role_mapping_protocoladmin.stdout\\'\\nignore_errors: true\\nwhen:\\n- scale_gui_groups.protocoladmin is defined\\n- \\' scale_gui_groups.protocoladmin not in scale_gui_conf_lsusergrp.stdout\\'\\n'},\n",
       " {'text': \"name: configure | Set default collector role\\n \\n \\nset_fact:\\n  scale_cluster_gui: '{{ scale_cluster_gui }}'\\nwhen: hostvars[inventory_hostname].scale_cluster_gui is undefined\\n\"},\n",
       " {'text': 'name: configure | Start and enable GUI service\\n \\n \\nsystemd:\\n  name: gpfsgui\\n  state: started\\n  enabled: true\\nwhen: scale_cluster_gui | bool\\n'},\n",
       " {'text': \"name: configure | Initialize the GUI\\n \\n \\ncommand: /usr/lpp/mmfs/gui/cli/initgui\\nregister: scale_gui_conf_initgui\\nfailed_when: scale_gui_conf_initgui.rc != 0 and 'EFSSG1000I' not in scale_gui_conf_initgui.stdout\\nwhen: scale_cluster_gui | bool\\nchanged_when: false\\n\"},\n",
       " {'text': 'name: configure | Hide the CallHome TIP in the GUI\\n \\n \\ncommand: mmhealth event hide callhome_not_enabled\\nregister: scale_gui_conf_hide_tip_callhome\\nignore_errors: true\\nwhen: scale_gui_hide_tip_callhome | bool\\n'},\n",
       " {'text': 'name: prepare | Disable SELinux\\n \\n \\nselinux:\\n  state: disabled\\nnotify: reboot\\nwhen: scale_prepare_disable_selinux | bool\\n'},\n",
       " {'text': \"name: prepare | Add Spectrum Scale directory to PATH\\n \\n \\nlineinfile:\\n  path: /root/.bashrc\\n  line: PATH=$PATH:/usr/lpp/mmfs/bin\\n  state: present\\nwhen:\\n- ansible_pkg_mgr != 'zypper'\\n- scale_prepare_disable_selinux | bool\\n\"},\n",
       " {'text': 'name: prepare | Disable SSH hostkey checking\\n \\n \\nlineinfile:\\n  path: /etc/ssh/ssh_config\\n  regexp: StrictHostKeyChecking\\n  line: StrictHostKeyChecking no\\n  state: present\\nwhen: scale_prepare_disable_ssh_hostkeycheck | bool\\n'},\n",
       " {'text': \"name: prepare | List installed firewall RPMs\\n \\n \\nyum:\\n  list: firewalld\\nregister: scale_prepare_firewallrpm\\nwhen: ansible_pkg_mgr == 'yum'\\n\"},\n",
       " {'text': \"name: prepare | List installed firewall RPMs\\n \\n \\ndnf:\\n  list: firewalld\\nregister: scale_prepare_firewalldnfrpm\\nwhen: ansible_pkg_mgr == 'dnf'\\n\"},\n",
       " {'text': 'name: prepare | Stop and disable firewall\\n \\n \\nservice:\\n  name: firewalld\\n  state: stopped\\n  enabled: false\\nfailed_when: false\\nchanged_when: false\\nwhen:\\n- scale_prepare_disable_firewall | bool\\n- (\"\\'installed\\' in scale_prepare_firewallrpm.results | map(attribute=\\'yumstate\\') |\\n  list\") or (\"\\'installed\\' in scale_prepare_firewalldnfrpm.results | map(attribute=\\'yumstate\\')\\n  | list\")\\n'},\n",
       " {'text': \"name: prepare | Install prerequisite RPMs\\n \\n \\nyum:\\n  name: yum-utils\\n  state: present\\nwhen: ansible_pkg_mgr == 'yum'\\n\"},\n",
       " {'text': \"name: precheck\\n \\n \\ninclude_tasks: check.yml\\nwhen: scale_protocols is defined and scale_protocols.hdfs|bool\\ntags: prepare\\nloop: '{{ scale_hdfs_clusters }}'\\n\"},\n",
       " {'text': \"name: null\\n \\n \\nset_fact:\\n  transparency_33_enabled: 'False'\\n  transparency_version: 'False'\\n\"},\n",
       " {'text': 'name: null\\n \\n \\nshell: echo $SCALE_HDFS_TRANSPARENCY_VERSION_33_ENABLE\\nregister: transparency_version\\ndelegate_to: localhost\\nrun_once: true\\n'},\n",
       " {'text': \"name: null\\n \\n \\nset_fact:\\n  transparency_33_enabled: '{{ transparency_version.stdout|bool }}'\\nwhen:\\n- transparency_version.stdout is defined\\n- transparency_version.stdout|bool\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': \"name: global_var | Initialize\\n \\n \\nset_fact:\\n  scale_hdfs_cluster: []\\n  scale_protocol_nodes_list: []\\n  export_cesip_length: ''\\n\"},\n",
       " {'text': \"name: check | Collect all protocol nodes\\n \\n \\nset_fact:\\n  scale_protocol_nodes_list: '{{ scale_protocol_nodes_list + [hostvars[hosts][''ansible_fqdn'']]\\n    }}'\\nwhen: hostvars[hosts]['is_protocol_node'] is defined and hostvars[hosts]['is_protocol_node']|bool\\nwith_items:\\n- '{{ ansible_play_hosts }}'\\nloop_control:\\n  loop_var: hosts\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': \"name: check | initializing scale_hdfs_cluster\\n \\n \\nset_fact:\\n  scale_hdfs_cluster: '{{ item }}'\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': \"name: check | verify hdfs cluster length\\n \\n \\nset_fact:\\n  hdfs_cluster_length: '{{ scale_hdfs_clusters| length }}'\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': \"name: check | get server node\\n \\n \\nset_fact:\\n  server: '{{ scale_hdfs_cluster.namenodes[0] }}'\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': \"name: check | verify cesip address\\n \\n \\nset_fact:\\n  export_cesip_length: '{{ scale_protocols.export_ip_pool| length }}'\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': \"name: check | calculate cesip when object is enabled\\n \\n \\nset_fact:\\n  export_cesip_length: '{{ export_cesip_length|int - 1 }}'\\nwhen:\\n- scale_protocols.object is defined\\n- scale_protocols.object|bool\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': \"name: Check | Check Namenodes running status\\n \\n \\nshell: /usr/lpp/mmfs/hadoop/sbin/mmhdfs hdfs-nn status | grep 'namenode pid is' |\\n  wc -l\\nregister: verify_namenodes\\ndelegate_to: '{{ server }}'\\nrun_once: true\\n\"},\n",
       " {'text': 'name: check | Check if hdfs is enabled\\n \\n \\nassert:\\n  that:\\n  - scale_protocols.hdfs|bool\\n  fail_msg: HDFS is not enabled\\n'},\n",
       " {'text': \"name: check |  Check if HDFS required information has been supplied.\\n \\n \\nassert:\\n  that:\\n  - hdfs_cluster is defined\\n  - hdfs_cluster| length > 0\\n  - hdfs_cluster.name is defined\\n  - hdfs_cluster.name| length > 0\\n  - hdfs_cluster.filesystem is defined\\n  - hdfs_cluster.filesystem| length > 0\\n  - hdfs_cluster.namenodes is defined\\n  - hdfs_cluster.namenodes| length > 0\\n  - hdfs_cluster.datanodes is defined\\n  - hdfs_cluster.datanodes| length > 0\\n  - hdfs_cluster.datadir is defined\\n  - hdfs_cluster.datadir| length > 0\\n  fail_msg: HDFS required parameter information is not defined.\\n  success_msg: HDFS required information is defined.\\nwith_items:\\n- '{{ scale_hdfs_cluster }}'\\nloop_control:\\n  loop_var: hdfs_cluster\\nrun_once: true\\ndelegate_to: localhost\\n\"},\n",
       " {'text': \"name: check | Verify JAVA_HOME\\n \\n \\ninclude_tasks: java_home.yml\\nloop: '{{ scale_hdfs_clusters }}'\\nloop_control:\\n  loop_var: hdfs_clusters\\n\"},\n",
       " {'text': 'name: global_var | Initialize\\n \\n \\nset_fact:\\n  scale_hdfs_nodes_list: []\\n  scale_hdfs_namenodes_list: []\\n  scale_hdfs_datanodes_list: []\\n'},\n",
       " {'text': \"name: global_var | Collect all HDFS NameNodes\\n \\n \\nset_fact:\\n  scale_hdfs_namenodes_list: '{{ item.namenodes | unique }}'\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': \"name: global_var | Collect all HDFS DataNodes\\n \\n \\nset_fact:\\n  scale_hdfs_datanodes_list: '{{ item.datanodes | unique }}'\\ndelegate_to: localhost\\nrun_once: true\\n\"},\n",
       " {'text': \"name: global_var | Get HDFS nodes\\n \\n \\nset_fact:\\n  scale_hdfs_nodes_list: '{{ scale_hdfs_namenodes_list + scale_hdfs_datanodes_list\\n    }}'\\n\"},\n",
       " {'text': \"name: global_var | make unique HDFS nodes\\n \\n \\nset_fact:\\n  scale_hdfs_nodes_list: '{{ scale_hdfs_nodes_list | unique }}'\\n\"},\n",
       " {'text': 'name: check | Check if atleast one hdfs node is configured\\n \\n \\nassert:\\n  that:\\n  - scale_hdfs_nodes_list|length > 0\\n  fail_msg: No hdfs nodes configured\\n'},\n",
       " {'text': 'name: check | Fetch JAVA_HOME path\\n \\n \\nshell: echo $JAVA_HOME\\nregister: java_path\\nwhen: ansible_fqdn in scale_hdfs_nodes_list\\n'},\n",
       " {'text': \"name: check | Check JAVA_HOME path exist\\n \\n \\nstat:\\n  path: '{{ java_path.stdout }}'\\nregister: java_path_details\\nwhen: ansible_fqdn in scale_hdfs_nodes_list\\n\"},\n",
       " {'text': 'name: check | Assert JAVA_HOME path exist\\n \\n \\nassert:\\n  that:\\n  - java_path_details.stat.exists\\n  fail_msg: The JAVA_HOME path does not exists !\\nwhen: ansible_fqdn in scale_hdfs_nodes_list\\n'},\n",
       " {'text': \"name: check | Set path of JAVA_HOME\\n \\n \\nset_fact:\\n  javahome_path: '{{ java_path.stdout }}'\\nwhen:\\n- ansible_fqdn in scale_hdfs_nodes_list\\n\"},\n",
       " {'text': 'name: check | verify JAVA\\n \\n \\ncommand: ls {{ javahome_path }}/bin/java\\nregister: jvm_list\\nwhen:\\n- ansible_fqdn in scale_hdfs_nodes_list\\n- javahome_path|length > 0\\n'},\n",
       " {'text': \"name: install | Stat remote installation package\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  checksum_algorithm: md5\\nregister: scale_install_remotepkg\\n\"},\n",
       " {'text': \"name: install | Check remote installation package\\n \\n \\nassert:\\n  that: scale_install_remotepkg.stat.exists\\n  msg: Please set the variable 'scale_install_remotepkg_path' to point to the remote\\n    installation package (accessible on Ansible managed node)!\\n\"},\n",
       " {'text': \"name: install | Stat checksum file\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}.md5'\\nregister: scale_install_md5_file\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ smb_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Make installation package executable\\n \\n \\nfile:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  mode: a+x\\nwhen: not scale_install_gpfs_rpmdir.stat.exists\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\ncommand: '{{ scale_install_remotepkg_path + '' --silent'' }}'\\nargs:\\n  creates: '{{ smb_extracted_path }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ smb_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the remote\\n    installation package!\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/rhel7/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '7'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/rhel8/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '8'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/sles12/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  == '12'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/sles15/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  >= '15'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/ubuntu16/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '16'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/ubuntu18/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '18'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '20'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ smb_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\nvars:\\n  localpkg: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\ncommand: '{{ localpkg + '' --silent'' }}'\\nargs:\\n  creates: '{{ smb_extracted_path }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ smb_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the local\\n    installation package!\\n\"},\n",
       " {'text': \"name: install | Delete installation package from node\\n \\n \\nfile:\\n  path: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\n  state: absent\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/rhel7/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '7'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/rhel8/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '8'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/sles12/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  == '12'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/sles15/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  >= '15'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/ubuntu16/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '16'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/ubuntu18/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '18'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '20'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/rhel7/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '7'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/rhel8/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '8'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/sles12/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  == '12'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/sles15/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  >= '15'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/ubuntu16/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '16'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/ubuntu18/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '18'\\n\"},\n",
       " {'text': \"name: install | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  >= '20'\\n\"},\n",
       " {'text': \"name: install | Configure smb YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-smb\\n  description: IBM Spectrum Scale (smb)\\n  baseurl: '{{ scale_install_repository_url }}{{ scale_smb_url }}'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure smb zypper repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-smb-rpms\\n  repo: '{{ scale_install_repository_url }}{{ scale_smb_url }}'\\n  runrefresh: true\\n  state: present\\n  disable_gpg_check: true\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure smb APT repository\\n \\n \\napt_repository:\\n  filename: spectrum-scale-smb-debs\\n  repo: deb [trusted=yes] {{ scale_install_repository_url }}{{ scale_smb_url }} ./\\n  validate_certs: false\\n  state: present\\n  update_cache: true\\n  codename: IBM Spectrum Scale (SMB debs)\\n  mode: 511\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Add GPFS smb packages to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_smb_packages }}'\\n\"},\n",
       " {'text': \"name: install| Creates default directory\\n \\n \\nfile:\\n  path: '{{ scale_extracted_path }}'\\n  state: directory\\n  mode: a+x\\n  recurse: true\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path | basename\\n    }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Set installation package path\\n \\n \\nset_fact:\\n  dir_path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path |\\n    basename }}'\\n\"},\n",
       " {'text': \"name: install | gpfs base path\\n \\n \\nset_fact:\\n  gpfs_path_url: '{{ dir_path }}'\\nwhen: scale_install_directory_pkg_path is defined\\n\"},\n",
       " {'text': 'name: install | Initialize list of packages\\n \\n \\nset_fact:\\n  scale_install_all_packages: []\\n'},\n",
       " {'text': \"name: install | Set the extracted package directory path\\n \\n \\nset_fact:\\n  smb_extracted_path: '{{ scale_extracted_path }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages directory\\n \\n \\nstat:\\n  path: '{{ smb_extracted_path }}'\\nregister: scale_extracted_gpfs_dir\\n\"},\n",
       " {'text': \"name: install | Install GPFS SMB packages\\n \\n \\nzypper:\\n  name: '{{ scale_install_all_packages }}'\\n  state: present\\n  disable_gpg_check: false\\nwhen: ansible_fqdn in scale_smb_node_list\\n\"},\n",
       " {'text': \"name: install | Install GPFS SMB packages\\n \\n \\nyum:\\n  name: '{{ scale_install_all_packages }}'\\n  state: present\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\nwhen: ansible_fqdn in scale_smb_node_list\\n\"},\n",
       " {'text': \"name: Install GPFS smb packages\\n \\n \\npackage:\\n  name: '{{ scale_install_all_packages }}'\\n  state: present\\nwhen: scale_install_repository_url is defined and ansible_fqdn in scale_smb_node_list\\n\"},\n",
       " {'text': \"name: install| Install GPFS SMB deb\\n \\n \\napt:\\n  deb: '{{ item }}'\\n  state: present\\nwhen: scale_install_repository_url is not defined and ansible_fqdn in scale_smb_node_list\\nwith_items:\\n- '{{ scale_install_all_packages }}'\\n\"},\n",
       " {'text': \"name: install | Configure GUI YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-gui\\n  description: IBM Spectrum Scale (GUI)\\n  baseurl: '{{ scale_install_repository_url }}gpfs_rpms/'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure gui APT repository\\n \\n \\napt_repository:\\n  filename: spectrum-scale-gui-debs\\n  repo: deb [trusted=yes] {{ scale_install_repository_url }}gpfs_debs/ ./\\n  validate_certs: false\\n  state: present\\n  update_cache: true\\n  codename: IBM Spectrum Scale (GUI debs)\\n  mode: 511\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure GUI repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-gui\\n  description: IBM Spectrum Scale (GUI)\\n  repo: '{{ scale_install_repository_url }}/gpfs_rpms/'\\n  disable_gpg_check: false\\n  state: present\\n  overwrite_multiple: true\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Add GUI RPMs to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_gui_packages }}'\\nwhen: scale_cluster_gui | bool\\n\"},\n",
       " {'text': \"name: install | Stat remote installation package\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  checksum_algorithm: md5\\nregister: scale_install_remotepkg\\n\"},\n",
       " {'text': \"name: install | Check remote installation package\\n \\n \\nassert:\\n  that: scale_install_remotepkg.stat.exists\\n  msg: Please set the variable 'scale_install_remotepkg_path' to point to the remote\\n    installation package (accessible on Ansible managed node)!\\n\"},\n",
       " {'text': \"name: install | Stat checksum file\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}.md5'\\nregister: scale_install_md5_file\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Make installation package executable\\n \\n \\nfile:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  mode: a+x\\nwhen: not scale_install_gpfs_rpmdir.stat.exists\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\ncommand: '{{ scale_install_remotepkg_path + '' --silent'' }}'\\nargs:\\n  creates: '{{ scale_gpfs_path_url }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs__rpmdir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs__rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the remote\\n    installation package!\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\nvars:\\n  localpkg: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\ncommand: '{{ localpkg + '' --silent'' }}'\\nargs:\\n  creates: '{{ scale_gpfs_path_url }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_packagedir.stat.exists\\n  - scale_install_gpfs_packagedir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the local\\n    installation package!\\n\"},\n",
       " {'text': \"name: install | Delete installation package from node\\n \\n \\nfile:\\n  path: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\n  state: absent\\n\"},\n",
       " {'text': 'name: install | Initialize list of packages\\n \\n \\nset_fact:\\n  scale_install_all_packages: []\\n'},\n",
       " {'text': \"name: install| Creates default directory\\n \\n \\nfile:\\n  path: '{{ scale_extracted_path }}'\\n  state: directory\\n  mode: a+x\\n  recurse: true\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path | basename\\n    }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Set installation package path\\n \\n \\nset_fact:\\n  dir_path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path |\\n    basename }}'\\n\"},\n",
       " {'text': \"name: install | gpfs base path\\n \\n \\nset_fact:\\n  scale_gpfs_path_url: '{{ dir_path }}'\\nwhen: scale_install_directory_pkg_path is defined\\n\"},\n",
       " {'text': \"name: install | Install GPFS GUI packages\\n \\n \\npackage:\\n  name: '{{ scale_install_all_packages }}'\\n  state: present\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\n\"},\n",
       " {'text': \"name: Initialize\\n \\n \\nset_fact:\\n  scale_gnr_url: ''\\n\"},\n",
       " {'text': 'name: install | gnr path\\n \\n \\nset_fact:\\n  scale_gnr_url: gpfs_rpms/\\nwhen: ansible_distribution in scale_rhel_distribution\\n'},\n",
       " {'text': \"name: install | Configure gnr YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-gnr\\n  description: IBM Spectrum Scale (gnr)\\n  baseurl: '{{ scale_install_repository_url }}{{ scale_gnr_url }}'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Add GPFS gnr packages to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_gnr_packages }}'\\n\"},\n",
       " {'text': \"name: install | Stat remote installation package\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  checksum_algorithm: md5\\nregister: scale_install_remotepkg\\n\"},\n",
       " {'text': \"name: install | Check remote installation package\\n \\n \\nassert:\\n  that: scale_install_remotepkg.stat.exists\\n  msg: Please set the variable 'scale_install_remotepkg_path' to point to the remote\\n    installation package (accessible on Ansible managed node)!\\n\"},\n",
       " {'text': \"name: install | Stat checksum file\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}.md5'\\nregister: scale_install_md5_file\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ gnr_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Make installation package executable\\n \\n \\nfile:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  mode: a+x\\nwhen: not scale_install_gpfs_rpmdir.stat.exists\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\ncommand: '{{ scale_install_remotepkg_path + '' --silent'' }}'\\nargs:\\n  creates: '{{ gnr_extracted_path }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ gnr_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the remote\\n    installation package!\\n\"},\n",
       " {'text': 'name: install | gnr path\\n \\n \\nset_fact:\\n  scale_gnr_url: gpfs_rpms/\\nwhen: ansible_distribution in scale_rhel_distribution\\n'},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ gnr_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\nvars:\\n  localpkg: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\ncommand: '{{ localpkg + '' --silent'' }}'\\nargs:\\n  creates: '{{ gnr_extracted_path }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ gnr_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the local\\n    installation package!\\n\"},\n",
       " {'text': \"name: install | Delete installation package from node\\n \\n \\nfile:\\n  path: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\n  state: absent\\n\"},\n",
       " {'text': 'name: install | gnr path\\n \\n \\nset_fact:\\n  scale_gnr_url: gpfs_rpms/\\nwhen: ansible_distribution in scale_rhel_distribution\\n'},\n",
       " {'text': 'name: install | Initialize list of packages\\n \\n \\nset_fact:\\n  scale_install_all_packages: []\\n'},\n",
       " {'text': \"name: install | Set the extracted package directory path\\n \\n \\nset_fact:\\n  gnr_extracted_path: '{{ scale_extracted_path }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages directory\\n \\n \\nstat:\\n  path: '{{ gnr_extracted_path }}'\\nregister: scale_extracted_gpfs_dir\\n\"},\n",
       " {'text': \"name: install| Creates default directory\\n \\n \\nfile:\\n  path: '{{ scale_extracted_path }}'\\n  state: directory\\n  mode: a+x\\n  recurse: true\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path | basename\\n    }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Set installation package path\\n \\n \\nset_fact:\\n  dir_path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path |\\n    basename }}'\\n\"},\n",
       " {'text': \"name: install | gpfs base path\\n \\n \\nset_fact:\\n  gpfs_path_url: '{{ dir_path }}'\\nwhen: scale_install_directory_pkg_path is defined\\n\"},\n",
       " {'text': \"name: install | Install GPFS gnr packages\\n \\n \\nyum:\\n  name: '{{ scale_install_all_packages }}'\\n  state: present\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\n\"},\n",
       " {'text': \"name: configure | Check callhome capabilitiy\\n \\n \\nshell:\\n  cmd: '{{ scale_command_path }}mmcallhome capability list -Y | grep enabled'\\nregister: scale_callhome_config_status\\nignore_errors: true\\nfailed_when: false\\nrun_once: true\\n\"},\n",
       " {'text': 'name: Initialize\\n \\n \\nset_fact:\\n  is_scale_java_pkg_installed: false\\n'},\n",
       " {'text': \"name: upgrade | Configure GPFS YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-gpfs\\n  description: IBM Spectrum Scale (GPFS)\\n  baseurl: '{{ scale_install_repository_url }}gpfs_rpms/'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: upgrade | Configure core APT repository\\n \\n \\napt_repository:\\n  filename: spectrum-scale-core-debs\\n  repo: deb [trusted=yes] {{ scale_install_repository_url }}gpfs_debs/ ./\\n  validate_certs: false\\n  state: present\\n  update_cache: true\\n  codename: IBM Spectrum Scale (core debs)\\n  mode: 511\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: upgrade | Configure GPFS repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-gpfs\\n  description: IBM Spectrum Scale (GPFS)\\n  repo: '{{ scale_install_repository_url }}gpfs_rpms/'\\n  disable_gpg_check: true\\n  state: present\\n  overwrite_multiple: true\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS packages to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_install_gpfs_packages }}'\\n- gpfs.gskit\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS packages to list (prior to version 5.0.2.0)\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_install_add_packages_pre502 }}'\\nwhen: scale_version is version_compare('5.0.2', '<=')\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS packages for building GPL module from source to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwhen: scale_install_gplbin_package is undefined\\nwith_items: '{{ scale_install_gplsrc_packages }}'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS AFM COS package to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_hpt_packages }}'\\n\"},\n",
       " {'text': \"name: upgrade | Check if gpfs java package is installed\\n \\n \\nshell: rpm -q gpfs.java\\nregister: is_gpfsjava_package_installed\\nfailed_when: false\\nchanged_when: false\\nargs:\\n  warn: false\\nwhen: ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf' or ansible_pkg_mgr == 'zypper'\\n\"},\n",
       " {'text': \"name: upgrade | Set if gpfs java package is installed\\n \\n \\nset_fact:\\n  is_scale_java_pkg_installed: true\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf' or ansible_pkg_mgr == 'zypper'\\n- is_gpfsjava_package_installed.rc == 0\\n\"},\n",
       " {'text': 'name: upgrade | Check if gpfs java package is installed\\n \\n \\nshell: dpkg -l | grep gpfs.java | awk \"{print $1}\" |  grep ii\\nregister: is_gpfsjava_apt_package_installed\\nfailed_when: false\\nchanged_when: false\\nargs:\\n  warn: false\\nwhen: ansible_pkg_mgr == \\'apt\\'\\n'},\n",
       " {'text': \"name: upgrade | Set if gpfs java package installed\\n \\n \\nset_fact:\\n  is_scale_java_pkg_installed: true\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- is_gpfsjava_apt_package_installed.rc == 0\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS java packages to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- gpfs.java*\\nwhen: (is_scale_java_pkg_installed | bool)\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: upgrade | Extract installation package\\n \\n \\nvars:\\n  localpkg: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\ncommand: '{{ localpkg + '' --silent'' }}'\\nargs:\\n  creates: '{{ scale_gpfs_path_url }}'\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: upgrade | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_packagedir.stat.exists\\n  - scale_install_gpfs_packagedir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the local\\n    installation package!\\n\"},\n",
       " {'text': \"name: upgrade | Delete installation package from node\\n \\n \\nfile:\\n  path: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\n  state: absent\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS BASE (gpfs.base) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.base*{{ scale_architecture }}*\\nregister: scale_install_gpfs_base\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS BASE (gpfs.base) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_base.matched > 0\\n  msg: 'No GPFS BASE (gpfs.base) package found: {{ scale_gpfs_path_url }}/gpfs.base*{{\\n    scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS docs (gpfs.docs) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.docs*\\nregister: scale_install_gpfs_doc\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS docs (gpfs.docs) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_doc.matched > 0\\n  msg: 'No GPFS docs (gpfs.docs) package found: {{ scale_gpfs_path_url }}/gpfs.docs*'\\n\"},\n",
       " {'text': \"name: upgrade | Find gpfs.msg.en_US (gpfs.msg.en_US) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.msg.en*\\nregister: scale_install_gpfs_msg\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS (gpfs.msg.en_US) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_msg.matched > 0\\n  msg: 'No GPFS BASE (gpfs.base) package found: {{ scale_gpfs_path_url }}/gpfs.msg.en*'\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS Compression (gpfs.compression) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.compression*{{ scale_architecture }}*\\nregister: scale_install_gpfs_compression\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS Compression(gpfs.compression) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_compression.matched > 0\\n  msg: 'No GPFS Compression (gpfs.compression) package found: {{ scale_gpfs_path_url\\n    }}/gpfs.compression*{{ scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: upgrade | Find Global Security Kit (GSKit) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.gskit*{{ scale_architecture }}*\\nregister: scale_install_gpfs_gskit\\n\"},\n",
       " {'text': \"name: upgrade | Check valid Global Security Kit (GSKit) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_gskit.matched > 0\\n  msg: 'No Global Security Kit (GSKit) package found: {{ scale_gpfs_path_url }}/gpfs.gskit*{{\\n    scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS packages to list\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_gpfs_base.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_doc.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_msg.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_gskit.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_compression.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS packages to list (prior to version 5.0.2.0)\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_add_packages_pre502 }}'\\nwhen: scale_version is version_compare('5.0.2', '<=')\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS gpl (gpfs.gpl) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.gpl*\\nregister: scale_install_gpfs_gpl\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS GPL (gpfs.gpl) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_gpl.matched > 0\\n  msg: 'No GPFS GPL (gpfs.gpl) package found: {{ scale_gpfs_path_url }}/gpfs.gpl*'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS packages for building GPL module from source to list\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwhen: scale_install_gplbin_package is undefined\\nwith_items: '{{ scale_install_gpfs_gpl.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: upgrade | Get license package\\n \\n \\nyum:\\n  list: gpfs.license.*\\nregister: package_name_version\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n\"},\n",
       " {'text': \"name: Find license package\\n \\n \\nshell:\\n  cmd: apt-cache show gpfs.license.*\\nregister: package_name\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n\"},\n",
       " {'text': \"name: upgrade | Get license package\\n \\n \\nshell:\\n  cmd: zypper info gpfs.license.* | grep Name | cut -d ':' -f 2 | tr -d '[:space:]'\\nregister: package_name_version_zypp\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n\"},\n",
       " {'text': \"name: upgrade | Extract license package name\\n \\n \\nset_fact:\\n  scale_gpfs_license_package: '{{package_name_version|json_query(jsonquery)}}'\\nvars:\\n  jsonquery: results[?yumstate=='available'].name\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_gpfs_license_pkg is not defined\\n\"},\n",
       " {'text': \"name: upgrade | Extract license package name\\n \\n \\nset_fact:\\n  scale_gpfs_license_package: '{{ scale_gpfs_license_pkg }}'\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_gpfs_license_pkg is defined\\n\"},\n",
       " {'text': 'name: upgrade | Add GPFS license packages to list\\n \\n \\nset_fact:\\n  scale_install_license_packages: \\'{{ scale_install_license_packages + [ item ] }}\\'\\nwith_items:\\n- \\'{{ scale_gpfs_license_package }}\\'\\n- gpfs.adv\\n- gpfs.crypto\\nwhen:\\n- \\'\"gpfs.license.std\" not in scale_gpfs_license_package\\'\\n- \\'\"gpfs.license.da\" not in scale_gpfs_license_package\\'\\n'},\n",
       " {'text': \"name: upgrade | Add GPFS license packages to list\\n \\n \\nset_fact:\\n  scale_install_license_packages: '{{ scale_install_license_packages + [ item ] }}'\\nwhen: '''gpfs.license.std'' in scale_gpfs_license_package or ''gpfs.license.da'' in\\n  scale_gpfs_license_package'\\nwith_items:\\n- '{{ scale_gpfs_license_package }}'\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS License (gpfs.license) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.license*{{ scale_architecture }}*\\nregister: scale_install_gpfs_license\\n\"},\n",
       " {'text': 'name: upgrade | Check valid GPFS License (gpfs.license) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_license.matched > 0\\n  msg: \\'No GPFS License (gpfs.license) package found: \"{{ scale_gpfs_path_url }}/gpfs.license*{{\\n    scale_architecture }}*\"\\'\\n'},\n",
       " {'text': 'name: upgrade | Check valid only one GPFS License (gpfs.license) package\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_license.matched > 0\\n  - scale_install_gpfs_license.matched == 1\\n  msg: \\'More than one GPFS License (gpfs.license) package found: \"{{ scale_gpfs_path_url\\n    }}/gpfs.license*{{ scale_architecture }}*\"\\'\\n'},\n",
       " {'text': \"name: upgrade | Find GPFS License package\\n \\n \\nvars:\\n  gpfs_license_package: '{{ scale_install_gpfs_license.files.0.path | basename }}'\\nset_fact:\\n  scale_gpfs_license_package: '{{ gpfs_license_package }}'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS License packages to list\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_license_packages: '{{ scale_install_license_packages + [ current_package\\n    ] }}'\\nwith_items:\\n- '{{ scale_install_gpfs_license.files.0.path | basename }}'\\n\"},\n",
       " {'text': 'name: upgrade | Add GPFS Dependent License packages to list\\n \\n \\nvars:\\n  license_package: \\'{{ scale_install_gpfs_license.files.0.path | basename }}\\'\\n  current_package: \\'{{ scale_gpfs_path_url }}/{{ item }}\\'\\nset_fact:\\n  scale_install_license_packages: \\'{{ scale_install_license_packages + [ current_package\\n    ] }}\\'\\nwith_items:\\n- \\'{{ scale_install_gpfs_adv.files.0.path | basename }}\\'\\n- \\'{{ scale_install_gpfs_crypto.files.0.path | basename }}\\'\\nwhen:\\n- \\'\"gpfs.license.std\" not in scale_gpfs_license_package\\'\\n- \\'\"gpfs.license.da\" not in scale_gpfs_license_package\\'\\n'},\n",
       " {'text': 'name: upgrade | Initialize list of packages\\n \\n \\nset_fact:\\n  scale_install_all_packages: []\\n  scale_install_license_packages: []\\n'},\n",
       " {'text': \"name: upgrade | Stat remote installation package\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  checksum_algorithm: md5\\nregister: scale_install_remotepkg\\n\"},\n",
       " {'text': \"name: upgrade | Check remote installation package\\n \\n \\nassert:\\n  that: scale_install_remotepkg.stat.exists\\n  msg: Please set the variable 'scale_install_remotepkg_path' to point to the remote\\n    installation package (accessible on Ansible managed node)!\\n\"},\n",
       " {'text': \"name: upgrade | Stat checksum file\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}.md5'\\nregister: scale_install_md5_file\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: upgrade | Make installation package executable\\n \\n \\nfile:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  mode: a+x\\nwhen: not scale_install_gpfs_packagedir.stat.exists\\n\"},\n",
       " {'text': \"name: upgrade | Extract installation package\\n \\n \\ncommand: '{{ scale_install_remotepkg_path + '' --silent'' }}'\\nargs:\\n  creates: '{{ scale_gpfs_path_url }}'\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: upgrade | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_packagedir.stat.exists\\n  - scale_install_gpfs_packagedir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the remote\\n    installation package!\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS BASE (gpfs.base) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.base*{{ scale_architecture }}*\\nregister: scale_install_gpfs_base\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS BASE (gpfs.base) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_base.matched > 0\\n  msg: 'No GPFS BASE (gpfs.base) package found: {{ scale_gpfs_path_url }}/gpfs.base*{{\\n    scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS docs (gpfs.docs) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.docs*\\nregister: scale_install_gpfs_doc\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS docs (gpfs.docs) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_doc.matched > 0\\n  msg: 'No GPFS docs (gpfs.docs) package found: {{ scale_gpfs_path_url }}/gpfs.docs*'\\n\"},\n",
       " {'text': \"name: upgrade | Find gpfs.msg.en_US (gpfs.msg.en_US) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.msg.en*\\nregister: scale_install_gpfs_msg\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS (gpfs.msg.en_US) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_msg.matched > 0\\n  msg: 'No GPFS BASE (gpfs.base) package found: {{ scale_gpfs_path_url }}/gpfs.msg.en*'\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS Compression (gpfs.compression) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.compression*{{ scale_architecture }}*\\nregister: scale_install_gpfs_compression\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS Compression(gpfs.compression) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_compression.matched > 0\\n  msg: 'No GPFS Compression (gpfs.compression) package found: {{ scale_gpfs_path_url\\n    }}/gpfs.compression*{{ scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: upgrade | Find Global Security Kit (GSKit) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.gskit*{{ scale_architecture }}*\\nregister: scale_install_gpfs_gskit\\n\"},\n",
       " {'text': \"name: upgrade | Check valid Global Security Kit (GSKit) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_gskit.matched > 0\\n  msg: 'No Global Security Kit (GSKit) package found: {{ scale_gpfs_path_url }}/gpfs.gskit*{{\\n    scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS packages to list\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_gpfs_base.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_doc.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_msg.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_gskit.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_compression.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS packages to list (prior to version 5.0.2.0)\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_add_packages_pre502 }}'\\nwhen: scale_version is version_compare('5.0.2', '<=')\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS gpl (gpfs.gpl) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.gpl*\\nregister: scale_install_gpfs_gpl\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS GPL (gpfs.gpl) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_gpl.matched > 0\\n  msg: 'No GPFS GPL (gpfs.gpl) package found: {{ scale_gpfs_path_url }}/gpfs.gpl*'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS packages for building GPL module from source to list\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwhen: scale_install_gplbin_package is undefined\\nwith_items: '{{ scale_install_gpfs_gpl.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: install| Creates default directory\\n \\n \\nfile:\\n  path: '{{ scale_extracted_path }}'\\n  state: directory\\n  mode: a+x\\n  recurse: true\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path | basename\\n    }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: upgrade | Set installation package path\\n \\n \\nset_fact:\\n  dir_path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path |\\n    basename }}'\\n\"},\n",
       " {'text': \"name: upgrade | gpfs base path\\n \\n \\nset_fact:\\n  scale_gpfs_path_url: '{{ dir_path }}'\\nwhen: scale_install_directory_pkg_path is defined\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS BASE (gpfs.base) package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: gpfs.base*{{ scale_architecture }}*\\nregister: scale_install_gpfs_base\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS BASE (gpfs.base) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_base.matched > 0\\n  msg: 'No GPFS BASE (gpfs.base) package found: {{ dir_path }}/gpfs.base*{{ scale_architecture\\n    }}*'\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS docs (gpfs.docs) package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: gpfs.docs*\\nregister: scale_install_gpfs_doc\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS docs (gpfs.docs) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_doc.matched > 0\\n  msg: 'No GPFS docs (gpfs.docs) package found: {{ dir_path }}/gpfs.docs*'\\n\"},\n",
       " {'text': \"name: upgrade | Find gpfs.msg.en_US (gpfs.msg.en_US) package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: gpfs.msg.en*\\nregister: scale_install_gpfs_msg\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS (gpfs.msg.en_US) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_msg.matched > 0\\n  msg: 'No GPFS BASE (gpfs.base) package found: {{ dir_path }}/gpfs.msg.en*'\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS Compression (gpfs.compression) package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: gpfs.compression*{{ scale_architecture }}*\\nregister: scale_install_gpfs_compression\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS Compression(gpfs.compression) package\\n \\n \\ndebug:\\n  msg: 'No GPFS Compression (gpfs.compression) package found: {{ dir_path }}/gpfs.compression*{{\\n    scale_architecture }}*'\\nwhen: scale_install_gpfs_compression.matched < 1\\n\"},\n",
       " {'text': \"name: upgrade | Find Global Security Kit (GSKit) package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: gpfs.gskit*{{ scale_architecture }}*\\nregister: scale_install_gpfs_gskit\\n\"},\n",
       " {'text': \"name: upgrade | Check valid Global Security Kit (GSKit) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_gskit.matched > 0\\n  msg: 'No Global Security Kit (GSKit) package found: {{ dir_path }}/gpfs.gskit*{{\\n    scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS packages to list\\n \\n \\nvars:\\n  current_package: '{{ dir_path }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_gpfs_base.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_doc.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_msg.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_gskit.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS compression packages to list\\n \\n \\nvars:\\n  current_package: '{{ dir_path }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items: '{{ scale_install_gpfs_compression.files.0.path | basename }}'\\nwhen: scale_install_gpfs_compression.matched == 1\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS packages to list (prior to version 5.0.2.0)\\n \\n \\nvars:\\n  current_package: '{{ dir_path }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_add_packages_pre502 }}'\\nwhen: scale_version is version_compare('5.0.2', '<=')\\n\"},\n",
       " {'text': \"name: upgrade | Find GPFS gpl (gpfs.gpl) package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: gpfs.gpl*\\nregister: scale_install_gpfs_gpl\\n\"},\n",
       " {'text': \"name: upgrade | Check valid GPFS GPL (gpfs.gpl) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_gpl.matched > 0\\n  msg: 'No GPFS GPL (gpfs.gpl) package found: {{ dir_path }}/gpfs.gpl*'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS packages for building GPL module from source to list\\n \\n \\nvars:\\n  current_package: '{{ dir_path }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwhen: scale_install_gplbin_package is undefined\\nwith_items: '{{ scale_install_gpfs_gpl.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: upgrade | Find workflows package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: ibm_cloud_workflows*\\nregister: scale_install_cloud_workflows\\n\"},\n",
       " {'text': \"name: upgrade | Add workflows package from source to list\\n \\n \\nvars:\\n  current_package: '{{ dir_path }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items: '{{ scale_install_cloud_workflows.files.0.path | basename }}'\\nwhen: scale_install_cloud_workflows.matched == 1\\n\"},\n",
       " {'text': \"name: upgrade | Configure GPL module YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-gplbin\\n  description: IBM Spectrum Scale (GPFS) GPL module\\n  baseurl: '{{ scale_install_gplbin_repository_url }}'\\n  gpgcheck: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_gplbin_repository_url is defined\\n\"},\n",
       " {'text': \"name: upgrade | Configure GPL module repository\\n \\n \\napt_repository:\\n  name: spectrum-scale-gplbin\\n  description: IBM Spectrum Scale (GPFS) GPL module\\n  baseurl: '{{ scale_install_gplbin_repository_url }}'\\n  gpgcheck: false\\n  state: present\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_gplbin_repository_url is defined\\n\"},\n",
       " {'text': \"name: upgrade | Configure GPL module repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-gplbin\\n  description: IBM Spectrum Scale (GPFS) GPL module\\n  baseurl: '{{ scale_install_gplbin_repository_url }}'\\n  gpgcheck: false\\n  state: present\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n- scale_install_gplbin_repository_url is defined\\n\"},\n",
       " {'text': \"name: upgrade | Add dependencies for pre-built GPL module to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items: '{{ scale_install_gplbin_prereqs }}'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPL module package to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ scale_install_gplbin_package\\n    ] }}'\\n\"},\n",
       " {'text': \"name: install| Creates default directory\\n \\n \\nfile:\\n  path: '{{ scale_extracted_path }}'\\n  state: directory\\n  mode: a+x\\n  recurse: true\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path | basename\\n    }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: upgrade | Set installation package path\\n \\n \\nset_fact:\\n  dir_path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path |\\n    basename }}'\\n\"},\n",
       " {'text': \"name: upgrade | gpfs base path\\n \\n \\nset_fact:\\n  gpfs_path_url: '{{ dir_path }}'\\nwhen: scale_install_directory_pkg_path is defined\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ smb_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: upgrade | Extract installation package\\n \\n \\nvars:\\n  localpkg: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\ncommand: '{{ localpkg + '' --silent'' }}'\\nargs:\\n  creates: '{{ smb_extracted_path }}'\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ smb_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: upgrade | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the local\\n    installation package!\\n\"},\n",
       " {'text': \"name: upgrade | Delete installation package from node\\n \\n \\nfile:\\n  path: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\n  state: absent\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/rhel7/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '7'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/rhel8/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '8'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/sles12/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  == '12'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/sles15/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  >= '15'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/ubuntu16/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '16'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/ubuntu18/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '18'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '20'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/rhel7/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '7'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/rhel8/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '8'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/sles12/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  == '12'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/sles15/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  >= '15'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/ubuntu16/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '16'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/ubuntu18/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '18'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  >= '20'\\n\"},\n",
       " {'text': \"name: upgrade | Configure smb YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-smb\\n  description: IBM Spectrum Scale (smb)\\n  baseurl: '{{ scale_install_repository_url }}{{ scale_smb_url }}'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: upgrade | Configure smb zypper repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-smb-rpms\\n  repo: '{{ scale_install_repository_url }}{{ scale_smb_url }}'\\n  runrefresh: true\\n  state: present\\n  disable_gpg_check: true\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: upgrade | Configure smb APT repository\\n \\n \\napt_repository:\\n  filename: spectrum-scale-smb-debs\\n  repo: deb [trusted=yes] {{ scale_install_repository_url }}{{ scale_smb_url }} ./\\n  validate_certs: false\\n  state: present\\n  update_cache: true\\n  codename: IBM Spectrum Scale (SMB debs)\\n  mode: 511\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS smb packages to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_smb_packages }}'\\n\"},\n",
       " {'text': \"name: upgrade | Stat remote installation package\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  checksum_algorithm: md5\\nregister: scale_install_remotepkg\\n\"},\n",
       " {'text': \"name: upgrade | Check remote installation package\\n \\n \\nassert:\\n  that: scale_install_remotepkg.stat.exists\\n  msg: Please set the variable 'scale_install_remotepkg_path' to point to the remote\\n    installation package (accessible on Ansible managed node)!\\n\"},\n",
       " {'text': \"name: upgrade | Stat checksum file\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}.md5'\\nregister: scale_install_md5_file\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ smb_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: upgrade | Make installation package executable\\n \\n \\nfile:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  mode: a+x\\nwhen: not scale_install_gpfs_rpmdir.stat.exists\\n\"},\n",
       " {'text': \"name: upgrade | Extract installation package\\n \\n \\ncommand: '{{ scale_install_remotepkg_path + '' --silent'' }}'\\nargs:\\n  creates: '{{ smb_extracted_path }}'\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ smb_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: upgrade | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the remote\\n    installation package!\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/rhel7/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '7'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/rhel8/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '8'\\n\"},\n",
       " {'text': 'name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_rpms/sles12/\\nwhen: ansible_distribution in scale_sles_distribution\\n'},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/ubuntu16/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '16'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/ubuntu18/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '18'\\n\"},\n",
       " {'text': \"name: upgrade | smb path\\n \\n \\nset_fact:\\n  scale_smb_url: smb_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '20'\\n\"},\n",
       " {'text': 'name: upgrade | Initialize list of packages\\n \\n \\nset_fact:\\n  scale_install_all_packages: []\\n'},\n",
       " {'text': \"name: upgrade | Set the extracted package directory path\\n \\n \\nset_fact:\\n  smb_extracted_path: '{{ scale_extracted_path }}'\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages directory\\n \\n \\nstat:\\n  path: '{{ smb_extracted_path }}'\\nregister: scale_extracted_gpfs_dir\\n\"},\n",
       " {'text': \"name: upgrade | Upgrade GPFS SMB packages\\n \\n \\nyum:\\n  name: '{{ scale_install_all_packages }}'\\n  state: latest\\n  update_only: true\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\nregister: package_up\\nwhen: ansible_pkg_mgr == 'yum'\\n\"},\n",
       " {'text': \"name: upgrade | Upgrade GPFS SMB packages\\n \\n \\npackage:\\n  name: '{{ scale_install_all_packages }}'\\n  state: latest\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  >= '8'\\n\"},\n",
       " {'text': \"name: upgrade | Upgrade GPFS SMB packages\\n \\n \\nzypper:\\n  name: '{{ scale_install_all_packages }}'\\n  state: latest\\n  disable_gpg_check: false\\n\"},\n",
       " {'text': \"name: Install GPFS smb packages\\n \\n \\npackage:\\n  name: '{{ scale_install_all_packages }}'\\n  state: latest\\nwhen: scale_install_repository_url is defined\\n\"},\n",
       " {'text': \"name: upgrade | Upgrade GPFS SMB deb\\n \\n \\napt:\\n  deb: '{{ item }}'\\n  state: latest\\nwhen: scale_install_repository_url is not defined\\nwith_items:\\n- '{{ scale_install_all_packages }}'\\n\"},\n",
       " {'text': \"name: install | Initialize\\n \\n \\nset_fact:\\n  scale_fal_url: ''\\n\"},\n",
       " {'text': \"name: install | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/rhel7/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '7'\\n\"},\n",
       " {'text': \"name: install | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/rhel8/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '8'\\n\"},\n",
       " {'text': 'name: install | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution\\n'},\n",
       " {'text': 'name: install | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/sles15/\\nwhen: ansible_distribution in scale_sles_distribution\\n'},\n",
       " {'text': \"name: install | Configure GPFS Java YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-gpfs-java\\n  description: IBM Spectrum Scale (GPFS Java)\\n  baseurl: '{{ scale_install_repository_url }}gpfs_rpms/'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure GPFS Java APT repository\\n \\n \\napt_repository:\\n  filename: spectrum-scale-gpfs-java-debs\\n  repo: deb [trusted=yes] {{ scale_install_repository_url }}gpfs_debs/ ./\\n  validate_certs: false\\n  state: present\\n  update_cache: true\\n  codename: IBM Spectrum Scale (gpfs java debs)\\n  mode: 511\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure GPFS Java repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-gpfs-java\\n  description: IBM Spectrum Scale (GPFS java)\\n  repo: '{{ scale_install_repository_url }}gpfs_rpms/'\\n  disable_gpg_check: true\\n  state: present\\n  overwrite_multiple: true\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure fal YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-fal\\n  description: IBM Spectrum Scale (FAL)\\n  baseurl: '{{ scale_install_repository_url }}{{ scale_fal_url }}'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure fal APT repository\\n \\n \\napt_repository:\\n  filename: spectrum-scale-fal-debs\\n  repo: deb [trusted=yes] {{ scale_install_repository_url }}{{ scale_fal_url }} ./\\n  validate_certs: false\\n  state: present\\n  update_cache: true\\n  codename: IBM Spectrum Scale (FAL debs)\\n  mode: 511\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure fal repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-fal-sles\\n  description: IBM Spectrum Scale (FAL)\\n  repo: '{{ scale_install_repository_url }}{{ scale_fal_url }}'\\n  disable_gpg_check: false\\n  state: present\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n\"},\n",
       " {'text': \"name: install | Add GPFS file audit logging packages to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_auditlogging_packages }}'\\nwhen: (scale_fileauditlogging_enable | bool)\\n\"},\n",
       " {'text': \"name: install| Creates default directory\\n \\n \\nfile:\\n  path: '{{ scale_extracted_path }}'\\n  state: directory\\n  mode: a+x\\n  recurse: true\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path | basename\\n    }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\nset_fact:\\n  dir_path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path |\\n    basename }}'\\n\"},\n",
       " {'text': \"name: install | gpfs base path\\n \\n \\nset_fact:\\n  gpfs_path_url: '{{ dir_path }}'\\nwhen: scale_install_directory_pkg_path is defined\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\nvars:\\n  localpkg: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\ncommand: '{{ localpkg + '' --silent'' }}'\\nargs:\\n  creates: '{{ scale_gpfs_path_url }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_packagedir.stat.exists\\n  - scale_install_gpfs_packagedir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the local\\n    installation package!\\n\"},\n",
       " {'text': \"name: install | Delete installation package from node\\n \\n \\nfile:\\n  path: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\n  state: absent\\n\"},\n",
       " {'text': 'name: install | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/rhel/\\nwhen: ansible_distribution in scale_rhel_distribution\\n'},\n",
       " {'text': 'name: install | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution\\n'},\n",
       " {'text': 'name: install | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/rhel/\\nwhen: ansible_distribution in scale_sles_distribution\\n'},\n",
       " {'text': \"name: install | Stat remote installation package\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  checksum_algorithm: md5\\nregister: scale_install_remotepkg\\n\"},\n",
       " {'text': \"name: install | Check remote installation package\\n \\n \\nassert:\\n  that: scale_install_remotepkg.stat.exists\\n  msg: Please set the variable 'scale_install_remotepkg_path' to point to the remote\\n    installation package (accessible on Ansible managed node)!\\n\"},\n",
       " {'text': \"name: install | Stat checksum file\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}.md5'\\nregister: scale_install_md5_file\\n\"},\n",
       " {'text': 'name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: /usr/lpp/mmfs/{{ scale_version }}/gpfs_rpms\\nregister: scale_install_gpfs_rpmdir\\n'},\n",
       " {'text': \"name: install | Make installation package executable\\n \\n \\nfile:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  mode: a+x\\nwhen: not scale_install_gpfs_rpmdir.stat.exists\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\ncommand: '{{ scale_install_remotepkg_path + '' --silent'' }}'\\nargs:\\n  creates: /usr/lpp/mmfs/{{ scale_version }}/gpfs_rpms\\n\"},\n",
       " {'text': 'name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: /usr/lpp/mmfs/{{ scale_version }}/gpfs_rpms\\nregister: scale_install_gpfs_rpmdir\\n'},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the remote\\n    installation package!\\n\"},\n",
       " {'text': 'name: install | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/rhel/\\nwhen: ansible_distribution in scale_rhel_distribution\\n'},\n",
       " {'text': 'name: install | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution\\n'},\n",
       " {'text': 'name: install | file audit logging path\\n \\n \\nset_fact:\\n  scale_fal_url: gpfs_rpms/rhel/\\nwhen: ansible_distribution in scale_sles_distribution\\n'},\n",
       " {'text': 'name: install | Initialize list of packages\\n \\n \\nset_fact:\\n  scale_install_all_packages: []\\n'},\n",
       " {'text': \"name: install | Install GPFS file audit logging packages\\n \\n \\npackage:\\n  name: '{{ scale_install_all_packages }}'\\n  state: present\\nwhen: scale_install_repository_url is defined\\n\"},\n",
       " {'text': \"name: install | Install GPFS file audit logging packages\\n \\n \\npackage:\\n  name: '{{ scale_install_all_packages }}'\\n  state: present\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\n\"},\n",
       " {'text': \"name: auth | check if auth is enable\\n \\n \\ncommand: '{{ scale_command_path }}mmuserauth service list'\\nregister: scale_auth_status\\nignore_errors: true\\nfailed_when: false\\nrun_once: true\\n\"},\n",
       " {'text': \"name: auth | Copy the line as is in new file\\n \\n \\nlineinfile:\\n  path: '{{ ldapnewpath }}'\\n  create: true\\n  line: '{{ item }}'\\n  state: present\\nwhen: searchstring1 not in item and searchstring2 not in item\\nrun_once: true\\ndelegate_to: localhost\\n\"},\n",
       " {'text': \"name: install| Creates default directory\\n \\n \\nfile:\\n  path: '{{ scale_extracted_path }}'\\n  state: directory\\n  mode: a+x\\n  recurse: true\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path | basename\\n    }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Set installation package path\\n \\n \\nset_fact:\\n  dir_path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path |\\n    basename }}'\\n\"},\n",
       " {'text': \"name: install | gpfs base path\\n \\n \\nset_fact:\\n  scale_gpfs_path_url: '{{ dir_path }}'\\nwhen: scale_install_directory_pkg_path is defined\\n\"},\n",
       " {'text': 'name: Import a gpg key from a file\\n \\n \\nrpm_key:\\n  state: present\\n  key: \\'{{ dir_path }}/SpectrumScale_public_key.pgp\\'\\nwhen: ((ansible_distribution in scale_sles_distribution or ansible_distribution in\\n  scale_rhel_distribution) and scale_enable_gpg_check and scale_version >= \"5.0.5.0\")\\n'},\n",
       " {'text': \"name: install | Find GPFS BASE (gpfs.base) package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: gpfs.base*{{ scale_architecture }}*\\nregister: scale_install_gpfs_base\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS BASE (gpfs.base) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_base.matched > 0\\n  msg: 'No GPFS BASE (gpfs.base) package found: {{ dir_path }}/gpfs.base*{{ scale_architecture\\n    }}*'\\n\"},\n",
       " {'text': \"name: install | Find GPFS docs (gpfs.docs) package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: gpfs.docs*\\nregister: scale_install_gpfs_doc\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS docs (gpfs.docs) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_doc.matched > 0\\n  msg: 'No GPFS docs (gpfs.docs) package found: {{ dir_path }}/gpfs.docs*'\\n\"},\n",
       " {'text': \"name: install | Find gpfs.msg.en_US (gpfs.msg.en_US) package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: gpfs.msg.en*\\nregister: scale_install_gpfs_msg\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS (gpfs.msg.en_US) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_msg.matched > 0\\n  msg: 'No GPFS BASE (gpfs.base) package found: {{ dir_path }}/gpfs.msg.en*'\\n\"},\n",
       " {'text': \"name: install | Find GPFS Compression (gpfs.compression) package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: gpfs.compression*{{ scale_architecture }}*\\nregister: scale_install_gpfs_compression\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS Compression(gpfs.compression) package\\n \\n \\ndebug:\\n  msg: 'No GPFS Compression (gpfs.compression) package found: {{ dir_path }}/gpfs.compression*{{\\n    scale_architecture }}*'\\nwhen: scale_install_gpfs_compression.matched < 1\\n\"},\n",
       " {'text': \"name: install | Find Global Security Kit (GSKit) package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: gpfs.gskit*{{ scale_architecture }}*\\nregister: scale_install_gpfs_gskit\\n\"},\n",
       " {'text': \"name: install | Check valid Global Security Kit (GSKit) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_gskit.matched > 0\\n  msg: 'No Global Security Kit (GSKit) package found: {{ dir_path }}/gpfs.gskit*{{\\n    scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: install | Add GPFS packages to list\\n \\n \\nvars:\\n  current_package: '{{ dir_path }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_gpfs_base.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_doc.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_msg.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_gskit.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: install | Add GPFS compression packages to list\\n \\n \\nvars:\\n  current_package: '{{ dir_path }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items: '{{ scale_install_gpfs_compression.files.0.path | basename }}'\\nwhen: scale_install_gpfs_compression.matched == 1\\n\"},\n",
       " {'text': \"name: install | Add GPFS packages to list (prior to version 5.0.2.0)\\n \\n \\nvars:\\n  current_package: '{{ dir_path }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_add_packages_pre502 }}'\\nwhen: scale_version is version_compare('5.0.2', '<=')\\n\"},\n",
       " {'text': \"name: install | Find GPFS gpl (gpfs.gpl) package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: gpfs.gpl*\\nregister: scale_install_gpfs_gpl\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS GPL (gpfs.gpl) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_gpl.matched > 0\\n  msg: 'No GPFS GPL (gpfs.gpl) package found: {{ dir_path }}/gpfs.gpl*'\\n\"},\n",
       " {'text': \"name: install | Add GPFS packages for building GPL module from source to list\\n \\n \\nvars:\\n  current_package: '{{ dir_path }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwhen: scale_install_gplbin_package is undefined\\nwith_items: '{{ scale_install_gpfs_gpl.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: install | Find workflows package\\n \\n \\nfind:\\n  paths: '{{ dir_path }}'\\n  patterns: ibm_cloud_workflows*\\nregister: scale_install_cloud_workflows\\n\"},\n",
       " {'text': \"name: install | Add workflows package from source to list\\n \\n \\nvars:\\n  current_package: '{{ dir_path }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items: '{{ scale_install_cloud_workflows.files.0.path | basename }}'\\nwhen: scale_install_cloud_workflows.matched == 1\\n\"},\n",
       " {'text': \"name: install | Find GPFS License (gpfs.license) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.license*{{ scale_architecture }}*\\nregister: scale_install_gpfs_license\\n\"},\n",
       " {'text': 'name: install | Check valid GPFS License (gpfs.license) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_license.matched > 0\\n  msg: \\'No GPFS License (gpfs.license) package found: \"{{ scale_gpfs_path_url }}/gpfs.license*{{\\n    scale_architecture }}*\"\\'\\n'},\n",
       " {'text': 'name: install | Check valid only one GPFS License (gpfs.license) package\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_license.matched > 0\\n  - scale_install_gpfs_license.matched == 1\\n  msg: \\'More than one GPFS License (gpfs.license) package found: \"{{ scale_gpfs_path_url\\n    }}/gpfs.license*{{ scale_architecture }}*\"\\'\\n'},\n",
       " {'text': \"name: install | Find GPFS License package\\n \\n \\nvars:\\n  gpfs_license_package: '{{ scale_install_gpfs_license.files.0.path | basename }}'\\nset_fact:\\n  scale_gpfs_license_package: '{{ gpfs_license_package }}'\\n\"},\n",
       " {'text': \"name: install | Add GPFS License packages to list\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_license_packages: '{{ scale_install_license_packages + [ current_package\\n    ] }}'\\nwith_items:\\n- '{{ scale_install_gpfs_license.files.0.path | basename }}'\\n\"},\n",
       " {'text': 'name: install | Add GPFS Dependent License packages to list\\n \\n \\nvars:\\n  license_package: \\'{{ scale_install_gpfs_license.files.0.path | basename }}\\'\\n  current_package: \\'{{ scale_gpfs_path_url }}/{{ item }}\\'\\nset_fact:\\n  scale_install_license_packages: \\'{{ scale_install_license_packages + [ current_package\\n    ] }}\\'\\nwith_items:\\n- \\'{{ scale_install_gpfs_adv.files.0.path | basename }}\\'\\n- \\'{{ scale_install_gpfs_crypto.files.0.path | basename }}\\'\\nwhen:\\n- \\'\"gpfs.license.std\" not in scale_gpfs_license_package\\'\\n- \\'\"gpfs.license.da\" not in scale_gpfs_license_package\\'\\n'},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\nvars:\\n  localpkg: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\ncommand: '{{ ''/bin/bash '' + localpkg + '' --silent'' }}'\\nargs:\\n  creates: '{{ scale_gpfs_path_url }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_packagedir.stat.exists\\n  - scale_install_gpfs_packagedir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the local\\n    installation package!\\n\"},\n",
       " {'text': \"name: install | Delete installation package from node\\n \\n \\nfile:\\n  path: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\n  state: absent\\n\"},\n",
       " {'text': \"name: install | Find GPFS BASE (gpfs.base) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.base*{{ scale_architecture }}*\\nregister: scale_install_gpfs_base\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS BASE (gpfs.base) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_base.matched > 0\\n  msg: 'No GPFS BASE (gpfs.base) package found: {{ scale_gpfs_path_url }}/gpfs.base*{{\\n    scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: install | Find GPFS docs (gpfs.docs) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.docs*\\nregister: scale_install_gpfs_doc\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS docs (gpfs.docs) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_doc.matched > 0\\n  msg: 'No GPFS docs (gpfs.docs) package found: {{ scale_gpfs_path_url }}/gpfs.docs*'\\n\"},\n",
       " {'text': \"name: install | Find gpfs.msg.en_US (gpfs.msg.en_US) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.msg.en*\\nregister: scale_install_gpfs_msg\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS (gpfs.msg.en_US) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_msg.matched > 0\\n  msg: 'No GPFS BASE (gpfs.base) package found: {{ scale_gpfs_path_url }}/gpfs.msg.en*'\\n\"},\n",
       " {'text': \"name: install | Find GPFS Compression (gpfs.compression) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.compression*{{ scale_architecture }}*\\nregister: scale_install_gpfs_compression\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS Compression(gpfs.compression) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_compression.matched > 0\\n  msg: 'No GPFS Compression (gpfs.compression) package found: {{ scale_gpfs_path_url\\n    }}/gpfs.compression*{{ scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: install | Find Global Security Kit (GSKit) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.gskit*{{ scale_architecture }}*\\nregister: scale_install_gpfs_gskit\\n\"},\n",
       " {'text': \"name: install | Check valid Global Security Kit (GSKit) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_gskit.matched > 0\\n  msg: 'No Global Security Kit (GSKit) package found: {{ scale_gpfs_path_url }}/gpfs.gskit*{{\\n    scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: install | Add GPFS packages to list\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_gpfs_base.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_doc.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_msg.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_gskit.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_compression.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: install | Add GPFS packages to list (prior to version 5.0.2.0)\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_add_packages_pre502 }}'\\nwhen: scale_version is version_compare('5.0.2', '<=')\\n\"},\n",
       " {'text': \"name: install | Find GPFS gpl (gpfs.gpl) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.gpl*\\nregister: scale_install_gpfs_gpl\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS GPL (gpfs.gpl) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_gpl.matched > 0\\n  msg: 'No GPFS GPL (gpfs.gpl) package found: {{ scale_gpfs_path_url }}/gpfs.gpl*'\\n\"},\n",
       " {'text': \"name: install | Add GPFS packages for building GPL module from source to list\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwhen: scale_install_gplbin_package is undefined\\nwith_items: '{{ scale_install_gpfs_gpl.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: update | Find current version\\n \\n \\nshell: /usr/lpp/mmfs/bin/mmdiag --version -Y | grep -v HEADER | cut -d ':' -f 7 |\\n  tr -d '[:space:]'\\nregister: scale_current_version\\nchanged_when: false\\nfailed_when: false\\n\"},\n",
       " {'text': \"name: update | Find current gpfs version\\n \\n \\nshell: rpm -q gpfs.base --queryformat '%{VERSION}-%{RELEASE}\\\\n'\\nargs:\\n  warn: false\\nregister: scale_current_version_gpfs\\nchanged_when: false\\nfailed_when: false\\n\"},\n",
       " {'text': 'name: update | Find available version\\n \\n \\nshell: rpm -qp \"{{ scale_gpfs_path_url }}/gpfs.base-*.{{ scale_architecture }}.rpm\"\\n  --qf \\'%{VERSION}-%{RELEASE}\\\\n\\'\\nargs:\\n  warn: false\\nregister: scale_repo_gpfsversion\\nwhen: scale_install_repository_url is undefined\\nchanged_when: false\\n'},\n",
       " {'text': \"name: update | Check if node needs to be updated\\n \\n \\nset_fact:\\n  scale_install_needsupdate: '{{ scale_current_version_gpfs.stdout != scale_repo_gpfsversion.stdout\\n    }}'\\n  scale_repo_gpfsversion: '{{ scale_repo_gpfsversion.stdout }}'\\nwhen: scale_install_repository_url is undefined\\n\"},\n",
       " {'text': 'name: update | Get package version\\n \\n \\nyum:\\n  list: gpfs.base\\nregister: package_name_version\\n'},\n",
       " {'text': \"name: update | Set package version\\n \\n \\nset_fact:\\n  package_name_version: '{{ package_name_version.results|selectattr(''yumstate'',''match'',''available'')|map(attribute=''version'')|list|first\\n    }}'\\n  package_name_release: '{{ package_name_version.results|selectattr(''yumstate'',''match'',''available'')|map(attribute=''release'')|list|first\\n    }}'\\nwhen:\\n- '''available'' in package_name_version.results | map(attribute=''yumstate'') | list'\\n\"},\n",
       " {'text': \"name: update | Set gpfs package version\\n \\n \\nset_fact:\\n  package_gpfs_version: '{{ package_name_version }}-{{ package_name_release }}'\\nwhen: scale_install_repository_url is defined\\n\"},\n",
       " {'text': \"name: update | Check if node needs to be updated\\n \\n \\nset_fact:\\n  scale_install_needsupdate: '{{ scale_current_version_gpfs.stdout != package_gpfs_version\\n    }}'\\n  scale_repo_gpfsversion: '{{ package_gpfs_version }}'\\nwhen: scale_install_repository_url is defined\\n\"},\n",
       " {'text': \"name: install | Configure GPL module YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-gplbin\\n  description: IBM Spectrum Scale (GPFS) GPL module\\n  baseurl: '{{ scale_install_gplbin_repository_url }}'\\n  gpgcheck: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_gplbin_repository_url is defined\\n\"},\n",
       " {'text': \"name: install | Configure GPL module repository\\n \\n \\napt_repository:\\n  name: spectrum-scale-gplbin\\n  description: IBM Spectrum Scale (GPFS) GPL module\\n  baseurl: '{{ scale_install_gplbin_repository_url }}'\\n  gpgcheck: false\\n  state: present\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_gplbin_repository_url is defined\\n\"},\n",
       " {'text': \"name: install | Configure GPL module repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-gplbin\\n  description: IBM Spectrum Scale (GPFS) GPL module\\n  baseurl: '{{ scale_install_gplbin_repository_url }}'\\n  gpgcheck: false\\n  state: present\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n- scale_install_gplbin_repository_url is defined\\n\"},\n",
       " {'text': \"name: install | Add dependencies for pre-built GPL module to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items: '{{ scale_install_gplbin_prereqs }}'\\n\"},\n",
       " {'text': \"name: install | Add GPL module package to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ scale_install_gplbin_package\\n    ] }}'\\n\"},\n",
       " {'text': \"name: update | Find current version\\n \\n \\nshell: /usr/lpp/mmfs/bin/mmdiag --version -Y | grep -v HEADER | cut -d ':' -f 7 |\\n  tr -d '[:space:]'\\nregister: scale_current_version\\nchanged_when: false\\nfailed_when: false\\n\"},\n",
       " {'text': \"name: update | Check if node needs to be updated\\n \\n \\nset_fact:\\n  scale_install_needsupdate: '{{ scale_current_version.stdout != scale_version }}'\\n\"},\n",
       " {'text': \"name: install | Stat remote installation package\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  checksum_algorithm: md5\\nregister: scale_install_remotepkg\\n\"},\n",
       " {'text': \"name: install | Check remote installation package\\n \\n \\nassert:\\n  that: scale_install_remotepkg.stat.exists\\n  msg: Please set the variable 'scale_install_remotepkg_path' to point to the remote\\n    installation package (accessible on Ansible managed node)!\\n\"},\n",
       " {'text': \"name: install | Stat checksum file\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}.md5'\\nregister: scale_install_md5_file\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Make installation package executable\\n \\n \\nfile:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  mode: a+x\\nwhen: not scale_install_gpfs_packagedir.stat.exists\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\ncommand: '{{ scale_install_remotepkg_path + '' --silent'' }}'\\nargs:\\n  creates: '{{ scale_gpfs_path_url }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_packagedir.stat.exists\\n  - scale_install_gpfs_packagedir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the remote\\n    installation package!\\n\"},\n",
       " {'text': \"name: install | Find GPFS BASE (gpfs.base) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.base*{{ scale_architecture }}*\\nregister: scale_install_gpfs_base\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS BASE (gpfs.base) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_base.matched > 0\\n  msg: 'No GPFS BASE (gpfs.base) package found: {{ scale_gpfs_path_url }}/gpfs.base*{{\\n    scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: install | Find GPFS docs (gpfs.docs) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.docs*\\nregister: scale_install_gpfs_doc\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS docs (gpfs.docs) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_doc.matched > 0\\n  msg: 'No GPFS docs (gpfs.docs) package found: {{ scale_gpfs_path_url }}/gpfs.docs*'\\n\"},\n",
       " {'text': \"name: install | Find gpfs.msg.en_US (gpfs.msg.en_US) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.msg.en*\\nregister: scale_install_gpfs_msg\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS (gpfs.msg.en_US) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_msg.matched > 0\\n  msg: 'No GPFS BASE (gpfs.base) package found: {{ scale_gpfs_path_url }}/gpfs.msg.en*'\\n\"},\n",
       " {'text': \"name: install | Find GPFS Compression (gpfs.compression) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.compression*{{ scale_architecture }}*\\nregister: scale_install_gpfs_compression\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS Compression(gpfs.compression) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_compression.matched > 0\\n  msg: 'No GPFS Compression (gpfs.compression) package found: {{ scale_gpfs_path_url\\n    }}/gpfs.compression*{{ scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: install | Find Global Security Kit (GSKit) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.gskit*{{ scale_architecture }}*\\nregister: scale_install_gpfs_gskit\\n\"},\n",
       " {'text': \"name: install | Check valid Global Security Kit (GSKit) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_gskit.matched > 0\\n  msg: 'No Global Security Kit (GSKit) package found: {{ scale_gpfs_path_url }}/gpfs.gskit*{{\\n    scale_architecture }}*'\\n\"},\n",
       " {'text': \"name: install | Add GPFS packages to list\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_gpfs_base.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_doc.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_msg.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_gskit.files.0.path | basename }}'\\n- '{{ scale_install_gpfs_compression.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: install | Add GPFS packages to list (prior to version 5.0.2.0)\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_add_packages_pre502 }}'\\nwhen: scale_version is version_compare('5.0.2', '<=')\\n\"},\n",
       " {'text': \"name: install | Find GPFS gpl (gpfs.gpl) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.gpl*\\nregister: scale_install_gpfs_gpl\\n\"},\n",
       " {'text': \"name: install | Check valid GPFS GPL (gpfs.gpl) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_gpl.matched > 0\\n  msg: 'No GPFS GPL (gpfs.gpl) package found: {{ scale_gpfs_path_url }}/gpfs.gpl*'\\n\"},\n",
       " {'text': \"name: install | Add GPFS packages for building GPL module from source to list\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwhen: scale_install_gplbin_package is undefined\\nwith_items: '{{ scale_install_gpfs_gpl.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: install | Configure GPFS YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-gpfs\\n  description: IBM Spectrum Scale (GPFS)\\n  baseurl: '{{ scale_install_repository_url }}gpfs_rpms/'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure core APT repository\\n \\n \\napt_repository:\\n  filename: spectrum-scale-core-debs\\n  repo: deb [trusted=yes] {{ scale_install_repository_url }}gpfs_debs/ ./\\n  validate_certs: false\\n  state: present\\n  update_cache: true\\n  codename: IBM Spectrum Scale (core debs)\\n  mode: 511\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure GPFS repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-gpfs\\n  description: IBM Spectrum Scale (GPFS)\\n  repo: '{{ scale_install_repository_url }}gpfs_rpms/'\\n  disable_gpg_check: true\\n  state: present\\n  overwrite_multiple: true\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Add GPFS packages to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_install_gpfs_packages }}'\\n- gpfs.gskit\\n\"},\n",
       " {'text': \"name: install | Add GPFS packages to list (prior to version 5.0.2.0)\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_install_add_packages_pre502 }}'\\nwhen: scale_version is version_compare('5.0.2', '<=')\\n\"},\n",
       " {'text': \"name: install | Add GPFS packages for building GPL module from source to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwhen: scale_install_gplbin_package is undefined\\nwith_items: '{{ scale_install_gplsrc_packages }}'\\n\"},\n",
       " {'text': \"name: install | Get license package\\n \\n \\nyum:\\n  list: gpfs.license.*\\nregister: package_name_version\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n\"},\n",
       " {'text': \"name: Find license package\\n \\n \\nshell:\\n  cmd: apt-cache show gpfs.license.*\\nregister: package_name\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n\"},\n",
       " {'text': \"name: install | Get license package\\n \\n \\nshell:\\n  cmd: zypper info gpfs.license.* | grep Name | cut -d ':' -f 2 | tr -d '[:space:]'\\nargs:\\n  warn: false\\nregister: package_name_version_zypp\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n\"},\n",
       " {'text': 'name: install | Check valid only one GPFS License (gpfs.license) RPM\\n \\n \\nassert:\\n  that: package_name_version.results | selectattr(\"yumstate\", \"match\", \"available\")\\n    | list | length >= 1\\n  msg: \\'More than one GPFS License (gpfs.license) RPM found: \"gpfs.license*{{ scale_architecture\\n    }}*\"\\'\\nwhen:\\n- ansible_pkg_mgr == \\'yum\\' or ansible_pkg_mgr == \\'dnf\\'\\n'},\n",
       " {'text': \"name: install | Find GPFS License package\\n \\n \\nvars:\\n  gpfs_license_package: '{{ package_name_version.results|selectattr(''yumstate'',''match'',''available'')|map(attribute=''name'')|list\\n    }}'\\nset_fact:\\n  scale_gpfs_license_package: '{{ gpfs_license_package }}'\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n\"},\n",
       " {'text': \"name: install | Find GPFS License package\\n \\n \\nset_fact:\\n  scale_gpfs_license_package: '{{ package_name.stdout_lines.0[9:] }}'\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n\"},\n",
       " {'text': \"name: install | Find GPFS License package\\n \\n \\nset_fact:\\n  scale_gpfs_license_package: '{{ package_name_version_zypp.stdout }}'\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n\"},\n",
       " {'text': 'name: install | Add GPFS license packages to list\\n \\n \\nset_fact:\\n  scale_install_license_packages: \\'{{ scale_install_license_packages + [ item ] }}\\'\\nwith_items:\\n- \\'{{ scale_gpfs_license_package }}\\'\\n- gpfs.adv\\n- gpfs.crypto\\nwhen:\\n- \\'\"gpfs.license.std\" not in scale_gpfs_license_package\\'\\n- \\'\"gpfs.license.da\" not in scale_gpfs_license_package\\'\\n'},\n",
       " {'text': \"name: install | Add GPFS license packages to list\\n \\n \\nset_fact:\\n  scale_install_license_packages: '{{ scale_gpfs_license_package }}'\\nwhen: '''gpfs.license.std'' in scale_gpfs_license_package or ''gpfs.license.da'' in\\n  scale_gpfs_license_package'\\n\"},\n",
       " {'text': 'name: install | Initialize list of packages\\n \\n \\nset_fact:\\n  scale_install_all_packages: []\\n  scale_install_license_packages: []\\n'},\n",
       " {'text': 'name: install | Initialize list of packages\\n \\n \\nset_fact:\\n  scale_install_all_packages: []\\n'},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\nvars:\\n  localpkg: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\ncommand: '{{ localpkg + '' --silent'' }}'\\nargs:\\n  creates: '{{ scale_gpfs_path_url }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_packagedir.stat.exists\\n  - scale_install_gpfs_packagedir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the local\\n    installation package!\\n\"},\n",
       " {'text': \"name: install | Delete installation package from node\\n \\n \\nfile:\\n  path: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\n  state: absent\\n\"},\n",
       " {'text': 'name: install | Set package arch\\n \\n \\nset_fact:\\n  package_arch: el\\n'},\n",
       " {'text': 'name: install | Set package arch\\n \\n \\nset_fact:\\n  package_arch: U\\nwhen: ansible_distribution in scale_ubuntu_distribution\\n'},\n",
       " {'text': 'name: install | Set package arch\\n \\n \\nset_fact:\\n  package_arch: sles\\nwhen: ansible_distribution in scale_sles_distribution\\n'},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_rpms/rhel7/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '7'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_rpms/rhel8/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '8'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_debs/ubuntu/ubuntu16/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '16'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_debs/ubuntu/ubuntu18/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '18'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '20'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_rpms/sles12/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  == '12'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_rpms/sles15/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  == '15'\\n\"},\n",
       " {'text': \"name: install | Find gpfs.gss.pmsensors (gpfs.gss.pmsensors) RPM\\n \\n \\nfind:\\n  paths: '{{ scale_extracted_path }}/{{ scale_zimon_url }}'\\n  patterns: gpfs.gss.pmsensors*{{ package_arch }}{{ ansible_distribution_major_version\\n    }}*\\nregister: scale_install_gpfs_pmsensors\\n\"},\n",
       " {'text': 'name: install | Check valid GPFS (gpfs.gss.pmsensors) RPM\\n \\n \\nassert:\\n  that: scale_install_gpfs_pmsensors.matched > 0\\n  msg: \\'No GPFS pmsensors (gpfs.gss.pmsensors) RPM found: \"{{ scale_extracted_path\\n    }}/{{ scale_zimon_url }}/gpfs.gss.pmsensors*{{ package_arch }}{{ ansible_distribution_major_version\\n    }}*\"\\'\\n'},\n",
       " {'text': \"name: install | Add GPFS zimon sensors packages to list\\n \\n \\nvars:\\n  current_package: '{{ scale_extracted_path }}/{{ scale_zimon_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_gpfs_pmsensors.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: install | Stat remote installation package\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  checksum_algorithm: md5\\nregister: scale_install_remotepkg\\n\"},\n",
       " {'text': \"name: install | Check remote installation package\\n \\n \\nassert:\\n  that: scale_install_remotepkg.stat.exists\\n  msg: Please set the variable 'scale_install_remotepkg_path' to point to the remote\\n    installation package (accessible on Ansible managed node)!\\n\"},\n",
       " {'text': \"name: install | Stat checksum file\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}.md5'\\nregister: scale_install_md5_file\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Make installation package executable\\n \\n \\nfile:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  mode: a+x\\nwhen: not scale_install_gpfs_rpmdir.stat.exists\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\ncommand: '{{ scale_install_remotepkg_path + '' --silent'' }}'\\nargs:\\n  creates: '{{ scale_gpfs_path_url }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_gpfs_path_url }}'\\nregister: scale_install_gpfs__rpmdir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs__rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the remote\\n    installation package!\\n\"},\n",
       " {'text': 'name: install | Set package arch\\n \\n \\nset_fact:\\n  package_arch: el\\n'},\n",
       " {'text': 'name: install | Set package arch\\n \\n \\nset_fact:\\n  package_arch: U\\nwhen: ansible_distribution in scale_ubuntu_distribution\\n'},\n",
       " {'text': 'name: install | Set package arch\\n \\n \\nset_fact:\\n  package_arch: sles\\nwhen: ansible_distribution in scale_sles_distribution\\n'},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_rpms/rhel7/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '7'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_rpms/rhel8/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '8'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_debs/ubuntu/ubuntu16/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '16'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_debs/ubuntu/ubuntu18/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '18'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '20'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_rpms/sles12/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  == '12'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_rpms/sles15/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  == '15'\\n\"},\n",
       " {'text': \"name: install | Find gpfs.gss.pmsensors (gpfs.gss.pmsensors) RPM\\n \\n \\nfind:\\n  paths: '{{ scale_extracted_path }}/{{ scale_zimon_url }}'\\n  patterns: gpfs.gss.pmsensors*{{ package_arch }}{{ ansible_distribution_major_version\\n    }}*\\nregister: scale_install_gpfs_pmsensors\\n\"},\n",
       " {'text': 'name: install | Check valid GPFS (gpfs.gss.pmsensors) RPM\\n \\n \\nassert:\\n  that: scale_install_gpfs_pmsensors.matched > 0\\n  msg: \\'No GPFS pmsensors (gpfs.gss.pmsensors) RPM found: \"{{ scale_extracted_path\\n    }}/{{ scale_zimon_url }}/gpfs.gss.pmsensors*{{ package_arch }}{{ ansible_distribution_major_version\\n    }}*\"\\'\\n'},\n",
       " {'text': \"name: install | Add GPFS zimon sensors packages to list\\n \\n \\nvars:\\n  current_package: '{{ scale_extracted_path }}/{{ scale_zimon_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_gpfs_pmsensors.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: install| Creates default directory\\n \\n \\nfile:\\n  path: '{{ scale_extracted_path }}'\\n  state: directory\\n  mode: a+x\\n  recurse: true\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path | basename\\n    }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\nset_fact:\\n  dir_path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path |\\n    basename }}'\\n\"},\n",
       " {'text': \"name: install | gpfs base path\\n \\n \\nset_fact:\\n  scale_gpfs_path_url: '{{ dir_path }}'\\nwhen: scale_install_directory_pkg_path is defined\\n\"},\n",
       " {'text': \"name: install | Find gpfs.gss.pmsensors (gpfs.gss.pmsensors) package\\n \\n \\nfind:\\n  paths: '{{ scale_gpfs_path_url }}'\\n  patterns: gpfs.gss.pmsensors*el{{ ansible_distribution_major_version }}.{{ scale_architecture\\n    }}*\\nregister: scale_install_gpfs_pmsensors\\n\"},\n",
       " {'text': 'name: install | Check valid GPFS (gpfs.gss.pmsensors) package\\n \\n \\nassert:\\n  that: scale_install_gpfs_pmsensors.matched > 0\\n  msg: \\'No GPFS pmsensors (gpfs.gss.pmsensors) package found: \"{{ scale_gpfs_path_url\\n    }}/gpfs.gss.pmsensors*el{{ ansible_distribution_major_version }}.{{ scale_architecture\\n    }}*\"\\'\\n'},\n",
       " {'text': \"name: install | Add GPFS zimon sensors packages to list\\n \\n \\nvars:\\n  current_package: '{{ scale_gpfs_path_url }}/{{ item }}'\\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ current_package ]\\n    }}'\\nwith_items:\\n- '{{ scale_install_gpfs_pmsensors.files.0.path | basename }}'\\n\"},\n",
       " {'text': \"name: Initialize\\n \\n \\nset_fact:\\n  scale_zimon_url: ''\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_rpms/rhel7/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '7'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_rpms/rhel8/\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  == '8'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_debs/ubuntu/ubuntu16/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '16'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_debs/ubuntu/ubuntu18/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '18'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_debs/ubuntu/\\nwhen: ansible_distribution in scale_ubuntu_distribution and ansible_distribution_major_version\\n  == '20'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_rpms/sles12/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  == '12'\\n\"},\n",
       " {'text': \"name: install | zimon path\\n \\n \\nset_fact:\\n  scale_zimon_url: zimon_rpms/sles15/\\nwhen: ansible_distribution in scale_sles_distribution and ansible_distribution_major_version\\n  == '15'\\n\"},\n",
       " {'text': \"name: install | Configure ZIMon YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-zimon\\n  description: IBM Spectrum Scale (ZIMon)\\n  baseurl: '{{ scale_install_repository_url }}{{ scale_zimon_url }}'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure zimon APT repository\\n \\n \\napt_repository:\\n  filename: spectrum-scale-zimon-debs\\n  repo: deb [trusted=yes] {{ scale_install_repository_url }}{{ scale_zimon_url }}\\n    ./\\n  validate_certs: false\\n  state: present\\n  update_cache: true\\n  codename: IBM Spectrum Scale (Zimon debs)\\n  mode: 511\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure ZIMon repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-zimon\\n  description: IBM Spectrum Scale (ZIMon)\\n  repo: '{{ scale_install_repository_url }}{{ scale_zimon_url }}'\\n  disable_gpg_check: false\\n  state: present\\n  overwrite_multiple: true\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n\"},\n",
       " {'text': \"name: install | package methods\\n \\n \\nset_fact:\\n  scale_zimon_sensors_packages: '{{ scale_zimon_sensors_packages }}'\\n  scale_zimon_collector_packages: '{{ scale_zimon_collector_packages }}'\\nwhen: ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n\"},\n",
       " {'text': \"name: install | package methods\\n \\n \\nset_fact:\\n  scale_zimon_sensors_packages: '{{ scale_zimon_sensors_packages_ubuntu }}'\\n  scale_zimon_collector_packages: '{{ scale_zimon_collector_packages_ubuntu }}'\\nwhen: ansible_pkg_mgr == 'apt'\\n\"},\n",
       " {'text': \"name: install | package methods\\n \\n \\nset_fact:\\n  scale_zimon_sensors_packages: '{{ scale_zimon_sensors_packages_suse }}'\\n  scale_zimon_collector_packages: '{{ scale_zimon_collector_packages_suse }}'\\nwhen: ansible_pkg_mgr == 'zypper'\\n\"},\n",
       " {'text': \"name: install | Add GPFS sensors packages to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_zimon_sensors_packages }}'\\n\"},\n",
       " {'text': \"name: install | Add GPFS collector packages to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_zimon_collector_packages }}'\\nwhen: (scale_zimon_collector | bool) or (scale_cluster_gui | bool)\\n\"},\n",
       " {'text': \"name: install | Install GPFS Zimon packages\\n \\n \\npackage:\\n  name: '{{ scale_install_all_packages }}'\\n  state: present\\nwhen: scale_install_repository_url is defined\\n\"},\n",
       " {'text': \"name: install | Install GPFS Zimon packages\\n \\n \\npackage:\\n  name: '{{ scale_install_all_packages }}'\\n  state: present\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\n\"},\n",
       " {'text': \"name: install| Creates default directory\\n \\n \\nfile:\\n  path: '{{ scale_extracted_path }}'\\n  state: directory\\n  mode: a+x\\n  recurse: true\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path | basename\\n    }}'\\nregister: scale_install_gpfs_packagedir\\n\"},\n",
       " {'text': \"name: upgrade | Set installation package path\\n \\n \\nset_fact:\\n  dir_path: '{{ scale_extracted_path + ''/'' + scale_install_directory_pkg_path |\\n    basename }}'\\n\"},\n",
       " {'text': \"name: upgrade | gpfs base path\\n \\n \\nset_fact:\\n  gpfs_path_url: '{{ dir_path }}'\\nwhen: scale_install_directory_pkg_path is defined\\n\"},\n",
       " {'text': 'name: upgrade | Initialize list of packages\\n \\n \\nset_fact:\\n  scale_install_all_packages: []\\n'},\n",
       " {'text': \"name: upgrade | Set the extracted package directory path\\n \\n \\nset_fact:\\n  gnr_extracted_path: '{{ scale_extracted_path }}'\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages directory\\n \\n \\nstat:\\n  path: '{{ gnr_extracted_path }}'\\nregister: scale_extracted_gpfs_dir\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ gnr_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: upgrade | Extract installation package\\n \\n \\nvars:\\n  localpkg: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\ncommand: '{{ localpkg + '' --silent'' }}'\\nargs:\\n  creates: '{{ gnr_extracted_path }}'\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ gnr_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: upgrade | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the local\\n    installation package!\\n\"},\n",
       " {'text': \"name: upgrade | Delete installation package from node\\n \\n \\nfile:\\n  path: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\n  state: absent\\n\"},\n",
       " {'text': 'name: upgrade | gnr path\\n \\n \\nset_fact:\\n  scale_gnr_url: gpfs_rpms/\\nwhen: ansible_distribution in scale_rhel_distribution\\n'},\n",
       " {'text': \"name: upgrade | Stat remote installation package\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  checksum_algorithm: md5\\nregister: scale_install_remotepkg\\n\"},\n",
       " {'text': \"name: upgrade | Check remote installation package\\n \\n \\nassert:\\n  that: scale_install_remotepkg.stat.exists\\n  msg: Please set the variable 'scale_install_remotepkg_path' to point to the remote\\n    installation package (accessible on Ansible managed node)!\\n\"},\n",
       " {'text': \"name: upgrade | Stat checksum file\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}.md5'\\nregister: scale_install_md5_file\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ gnr_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: upgrade | Make installation package executable\\n \\n \\nfile:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  mode: a+x\\nwhen: not scale_install_gpfs_rpmdir.stat.exists\\n\"},\n",
       " {'text': \"name: upgrade | Extract installation package\\n \\n \\ncommand: '{{ scale_install_remotepkg_path + '' --silent'' }}'\\nargs:\\n  creates: '{{ gnr_extracted_path }}'\\n\"},\n",
       " {'text': \"name: upgrade | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ gnr_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: upgrade | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the remote\\n    installation package!\\n\"},\n",
       " {'text': 'name: upgrade | gnr path\\n \\n \\nset_fact:\\n  scale_gnr_url: gpfs_rpms/\\nwhen: ansible_distribution in scale_rhel_distribution\\n'},\n",
       " {'text': \"name: Initialize\\n \\n \\nset_fact:\\n  scale_gnr_url: ''\\n\"},\n",
       " {'text': 'name: upgrade | gnr path\\n \\n \\nset_fact:\\n  scale_gnr_url: gpfs_rpms/\\nwhen: ansible_distribution in scale_rhel_distribution\\n'},\n",
       " {'text': \"name: upgrade | Configure gnr YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-gnr\\n  description: IBM Spectrum Scale (gnr)\\n  baseurl: '{{ scale_install_repository_url }}{{ scale_gnr_url }}'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: upgrade | Add GPFS gnr packages to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_gnr_packages }}'\\n\"},\n",
       " {'text': \"name: upgrade | Upgrade GPFS gnr packages\\n \\n \\nyum:\\n  name: '{{ scale_install_all_packages }}'\\n  state: latest\\n  update_only: true\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\nwhen: ansible_pkg_mgr == 'yum'\\n\"},\n",
       " {'text': \"name: upgrade | Upgrade GPFS gnr packages\\n \\n \\npackage:\\n  name: '{{ scale_install_all_packages }}'\\n  state: latest\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\nwhen: ansible_distribution in scale_rhel_distribution and ansible_distribution_major_version\\n  >= '8'\\n\"},\n",
       " {'text': 'name: install | Initialize list of packages\\n \\n \\nset_fact:\\n  scale_install_all_packages: []\\n'},\n",
       " {'text': \"name: install | Set the extracted package directory path\\n \\n \\nset_fact:\\n  scale_callhome_extracted_path: '{{ scale_extracted_path }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages directory\\n \\n \\nstat:\\n  path: '{{ scale_callhome_extracted_path }}'\\nregister: scale_extracted_gpfs_dir\\n\"},\n",
       " {'text': \"name: install | Configure Callhome YUM repository\\n \\n \\nyum_repository:\\n  name: spectrum-scale-callhome-rpms\\n  description: IBM Spectrum Scale (Callhome RPMS)\\n  baseurl: '{{ scale_install_repository_url }}gpfs_rpms/'\\n  gpgcheck: '{{ scale_install_gpgcheck }}'\\n  repo_gpgcheck: false\\n  sslverify: false\\n  state: present\\nnotify: yum-clean-metadata\\nwhen:\\n- ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure Callhome APT repository\\n \\n \\napt_repository:\\n  filename: spectrum-scale-callhome-debs\\n  repo: deb [trusted=yes] {{ scale_install_repository_url }}gpfs_debs/ ./\\n  validate_certs: false\\n  state: present\\n  update_cache: true\\n  codename: IBM Spectrum Scale (Callhome debs)\\n  mode: 511\\nwhen:\\n- ansible_pkg_mgr == 'apt'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Configure Callhome zypper repository\\n \\n \\nzypper_repository:\\n  name: spectrum-scale-callhome-rpms\\n  repo: '{{ scale_install_repository_url }}gpfs_rpms/'\\n  runrefresh: true\\n  state: present\\n  disable_gpg_check: true\\nwhen:\\n- ansible_pkg_mgr == 'zypper'\\n- scale_install_repository_url != 'existing'\\n\"},\n",
       " {'text': \"name: install | Add GPFS callhome packages to list\\n \\n \\nset_fact:\\n  scale_install_all_packages: '{{ scale_install_all_packages + [ item ] }}'\\nwith_items:\\n- '{{ scale_callhome_packages }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_callhome_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\nvars:\\n  localpkg: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\ncommand: '{{ localpkg + '' --silent'' }}'\\nargs:\\n  creates: '{{ scale_callhome_extracted_path }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_callhome_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs_rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the local\\n    installation package!\\n\"},\n",
       " {'text': \"name: install | Delete installation package from node\\n \\n \\nfile:\\n  path: '{{ scale_install_localpkg_tmpdir_path + ''/'' + scale_install_localpkg_path\\n    | basename }}'\\n  state: absent\\n\"},\n",
       " {'text': 'name: install | callhome path\\n \\n \\nset_fact:\\n  callhome_url: gpfs_rpms/\\nwhen: ansible_distribution in scale_rhel_distribution or ansible_distribution in scale_sles_distribution\\n'},\n",
       " {'text': 'name: install | callhome path\\n \\n \\nset_fact:\\n  callhome_url: gpfs_debs/\\nwhen: ansible_distribution in scale_ubuntu_distribution\\n'},\n",
       " {'text': \"name: install | Stat remote installation package\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  checksum_algorithm: md5\\nregister: scale_install_remotepkg\\n\"},\n",
       " {'text': \"name: install | Check remote installation package\\n \\n \\nassert:\\n  that: scale_install_remotepkg.stat.exists\\n  msg: Please set the variable 'scale_install_remotepkg_path' to point to the remote\\n    installation package (accessible on Ansible managed node)!\\n\"},\n",
       " {'text': \"name: install | Stat checksum file\\n \\n \\nstat:\\n  path: '{{ scale_install_remotepkg_path }}.md5'\\nregister: scale_install_md5_file\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_callhome_extracted_path }}'\\nregister: scale_install_gpfs_rpmdir\\n\"},\n",
       " {'text': \"name: install | Make installation package executable\\n \\n \\nfile:\\n  path: '{{ scale_install_remotepkg_path }}'\\n  mode: a+x\\nwhen: not scale_install_gpfs_rpmdir.stat.exists\\n\"},\n",
       " {'text': \"name: install | Extract installation package\\n \\n \\ncommand: '{{ scale_install_remotepkg_path + '' --silent'' }}'\\nargs:\\n  creates: '{{ scale_callhome_extracted_path }}'\\n\"},\n",
       " {'text': \"name: install | Stat extracted packages\\n \\n \\nstat:\\n  path: '{{ scale_callhome_extracted_path }}'\\nregister: scale_install_gpfs__rpmdir\\n\"},\n",
       " {'text': \"name: install | Check extracted packages\\n \\n \\nassert:\\n  that:\\n  - scale_install_gpfs__rpmdir.stat.exists\\n  - scale_install_gpfs_rpmdir.stat.isdir\\n  msg: The variable 'scale_version' doesn't seem to match the contents of the remote\\n    installation package!\\n\"},\n",
       " {'text': 'name: install | callhome path\\n \\n \\nset_fact:\\n  callhome_url: gpfs_debs/\\nwhen: ansible_distribution in scale_ubuntu_distribution\\n'},\n",
       " {'text': 'name: install | callhome path\\n \\n \\nset_fact:\\n  callhome_url: gpfs_rpms/\\nwhen: ansible_distribution in scale_rhel_distribution or ansible_distribution in scale_sles_distribution\\n'},\n",
       " {'text': 'name: install | Disable repo metadata gpg check\\n \\n \\ncommand: zypper modifyrepo --gpgcheck-allow-unsigned-repo --all\\nargs:\\n  warn: false\\n'},\n",
       " {'text': \"name: install | Install GPFS Callhome packages\\n \\n \\nzypper:\\n  name: '{{ scale_install_all_packages }}'\\n  state: present\\n  disable_gpg_check: false\\n\"},\n",
       " {'text': 'name: install | Enable repo metadata gpg check\\n \\n \\ncommand: zypper modifyrepo --default-gpgcheck --all\\nargs:\\n  warn: false\\n'},\n",
       " {'text': \"name: install | Install GPFS Callhome packages\\n \\n \\npackage:\\n  name: '{{ scale_install_all_packages }}'\\n  state: present\\nwhen: scale_install_repository_url is defined\\n\"},\n",
       " {'text': \"name: install| Install GPFS Callhome deb\\n \\n \\napt:\\n  deb: '{{ item }}'\\n  state: present\\nwhen: scale_install_repository_url is not defined\\nwith_items:\\n- '{{ scale_install_all_packages }}'\\n\"},\n",
       " {'text': \"name: install | Install GPFS Callhome packages\\n \\n \\nyum:\\n  name: '{{ scale_install_all_packages }}'\\n  state: present\\n  disable_gpg_check: '{{ scale_disable_gpgcheck }}'\\n\"},\n",
       " {'text': 'name: global_var | Initialize\\n \\n \\nset_fact:\\n  scale_hdfs_nodes_list: []\\n  scale_hdfs_namenodes_list: []\\n  scale_hdfs_datanodes_list: []\\n  scale_hdfs_cluster: []\\n  scale_install_all_packages: []\\n'},\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GeneralDataset(data=train_data, separator=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model must be sharded\n",
    "# backbone_model_name = \"TinyPixel/Llama-2-7B-bf16-sharded\"\n",
    "# backbone_model_name = \"bn22/Mistral-7B-v0.1-sharded\"\n",
    "backbone_model_name = \"bigcode/starcoderbase-1b\"\n",
    "push_to_hub_while_training = True\n",
    "# lora_hub_model_id = \"BobaZooba/AntModel-7B-XLLM-Demo-LoRA\"\n",
    "# hub_model_id = \"BobaZooba/AntModel-7B-XLLM-Demo\"\n",
    "\n",
    "max_steps = 100\n",
    "save_steps = 25\n",
    "warmup_steps = 5\n",
    "\n",
    "report_to_wandb = False\n",
    "wandb_project = None\n",
    "wandb_entity = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if report_to_wandb and wandb_project:\n",
    "    print(\"Please set at least wandb_project for W&B tracking. wandb_entity is your or your company username at W&B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    use_gradient_checkpointing=True,\n",
    "    model_name_or_path=backbone_model_name,\n",
    "    use_flash_attention_2=False,  # not supported in colab\n",
    "    load_in_4bit=True,\n",
    "    prepare_model_for_kbit_training=True,\n",
    "    apply_lora=True,\n",
    "    warmup_steps=warmup_steps,\n",
    "    max_steps=max_steps,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=1,\n",
    "\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    max_length=2048,\n",
    "\n",
    "    # tokenizer_padding_side=\"right\",  # good for llama2\n",
    "\n",
    "    # push_to_hub=push_to_hub_while_training,\n",
    "    # hub_model_id=lora_hub_model_id,\n",
    "    # hub_private_repo=False,\n",
    "\n",
    "    # W&B\n",
    "    report_to_wandb=False,\n",
    "    wandb_project=wandb_project,\n",
    "    wandb_entity=wandb_entity,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(config=config, train_dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-29 17:07:08.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mExperiment building has started\u001b[0m\n",
      "\u001b[32m2023-11-29 17:07:08.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mConfig:\n",
      "{\n",
      "  \"experiment_key\": \"base\",\n",
      "  \"save_safetensors\": true,\n",
      "  \"max_shard_size\": \"10GB\",\n",
      "  \"local_rank\": 0,\n",
      "  \"use_gradient_checkpointing\": true,\n",
      "  \"trainer_key\": \"lm\",\n",
      "  \"force_fp32\": false,\n",
      "  \"force_fp16\": false,\n",
      "  \"from_gptq\": false,\n",
      "  \"huggingface_hub_token\": null,\n",
      "  \"deepspeed_stage\": 0,\n",
      "  \"deepspeed_config_path\": null,\n",
      "  \"fsdp_strategy\": \"\",\n",
      "  \"fsdp_offload\": true,\n",
      "  \"seed\": 42,\n",
      "  \"stabilize\": false,\n",
      "  \"norm_fp32\": false,\n",
      "  \"path_to_env_file\": \"./.env\",\n",
      "  \"prepare_dataset\": true,\n",
      "  \"lora_hub_model_id\": null,\n",
      "  \"lora_model_local_path\": null,\n",
      "  \"fused_model_local_path\": null,\n",
      "  \"fuse_after_training\": false,\n",
      "  \"quantization_dataset_id\": null,\n",
      "  \"quantization_max_samples\": 1024,\n",
      "  \"quantized_model_path\": \"./quantized_model/\",\n",
      "  \"quantized_hub_model_id\": null,\n",
      "  \"quantized_hub_private_repo\": true,\n",
      "  \"dataset_key\": \"soda\",\n",
      "  \"train_local_path_to_data\": \"./train.jsonl\",\n",
      "  \"eval_local_path_to_data\": null,\n",
      "  \"shuffle\": true,\n",
      "  \"max_eval_samples\": 1000,\n",
      "  \"add_eval_to_train_if_no_path\": false,\n",
      "  \"tokenizer_name_or_path\": null,\n",
      "  \"tokenizer_use_fast\": null,\n",
      "  \"tokenizer_padding_side\": null,\n",
      "  \"collator_key\": \"lm\",\n",
      "  \"max_length\": 2048,\n",
      "  \"model_name_or_path\": \"bigcode/starcoderbase-1b\",\n",
      "  \"push_to_hub_bos_add_bos_token\": false,\n",
      "  \"use_flash_attention_2\": false,\n",
      "  \"trust_remote_code\": false,\n",
      "  \"device_map\": null,\n",
      "  \"prepare_model_for_kbit_training\": true,\n",
      "  \"offload_folder\": null,\n",
      "  \"load_in_8bit\": false,\n",
      "  \"load_in_4bit\": true,\n",
      "  \"llm_int8_threshold\": 6.0,\n",
      "  \"llm_int8_has_fp16_weight\": true,\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_quantize_after_model_init\": false,\n",
      "  \"gptq_bits\": 4,\n",
      "  \"gptq_group_size\": 128,\n",
      "  \"gptq_disable_exllama\": true,\n",
      "  \"apply_lora\": true,\n",
      "  \"lora_rank\": 8,\n",
      "  \"lora_alpha\": 32,\n",
      "  \"lora_dropout\": 0.1,\n",
      "  \"raw_lora_target_modules\": \"all\",\n",
      "  \"output_dir\": \"./outputs/\",\n",
      "  \"per_device_train_batch_size\": 2,\n",
      "  \"do_eval\": false,\n",
      "  \"per_device_eval_batch_size\": null,\n",
      "  \"gradient_accumulation_steps\": 2,\n",
      "  \"eval_accumulation_steps\": null,\n",
      "  \"eval_delay\": 0,\n",
      "  \"eval_steps\": 1000,\n",
      "  \"warmup_steps\": 5,\n",
      "  \"max_steps\": 100,\n",
      "  \"num_train_epochs\": 1,\n",
      "  \"learning_rate\": 0.0002,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"label_smoothing_factor\": 0.0,\n",
      "  \"logging_steps\": 1,\n",
      "  \"save_steps\": 25,\n",
      "  \"save_total_limit\": 1,\n",
      "  \"optim\": \"paged_adamw_8bit\",\n",
      "  \"push_to_hub\": false,\n",
      "  \"hub_model_id\": null,\n",
      "  \"hub_private_repo\": true,\n",
      "  \"neftune_noise_alpha\": null,\n",
      "  \"report_to_wandb\": false,\n",
      "  \"wandb_api_key\": null,\n",
      "  \"wandb_project\": null,\n",
      "  \"wandb_entity\": null\n",
      "}\u001b[0m\n",
      "\u001b[32m2023-11-29 17:07:08.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mConfig saved\u001b[0m\n",
      "\u001b[32m2023-11-29 17:07:08.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mChecks passed successfully\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'neftune_noise_alpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/bzd2/hetarth/starcoder/finetune/x-llm.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnusrat.cs.illinois.edu/home/bzd2/hetarth/starcoder/finetune/x-llm.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m experiment\u001b[39m.\u001b[39;49mbuild()\n",
      "File \u001b[0;32m~/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages/xllm/experiments/base.py:233\u001b[0m, in \u001b[0;36mExperiment.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_arguments \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbefore_training_arguments_build()\n\u001b[0;32m--> 233\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_arguments \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_training_arguments()\n\u001b[1;32m    234\u001b[0m     dist_logger(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining arguments was built:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_arguments\u001b[39m.\u001b[39mto_json_string()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter_training_arguments_build()\n",
      "File \u001b[0;32m~/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages/xllm/experiments/base.py:359\u001b[0m, in \u001b[0;36mExperiment.build_training_arguments\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_training_arguments\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m TrainingArguments:\n\u001b[0;32m--> 359\u001b[0m     training_arguments \u001b[39m=\u001b[39m build_training_arguments(config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig)\n\u001b[1;32m    360\u001b[0m     \u001b[39mreturn\u001b[39;00m training_arguments\n",
      "File \u001b[0;32m~/miniconda3/envs/hetarth_py10/lib/python3.10/site-packages/xllm/core/dependencies.py:92\u001b[0m, in \u001b[0;36mbuild_training_arguments\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     89\u001b[0m     fp16 \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     bf16 \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m training_arguments \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m     93\u001b[0m     output_dir\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49moutput_dir,\n\u001b[1;32m     94\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mper_device_train_batch_size,\n\u001b[1;32m     95\u001b[0m     gradient_accumulation_steps\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mgradient_accumulation_steps,\n\u001b[1;32m     96\u001b[0m     warmup_steps\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mwarmup_steps,\n\u001b[1;32m     97\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[1;32m     98\u001b[0m     max_steps\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mmax_steps \u001b[39mif\u001b[39;49;00m config\u001b[39m.\u001b[39;49mmax_steps \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     99\u001b[0m     num_train_epochs\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_train_epochs,\n\u001b[1;32m    100\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mweight_decay,\n\u001b[1;32m    101\u001b[0m     max_grad_norm\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mmax_grad_norm,\n\u001b[1;32m    102\u001b[0m     label_smoothing_factor\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mlabel_smoothing_factor,\n\u001b[1;32m    103\u001b[0m     fp16\u001b[39m=\u001b[39;49mfp16,\n\u001b[1;32m    104\u001b[0m     bf16\u001b[39m=\u001b[39;49mbf16,\n\u001b[1;32m    105\u001b[0m     logging_steps\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mlogging_steps,\n\u001b[1;32m    106\u001b[0m     report_to\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mwandb\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39mif\u001b[39;49;00m config\u001b[39m.\u001b[39;49mreport_to_wandb \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    107\u001b[0m     save_strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msteps\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    108\u001b[0m     save_steps\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49msave_steps,\n\u001b[1;32m    109\u001b[0m     save_total_limit\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49msave_total_limit,\n\u001b[1;32m    110\u001b[0m     hub_model_id\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mhub_model_id,\n\u001b[1;32m    111\u001b[0m     hub_strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcheckpoint\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    112\u001b[0m     hub_token\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49menviron\u001b[39m.\u001b[39;49mget(enums\u001b[39m.\u001b[39;49mEnvironmentVariables\u001b[39m.\u001b[39;49mhuggingface_hub_token, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    113\u001b[0m     push_to_hub\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpush_to_hub,\n\u001b[1;32m    114\u001b[0m     hub_private_repo\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mhub_private_repo,\n\u001b[1;32m    115\u001b[0m     save_safetensors\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49msave_safetensors,\n\u001b[1;32m    116\u001b[0m     fsdp\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mfsdp,\n\u001b[1;32m    117\u001b[0m     deepspeed\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdeepspeed,\n\u001b[1;32m    118\u001b[0m     remove_unused_columns\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    119\u001b[0m     log_level\u001b[39m=\u001b[39;49menums\u001b[39m.\u001b[39;49mLogLevel\u001b[39m.\u001b[39;49minfo,\n\u001b[1;32m    120\u001b[0m     disable_tqdm\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    121\u001b[0m     logging_first_step\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    122\u001b[0m     optim\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49moptim,  \u001b[39m# will be overwriten by deepspeed config if exist\u001b[39;49;00m\n\u001b[1;32m    123\u001b[0m     do_eval\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdo_eval,\n\u001b[1;32m    124\u001b[0m     evaluation_strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msteps\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m config\u001b[39m.\u001b[39;49mdo_eval \u001b[39melse\u001b[39;49;00m IntervalStrategy\u001b[39m.\u001b[39;49mNO,\n\u001b[1;32m    125\u001b[0m     per_device_eval_batch_size\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mper_device_eval_batch_size \u001b[39mor\u001b[39;49;00m config\u001b[39m.\u001b[39;49mper_device_train_batch_size,\n\u001b[1;32m    126\u001b[0m     eval_accumulation_steps\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49meval_accumulation_steps \u001b[39mor\u001b[39;49;00m config\u001b[39m.\u001b[39;49mgradient_accumulation_steps,\n\u001b[1;32m    127\u001b[0m     eval_delay\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49meval_delay,\n\u001b[1;32m    128\u001b[0m     eval_steps\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49meval_steps,\n\u001b[1;32m    129\u001b[0m     seed\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mseed,\n\u001b[1;32m    130\u001b[0m     data_seed\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mseed,\n\u001b[1;32m    131\u001b[0m     metric_for_best_model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39meval_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m config\u001b[39m.\u001b[39;49mdo_eval \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    132\u001b[0m     neftune_noise_alpha\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mneftune_noise_alpha,\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m training_arguments\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'neftune_noise_alpha'"
     ]
    }
   ],
   "source": [
    "experiment.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hetarth_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
