GpuFreq=control_disabled
Starting script...
Output: Requirement already satisfied: torch in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (2.2.2)
Requirement already satisfied: torchvision in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (0.17.2)
Requirement already satisfied: torchaudio in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (2.2.2)
Requirement already satisfied: filelock in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (3.13.3)
Requirement already satisfied: typing-extensions>=4.8.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (4.11.0)
Requirement already satisfied: sympy in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (1.12)
Requirement already satisfied: networkx in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (3.3)
Requirement already satisfied: jinja2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (3.1.3)
Requirement already satisfied: fsspec in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (2024.2.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (2.19.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (12.1.105)
Requirement already satisfied: triton==2.2.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch) (2.2.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)
Requirement already satisfied: numpy in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torchvision) (1.26.4)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torchvision) (10.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)
Requirement already satisfied: mpmath>=0.19 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from sympy->torch) (1.3.0)Output: Requirement already satisfied: transformers in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (4.40.0.dev0)
Requirement already satisfied: filelock in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers) (3.13.3)
Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers) (0.22.2)
Requirement already satisfied: numpy>=1.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers) (1.26.4)
Requirement already satisfied: packaging>=20.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers) (24.0)
Requirement already satisfied: pyyaml>=5.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers) (6.0.1)
Requirement already satisfied: regex!=2019.12.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers) (2023.12.25)
Requirement already satisfied: requests in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers) (2.31.0)
Requirement already satisfied: tokenizers<0.19,>=0.14 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers) (0.15.2)
Requirement already satisfied: safetensors>=0.4.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers) (0.4.2)
Requirement already satisfied: tqdm>=4.27 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers) (4.66.2)
Requirement already satisfied: fsspec>=2023.5.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->transformers) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->transformers) (3.6)
Requirement already satisfied: urllib3<3,>=1.21.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->transformers) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)Output: Found existing installation: peft 0.10.1.dev0
Uninstalling peft-0.10.1.dev0:
  Would remove:
    /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/peft-0.10.1.dev0.dist-info/*
    /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/peft/*
Proceed (Y/n)?   Successfully uninstalled peft-0.10.1.dev0Output: Collecting git+https://github.com/huggingface/peft.git
  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-sc1p56r0
  Resolved https://github.com/huggingface/peft.git to commit 26726bf1ddee6ca75ed4e1bfd292094526707a78
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: numpy>=1.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from peft==0.10.1.dev0) (1.26.4)
Requirement already satisfied: packaging>=20.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from peft==0.10.1.dev0) (24.0)
Requirement already satisfied: psutil in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from peft==0.10.1.dev0) (5.9.8)
Requirement already satisfied: pyyaml in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from peft==0.10.1.dev0) (6.0.1)
Requirement already satisfied: torch>=1.13.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from peft==0.10.1.dev0) (2.2.2)
Requirement already satisfied: transformers in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from peft==0.10.1.dev0) (4.40.0.dev0)
Requirement already satisfied: tqdm in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from peft==0.10.1.dev0) (4.66.2)
Requirement already satisfied: accelerate>=0.21.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from peft==0.10.1.dev0) (0.29.1)
Requirement already satisfied: safetensors in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from peft==0.10.1.dev0) (0.4.2)
Requirement already satisfied: huggingface-hub>=0.17.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from peft==0.10.1.dev0) (0.22.2)
Requirement already satisfied: filelock in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.1.dev0) (3.13.3)
Requirement already satisfied: fsspec>=2023.5.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.1.dev0) (2024.2.0)
Requirement already satisfied: requests in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.1.dev0) (2.31.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.10.1.dev0) (4.11.0)
Requirement already satisfied: sympy in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (1.12)
Requirement already satisfied: networkx in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (3.3)
Requirement already satisfied: jinja2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (3.1.3)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (2.19.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (12.1.105)
Requirement already satisfied: triton==2.2.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.1.dev0) (2.2.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.10.1.dev0) (12.4.127)
Requirement already satisfied: regex!=2019.12.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers->peft==0.10.1.dev0) (2023.12.25)
Requirement already satisfied: tokenizers<0.19,>=0.14 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers->peft==0.10.1.dev0) (0.15.2)
Requirement already satisfied: MarkupSafe>=2.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.10.1.dev0) (2.1.5)
Requirement already satisfied: charset-normalizer<4,>=2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.1.dev0) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.1.dev0) (3.6)
Requirement already satisfied: urllib3<3,>=1.21.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.1.dev0) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.1.dev0) (2024.2.2)
Requirement already satisfied: mpmath>=0.19 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.10.1.dev0) (1.3.0)
Building wheels for collected packages: peft
  Building wheel for peft (pyproject.toml): started
  Building wheel for peft (pyproject.toml): finished with status 'done'
  Created wheel for peft: filename=peft-0.10.1.dev0-py3-none-any.whl size=200819 sha256=981305b464ccec8c36452d617eec1cef6671278a6ab6b7120ae9b8169e028abb
  Stored in directory: /tmp/pip-ephem-wheel-cache-6d5b63o3/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087
Successfully built peft
Installing collected packages: peft
Successfully installed peft-0.10.1.dev0Output: Collecting git+https://github.com/huggingface/transformers
  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-3ggyw42c
  Resolved https://github.com/huggingface/transformers to commit 76fa17c1663a0efeca7208c20579833365584889
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: filelock in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (3.13.3)
Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (0.22.2)
Requirement already satisfied: numpy>=1.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (1.26.4)
Requirement already satisfied: packaging>=20.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (24.0)
Requirement already satisfied: pyyaml>=5.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (6.0.1)
Requirement already satisfied: regex!=2019.12.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (2023.12.25)
Requirement already satisfied: requests in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (2.31.0)
Requirement already satisfied: tokenizers<0.19,>=0.14 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (0.15.2)
Requirement already satisfied: safetensors>=0.4.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (0.4.2)
Requirement already satisfied: tqdm>=4.27 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (4.66.2)
Requirement already satisfied: fsspec>=2023.5.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (2024.2.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (4.11.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (3.6)
Requirement already satisfied: urllib3<3,>=1.21.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (2024.2.2)Output: Requirement already satisfied: datasets in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (2.18.0)
Requirement already satisfied: filelock in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (3.13.3)
Requirement already satisfied: numpy>=1.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (1.26.4)
Requirement already satisfied: pyarrow>=12.0.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (15.0.2)
Requirement already satisfied: pyarrow-hotfix in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (0.6)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (0.3.8)
Requirement already satisfied: pandas in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (2.2.1)
Requirement already satisfied: requests>=2.19.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (2.31.0)
Requirement already satisfied: tqdm>=4.62.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (4.66.2)
Requirement already satisfied: xxhash in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (3.4.1)
Requirement already satisfied: multiprocess in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (0.70.16)
Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)
Requirement already satisfied: aiohttp in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (3.9.3)
Requirement already satisfied: huggingface-hub>=0.19.4 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (0.22.2)
Requirement already satisfied: packaging in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (24.0)
Requirement already satisfied: pyyaml>=5.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from datasets) (6.0.1)
Requirement already satisfied: aiosignal>=1.1.2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)
Requirement already satisfied: attrs>=17.3.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)
Requirement already satisfied: frozenlist>=1.1.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)
Requirement already satisfied: multidict<7.0,>=4.5 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)
Requirement already satisfied: yarl<2.0,>=1.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)
Requirement already satisfied: async-timeout<5.0,>=4.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)
Requirement already satisfied: urllib3<3,>=1.21.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)
Requirement already satisfied: python-dateutil>=2.8.2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from pandas->datasets) (2024.1)
Requirement already satisfied: tzdata>=2022.7 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from pandas->datasets) (2024.1)
Requirement already satisfied: six>=1.5 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)Output: Requirement already satisfied: accelerate in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (0.29.1)
Requirement already satisfied: numpy>=1.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from accelerate) (1.26.4)
Requirement already satisfied: packaging>=20.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from accelerate) (24.0)
Requirement already satisfied: psutil in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from accelerate) (5.9.8)
Requirement already satisfied: pyyaml in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from accelerate) (6.0.1)
Requirement already satisfied: torch>=1.10.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from accelerate) (2.2.2)
Requirement already satisfied: huggingface-hub in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from accelerate) (0.22.2)
Requirement already satisfied: safetensors>=0.3.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from accelerate) (0.4.2)
Requirement already satisfied: filelock in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.3)
Requirement already satisfied: typing-extensions>=4.8.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)
Requirement already satisfied: sympy in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)
Requirement already satisfied: networkx in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)
Requirement already satisfied: jinja2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)
Requirement already satisfied: fsspec in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.19.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)
Requirement already satisfied: triton==2.2.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.2.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)
Requirement already satisfied: requests in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)
Requirement already satisfied: tqdm>=4.42.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.2)
Requirement already satisfied: MarkupSafe>=2.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)
Requirement already satisfied: charset-normalizer<4,>=2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)
Requirement already satisfied: urllib3<3,>=1.21.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)
Requirement already satisfied: mpmath>=0.19 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)Output: Requirement already satisfied: huggingface_hub in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (0.22.2)
Requirement already satisfied: filelock in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface_hub) (3.13.3)
Requirement already satisfied: fsspec>=2023.5.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)
Requirement already satisfied: packaging>=20.9 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface_hub) (24.0)
Requirement already satisfied: pyyaml>=5.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)
Requirement already satisfied: requests in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)
Requirement already satisfied: tqdm>=4.42.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface_hub) (4.66.2)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from huggingface_hub) (4.11.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)
Requirement already satisfied: urllib3<3,>=1.21.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)Output: Requirement already satisfied: bitsandbytes in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (0.43.0)
Requirement already satisfied: torch in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from bitsandbytes) (2.2.2)
Requirement already satisfied: numpy in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)
Requirement already satisfied: filelock in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.3)
Requirement already satisfied: typing-extensions>=4.8.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (4.11.0)
Requirement already satisfied: sympy in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)
Requirement already satisfied: networkx in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)
Requirement already satisfied: jinja2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.3)
Requirement already satisfied: fsspec in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (2.19.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)
Requirement already satisfied: triton==2.2.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch->bitsandbytes) (2.2.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)
Requirement already satisfied: MarkupSafe>=2.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)
Requirement already satisfied: mpmath>=0.19 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)Output: Requirement already satisfied: wandb in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (0.16.6)
Requirement already satisfied: Click!=8.0.0,>=7.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from wandb) (8.1.7)
Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from wandb) (3.1.43)
Requirement already satisfied: requests<3,>=2.0.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from wandb) (2.31.0)
Requirement already satisfied: psutil>=5.0.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from wandb) (5.9.8)
Requirement already satisfied: sentry-sdk>=1.0.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from wandb) (1.44.1)
Requirement already satisfied: docker-pycreds>=0.4.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from wandb) (0.4.0)
Requirement already satisfied: PyYAML in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from wandb) (6.0.1)
Requirement already satisfied: setproctitle in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from wandb) (1.3.3)
Requirement already satisfied: setuptools in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from wandb) (68.2.2)
Requirement already satisfied: appdirs>=1.4.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from wandb) (1.4.4)
Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from wandb) (4.25.3)
Requirement already satisfied: six>=1.4.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)
Requirement already satisfied: gitdb<5,>=4.0.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)
Requirement already satisfied: charset-normalizer<4,>=2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)
Requirement already satisfied: urllib3<3,>=1.21.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)
Requirement already satisfied: smmap<6,>=3.0.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)Output: Requirement already satisfied: scikit-learn in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (1.4.1.post1)
Requirement already satisfied: numpy<2.0,>=1.19.5 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from scikit-learn) (1.26.4)
Requirement already satisfied: scipy>=1.6.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from scikit-learn) (1.13.0)
Requirement already satisfied: joblib>=1.2.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from scikit-learn) (1.3.2)
Requirement already satisfied: threadpoolctl>=2.0.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from scikit-learn) (3.4.0)Output: Requirement already satisfied: code_bert_score in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (0.4.1)
Requirement already satisfied: torch>=1.0.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from code_bert_score) (2.2.2)
Requirement already satisfied: numpy in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from code_bert_score) (1.26.4)
Requirement already satisfied: pandas>=1.0.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from code_bert_score) (2.2.1)
Requirement already satisfied: requests in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from code_bert_score) (2.31.0)
Requirement already satisfied: tqdm>=4.31.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from code_bert_score) (4.66.2)
Requirement already satisfied: matplotlib in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from code_bert_score) (3.8.4)
Requirement already satisfied: transformers>=3.0.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from code_bert_score) (4.40.0.dev0)
Requirement already satisfied: python-dateutil>=2.8.2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from pandas>=1.0.1->code_bert_score) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from pandas>=1.0.1->code_bert_score) (2024.1)
Requirement already satisfied: tzdata>=2022.7 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from pandas>=1.0.1->code_bert_score) (2024.1)
Requirement already satisfied: filelock in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (3.13.3)
Requirement already satisfied: typing-extensions>=4.8.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (4.11.0)
Requirement already satisfied: sympy in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (1.12)
Requirement already satisfied: networkx in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (3.3)
Requirement already satisfied: jinja2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (3.1.3)
Requirement already satisfied: fsspec in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (2024.2.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (2.19.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (12.1.105)
Requirement already satisfied: triton==2.2.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from torch>=1.0.0->code_bert_score) (2.2.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->code_bert_score) (12.4.127)
Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers>=3.0.0->code_bert_score) (0.22.2)
Requirement already satisfied: packaging>=20.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers>=3.0.0->code_bert_score) (24.0)
Requirement already satisfied: pyyaml>=5.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers>=3.0.0->code_bert_score) (6.0.1)
Requirement already satisfied: regex!=2019.12.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers>=3.0.0->code_bert_score) (2023.12.25)
Requirement already satisfied: tokenizers<0.19,>=0.14 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers>=3.0.0->code_bert_score) (0.15.2)
Requirement already satisfied: safetensors>=0.4.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from transformers>=3.0.0->code_bert_score) (0.4.2)
Requirement already satisfied: contourpy>=1.0.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from matplotlib->code_bert_score) (1.2.1)
Requirement already satisfied: cycler>=0.10 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from matplotlib->code_bert_score) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from matplotlib->code_bert_score) (4.51.0)
Requirement already satisfied: kiwisolver>=1.3.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from matplotlib->code_bert_score) (1.4.5)
Requirement already satisfied: pillow>=8 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from matplotlib->code_bert_score) (10.3.0)
Requirement already satisfied: pyparsing>=2.3.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from matplotlib->code_bert_score) (3.1.2)
Requirement already satisfied: charset-normalizer<4,>=2 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->code_bert_score) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->code_bert_score) (3.6)
Requirement already satisfied: urllib3<3,>=1.21.1 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->code_bert_score) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from requests->code_bert_score) (2024.2.2)
Requirement already satisfied: six>=1.5 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->code_bert_score) (1.16.0)
Requirement already satisfied: MarkupSafe>=2.0 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->code_bert_score) (2.1.5)
Requirement already satisfied: mpmath>=0.19 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from sympy->torch>=1.0.0->code_bert_score) (1.3.0)Output: Requirement already satisfied: nltk in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (3.8.1)
Requirement already satisfied: click in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from nltk) (8.1.7)
Requirement already satisfied: joblib in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from nltk) (1.3.2)
Requirement already satisfied: regex>=2021.8.3 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from nltk) (2023.12.25)
Requirement already satisfied: tqdm in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages (from nltk) (4.66.2)GpuFreq=control_disabled
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:739: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:739: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:739: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:739: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
loading file vocab.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/vocab.json
loading file merges.txt from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/merges.txt
loading file tokenizer.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/special_tokens_map.json
loading file tokenizer_config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/tokenizer_config.json
loading file vocab.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/vocab.json
loading file merges.txt from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/merges.txt
loading file tokenizer.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/special_tokens_map.json
loading file tokenizer_config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/tokenizer_config.json
loading file vocab.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/vocab.json
loading file merges.txt from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/merges.txt
loading file tokenizer.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/special_tokens_map.json
loading file tokenizer_config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/tokenizer_config.json
loading file vocab.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/vocab.json
loading file merges.txt from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/merges.txt
loading file tokenizer.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/special_tokens_map.json
loading file tokenizer_config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/tokenizer_config.json
/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
Loading the dataset
Loading the dataset in streaming mode
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Delete /etc/motd file', 'repo_name': 'motd', 'download_link': 'https://old-galaxy.ansible.com/adriagalin/motd', 'path': 'data/repos/adriagalin/motd/tasks/main.yml', 'download_count': '81335', 'output': 'file:\n  path: /etc/motd\n  state: absent\nwhen: ag_motd_add_footer | bool\ntags:\n- motd\n- common\n', 'org_name': 'adriagalin', 'license': 'GPL-3.0-only'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: check if gogs exists', 'repo_name': 'openshift_gogs', 'download_link': 'https://old-galaxy.ansible.com/siamaksade/openshift_gogs', 'path': 'data/repos/siamaksade/openshift_gogs/tasks/main.yml', 'download_count': '16571', 'output': 'shell: oc get service gogs -n gogs\nregister: install_gogs\nignore_errors: true\nchanged_when: false\n', 'org_name': 'siamaksade', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: assert release profile idempotency', 'repo_name': 'sonarr', 'download_link': 'https://old-galaxy.ansible.com/devopsarr/sonarr', 'path': 'data/repos/devopsarr/sonarr/integration/targets/sonarr_release_profile/tasks/main.yml', 'download_count': '688', 'output': 'assert:\n  that:\n  - result.changed == false\n  - result.ignored == ["repack", "dvdrip"]\n', 'org_name': 'devopsarr', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Start and enable anaconda', 'repo_name': 'anaconda', 'download_link': 'https://old-galaxy.ansible.com/buluma/anaconda', 'path': 'data/repos/buluma/anaconda/tasks/main.yml', 'download_count': '9401', 'output': 'ansible.builtin.service:\n  name: anaconda\n  state: started\n  enabled: true\n', 'org_name': 'buluma', 'license': 'Apache-2.0-Short,Apache-2.0'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Add hosts group temporary inventory group without pem path', 'repo_name': 'ec2_server', 'download_link': 'https://old-galaxy.ansible.com/chrismeyersfsu/ec2_server', 'path': 'data/repos/chrismeyersfsu/ec2_server/tasks/main.yml', 'download_count': '1904', 'output': "add_host:\n  name: ''\n  groups: ec2_server_hosts\n  ansible_ssh_user: ''\nwith_items: ec2.instances\nwhen: ec2_server_pem_path == ''\n", 'org_name': 'chrismeyersfsu', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Install', 'repo_name': 'nginx', 'download_link': 'https://old-galaxy.ansible.com/lifeofguenter/nginx', 'path': 'data/repos/lifeofguenter/nginx/tasks/nginx.yml', 'download_count': '561', 'output': 'ansible.builtin.command: make install\nargs:\n  chdir: /tmp/nginx-1.24.0\nchanged_when: true\nbecome: true\nnotify: Restart_nginx\n', 'org_name': 'lifeofguenter', 'license': 'MIT'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: assert | Test locale_lc_time', 'repo_name': 'locale', 'download_link': 'https://old-galaxy.ansible.com/robertdebock/locale', 'path': 'data/repos/robertdebock/locale/tasks/assert.yml', 'download_count': '34969', 'output': 'ansible.builtin.assert:\n  that:\n  - locale_lc_time is defined\n  - locale_lc_time is string\n  - locale_lc_time is not none\n  quiet: true\n', 'org_name': 'robertdebock', 'license': 'Apache-2.0-Short,Apache-2.0'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Create the APT repository (Debian)', 'repo_name': 'visual-studio-code', 'download_link': 'https://old-galaxy.ansible.com/brentwg/visual-studio-code', 'path': 'data/repos/brentwg/visual-studio-code/tasks/Debian.yml', 'download_count': '513', 'output': 'apt_repository:\n  repo: deb [arch=amd64] https://packages.microsoft.com/repos/vscode stable main\n  filename: vscode\n', 'org_name': 'brentwg', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Add MariaDB Repository Key for', 'repo_name': 'mariadb_install', 'download_link': 'https://old-galaxy.ansible.com/mahdi22/mariadb_install', 'path': 'data/repos/mahdi22/mariadb_install/tasks/Debian-install.yml', 'download_count': '801', 'output': 'apt_key:\n  url: https://mariadb.org/mariadb_release_signing_key.asc\n  state: present\nwhen: (use_proxy is not defined) or (not use_proxy)\n', 'org_name': 'mahdi22', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: ensure necessary packages are installed.', 'repo_name': 'packer_rhel', 'download_link': 'https://old-galaxy.ansible.com/buluma/packer_rhel', 'path': 'data/repos/buluma/packer_rhel/tasks/main.yml', 'download_count': '747', 'output': 'ansible.builtin.yum:\n  name:\n  - wget\n  - perl\n  - cpp\n  - gcc\n  - make\n  - bzip2\n  - kernel-headers\n  - kernel-devel\n  - libselinux-python\n  - elfutils-libelf-devel\n  - cifs-utils\n  state: present\n', 'org_name': 'buluma', 'license': 'Apache-2.0-Short,Apache-2.0'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Debian/Ubuntu Family | Install unzip if it is currently not in installed state', 'repo_name': 'packer', 'download_link': 'https://old-galaxy.ansible.com/darkwizard242/packer', 'path': 'data/repos/darkwizard242/packer/tasks/install_debian.yml', 'download_count': '4445', 'output': 'ansible.builtin.apt:\n  name: unzip\n  state: present\n  force_apt_get: true\n  update_cache: true\n', 'org_name': 'darkwizard242', 'license': 'MIT'}
Loading the dataset
Loading the dataset in streaming mode
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Delete /etc/motd file', 'repo_name': 'motd', 'download_link': 'https://old-galaxy.ansible.com/adriagalin/motd', 'path': 'data/repos/adriagalin/motd/tasks/main.yml', 'download_count': '81335', 'output': 'file:\n  path: /etc/motd\n  state: absent\nwhen: ag_motd_add_footer | bool\ntags:\n- motd\n- common\n', 'org_name': 'adriagalin', 'license': 'GPL-3.0-only'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: check if gogs exists', 'repo_name': 'openshift_gogs', 'download_link': 'https://old-galaxy.ansible.com/siamaksade/openshift_gogs', 'path': 'data/repos/siamaksade/openshift_gogs/tasks/main.yml', 'download_count': '16571', 'output': 'shell: oc get service gogs -n gogs\nregister: install_gogs\nignore_errors: true\nchanged_when: false\n', 'org_name': 'siamaksade', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: assert release profile idempotency', 'repo_name': 'sonarr', 'download_link': 'https://old-galaxy.ansible.com/devopsarr/sonarr', 'path': 'data/repos/devopsarr/sonarr/integration/targets/sonarr_release_profile/tasks/main.yml', 'download_count': '688', 'output': 'assert:\n  that:\n  - result.changed == false\n  - result.ignored == ["repack", "dvdrip"]\n', 'org_name': 'devopsarr', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Start and enable anaconda', 'repo_name': 'anaconda', 'download_link': 'https://old-galaxy.ansible.com/buluma/anaconda', 'path': 'data/repos/buluma/anaconda/tasks/main.yml', 'download_count': '9401', 'output': 'ansible.builtin.service:\n  name: anaconda\n  state: started\n  enabled: true\n', 'org_name': 'buluma', 'license': 'Apache-2.0-Short,Apache-2.0'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Add hosts group temporary inventory group without pem path', 'repo_name': 'ec2_server', 'download_link': 'https://old-galaxy.ansible.com/chrismeyersfsu/ec2_server', 'path': 'data/repos/chrismeyersfsu/ec2_server/tasks/main.yml', 'download_count': '1904', 'output': "add_host:\n  name: ''\n  groups: ec2_server_hosts\n  ansible_ssh_user: ''\nwith_items: ec2.instances\nwhen: ec2_server_pem_path == ''\n", 'org_name': 'chrismeyersfsu', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Install', 'repo_name': 'nginx', 'download_link': 'https://old-galaxy.ansible.com/lifeofguenter/nginx', 'path': 'data/repos/lifeofguenter/nginx/tasks/nginx.yml', 'download_count': '561', 'output': 'ansible.builtin.command: make install\nargs:\n  chdir: /tmp/nginx-1.24.0\nchanged_when: true\nbecome: true\nnotify: Restart_nginx\n', 'org_name': 'lifeofguenter', 'license': 'MIT'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: assert | Test locale_lc_time', 'repo_name': 'locale', 'download_link': 'https://old-galaxy.ansible.com/robertdebock/locale', 'path': 'data/repos/robertdebock/locale/tasks/assert.yml', 'download_count': '34969', 'output': 'ansible.builtin.assert:\n  that:\n  - locale_lc_time is defined\n  - locale_lc_time is string\n  - locale_lc_time is not none\n  quiet: true\n', 'org_name': 'robertdebock', 'license': 'Apache-2.0-Short,Apache-2.0'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Create the APT repository (Debian)', 'repo_name': 'visual-studio-code', 'download_link': 'https://old-galaxy.ansible.com/brentwg/visual-studio-code', 'path': 'data/repos/brentwg/visual-studio-code/tasks/Debian.yml', 'download_count': '513', 'output': 'apt_repository:\n  repo: deb [arch=amd64] https://packages.microsoft.com/repos/vscode stable main\n  filename: vscode\n', 'org_name': 'brentwg', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Add MariaDB Repository Key for', 'repo_name': 'mariadb_install', 'download_link': 'https://old-galaxy.ansible.com/mahdi22/mariadb_install', 'path': 'data/repos/mahdi22/mariadb_install/tasks/Debian-install.yml', 'download_count': '801', 'output': 'apt_key:\n  url: https://mariadb.org/mariadb_release_signing_key.asc\n  state: present\nwhen: (use_proxy is not defined) or (not use_proxy)\n', 'org_name': 'mahdi22', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: ensure necessary packages are installed.', 'repo_name': 'packer_rhel', 'download_link': 'https://old-galaxy.ansible.com/buluma/packer_rhel', 'path': 'data/repos/buluma/packer_rhel/tasks/main.yml', 'download_count': '747', 'output': 'ansible.builtin.yum:\n  name:\n  - wget\n  - perl\n  - cpp\n  - gcc\n  - make\n  - bzip2\n  - kernel-headers\n  - kernel-devel\n  - libselinux-python\n  - elfutils-libelf-devel\n  - cifs-utils\n  state: present\n', 'org_name': 'buluma', 'license': 'Apache-2.0-Short,Apache-2.0'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Debian/Ubuntu Family | Install unzip if it is currently not in installed state', 'repo_name': 'packer', 'download_link': 'https://old-galaxy.ansible.com/darkwizard242/packer', 'path': 'data/repos/darkwizard242/packer/tasks/install_debian.yml', 'download_count': '4445', 'output': 'ansible.builtin.apt:\n  name: unzip\n  state: present\n  force_apt_get: true\n  update_cache: true\n', 'org_name': 'darkwizard242', 'license': 'MIT'}  0%|          | 0/400 [00:00<?, ?it/s]
  0%|          | 1/400 [00:00<02:50,  2.34it/s]
  0%|          | 0/400 [00:00<?, ?it/s]
 71%|  | 285/400 [00:00<00:00, 713.44it/s]
100%|| 400/400 [00:00<00:00, 696.12it/s]
The character to token ratio of the dataset is: 3.18
Loading the model  0%|          | 1/400 [00:00<01:04,  6.16it/s]
 71%|  | 285/400 [00:00<00:00, 1330.31it/s]
100%|| 400/400 [00:00<00:00, 1318.02it/s]
The character to token ratio of the dataset is: 3.18
Loading the model
/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Loading the dataset
Loading the dataset in streaming mode
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Delete /etc/motd file', 'repo_name': 'motd', 'download_link': 'https://old-galaxy.ansible.com/adriagalin/motd', 'path': 'data/repos/adriagalin/motd/tasks/main.yml', 'download_count': '81335', 'output': 'file:\n  path: /etc/motd\n  state: absent\nwhen: ag_motd_add_footer | bool\ntags:\n- motd\n- common\n', 'org_name': 'adriagalin', 'license': 'GPL-3.0-only'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: check if gogs exists', 'repo_name': 'openshift_gogs', 'download_link': 'https://old-galaxy.ansible.com/siamaksade/openshift_gogs', 'path': 'data/repos/siamaksade/openshift_gogs/tasks/main.yml', 'download_count': '16571', 'output': 'shell: oc get service gogs -n gogs\nregister: install_gogs\nignore_errors: true\nchanged_when: false\n', 'org_name': 'siamaksade', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: assert release profile idempotency', 'repo_name': 'sonarr', 'download_link': 'https://old-galaxy.ansible.com/devopsarr/sonarr', 'path': 'data/repos/devopsarr/sonarr/integration/targets/sonarr_release_profile/tasks/main.yml', 'download_count': '688', 'output': 'assert:\n  that:\n  - result.changed == false\n  - result.ignored == ["repack", "dvdrip"]\n', 'org_name': 'devopsarr', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Start and enable anaconda', 'repo_name': 'anaconda', 'download_link': 'https://old-galaxy.ansible.com/buluma/anaconda', 'path': 'data/repos/buluma/anaconda/tasks/main.yml', 'download_count': '9401', 'output': 'ansible.builtin.service:\n  name: anaconda\n  state: started\n  enabled: true\n', 'org_name': 'buluma', 'license': 'Apache-2.0-Short,Apache-2.0'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Add hosts group temporary inventory group without pem path', 'repo_name': 'ec2_server', 'download_link': 'https://old-galaxy.ansible.com/chrismeyersfsu/ec2_server', 'path': 'data/repos/chrismeyersfsu/ec2_server/tasks/main.yml', 'download_count': '1904', 'output': "add_host:\n  name: ''\n  groups: ec2_server_hosts\n  ansible_ssh_user: ''\nwith_items: ec2.instances\nwhen: ec2_server_pem_path == ''\n", 'org_name': 'chrismeyersfsu', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Install', 'repo_name': 'nginx', 'download_link': 'https://old-galaxy.ansible.com/lifeofguenter/nginx', 'path': 'data/repos/lifeofguenter/nginx/tasks/nginx.yml', 'download_count': '561', 'output': 'ansible.builtin.command: make install\nargs:\n  chdir: /tmp/nginx-1.24.0\nchanged_when: true\nbecome: true\nnotify: Restart_nginx\n', 'org_name': 'lifeofguenter', 'license': 'MIT'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: assert | Test locale_lc_time', 'repo_name': 'locale', 'download_link': 'https://old-galaxy.ansible.com/robertdebock/locale', 'path': 'data/repos/robertdebock/locale/tasks/assert.yml', 'download_count': '34969', 'output': 'ansible.builtin.assert:\n  that:\n  - locale_lc_time is defined\n  - locale_lc_time is string\n  - locale_lc_time is not none\n  quiet: true\n', 'org_name': 'robertdebock', 'license': 'Apache-2.0-Short,Apache-2.0'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Create the APT repository (Debian)', 'repo_name': 'visual-studio-code', 'download_link': 'https://old-galaxy.ansible.com/brentwg/visual-studio-code', 'path': 'data/repos/brentwg/visual-studio-code/tasks/Debian.yml', 'download_count': '513', 'output': 'apt_repository:\n  repo: deb [arch=amd64] https://packages.microsoft.com/repos/vscode stable main\n  filename: vscode\n', 'org_name': 'brentwg', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Add MariaDB Repository Key for', 'repo_name': 'mariadb_install', 'download_link': 'https://old-galaxy.ansible.com/mahdi22/mariadb_install', 'path': 'data/repos/mahdi22/mariadb_install/tasks/Debian-install.yml', 'download_count': '801', 'output': 'apt_key:\n  url: https://mariadb.org/mariadb_release_signing_key.asc\n  state: present\nwhen: (use_proxy is not defined) or (not use_proxy)\n', 'org_name': 'mahdi22', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: ensure necessary packages are installed.', 'repo_name': 'packer_rhel', 'download_link': 'https://old-galaxy.ansible.com/buluma/packer_rhel', 'path': 'data/repos/buluma/packer_rhel/tasks/main.yml', 'download_count': '747', 'output': 'ansible.builtin.yum:\n  name:\n  - wget\n  - perl\n  - cpp\n  - gcc\n  - make\n  - bzip2\n  - kernel-headers\n  - kernel-devel\n  - libselinux-python\n  - elfutils-libelf-devel\n  - cifs-utils\n  state: present\n', 'org_name': 'buluma', 'license': 'Apache-2.0-Short,Apache-2.0'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Debian/Ubuntu Family | Install unzip if it is currently not in installed state', 'repo_name': 'packer', 'download_link': 'https://old-galaxy.ansible.com/darkwizard242/packer', 'path': 'data/repos/darkwizard242/packer/tasks/install_debian.yml', 'download_count': '4445', 'output': 'ansible.builtin.apt:\n  name: unzip\n  state: present\n  force_apt_get: true\n  update_cache: true\n', 'org_name': 'darkwizard242', 'license': 'MIT'}  0%|          | 0/400 [00:00<?, ?it/s]
  0%|          | 1/400 [00:00<01:06,  5.99it/s]
 72%|  | 287/400 [00:00<00:00, 1321.13it/s]
100%|| 400/400 [00:00<00:00, 1303.26it/s]
The character to token ratio of the dataset is: 3.18
Loading the model
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
loading configuration file config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/config.json
Model config GPTBigCodeConfig {
  "_name_or_path": "bigcode/starcoderbase-1b",
  "activation_function": "gelu_pytorch_tanh",
  "architectures": [
    "GPTBigCodeForCausalLM"
  ],
  "attention_softmax_in_fp32": true,
  "attn_pdrop": 0.1,
  "bos_token_id": 0,
  "embd_pdrop": 0.1,
  "eos_token_id": 0,
  "inference_runner": 0,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "max_batch_size": null,
  "max_sequence_length": null,
  "model_type": "gpt_bigcode",
  "multi_query": true,
  "n_embd": 2048,
  "n_head": 16,
  "n_inner": 8192,
  "n_layer": 24,
  "n_positions": 8192,
  "pad_key_length": true,
  "pre_allocate_kv_cache": false,
  "resid_pdrop": 0.1,
  "scale_attention_softmax_in_fp32": true,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "torch_dtype": "float32",
  "transformers_version": "4.40.0.dev0",
  "use_cache": true,
  "validate_runner_input": true,
  "vocab_size": 49152
}Loading the dataset
Loading the dataset in streaming mode
loading configuration file config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/config.json
Model config GPTBigCodeConfig {
  "_name_or_path": "bigcode/starcoderbase-1b",
  "activation_function": "gelu_pytorch_tanh",
  "architectures": [
    "GPTBigCodeForCausalLM"
  ],
  "attention_softmax_in_fp32": true,
  "attn_pdrop": 0.1,
  "bos_token_id": 0,
  "embd_pdrop": 0.1,
  "eos_token_id": 0,
  "inference_runner": 0,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "max_batch_size": null,
  "max_sequence_length": null,
  "model_type": "gpt_bigcode",
  "multi_query": true,
  "n_embd": 2048,
  "n_head": 16,
  "n_inner": 8192,
  "n_layer": 24,
  "n_positions": 8192,
  "pad_key_length": true,
  "pre_allocate_kv_cache": false,
  "resid_pdrop": 0.1,
  "scale_attention_softmax_in_fp32": true,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "torch_dtype": "float32",
  "transformers_version": "4.40.0.dev0",
  "use_cache": true,
  "validate_runner_input": true,
  "vocab_size": 49152
}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Delete /etc/motd file', 'repo_name': 'motd', 'download_link': 'https://old-galaxy.ansible.com/adriagalin/motd', 'path': 'data/repos/adriagalin/motd/tasks/main.yml', 'download_count': '81335', 'output': 'file:\n  path: /etc/motd\n  state: absent\nwhen: ag_motd_add_footer | bool\ntags:\n- motd\n- common\n', 'org_name': 'adriagalin', 'license': 'GPL-3.0-only'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: check if gogs exists', 'repo_name': 'openshift_gogs', 'download_link': 'https://old-galaxy.ansible.com/siamaksade/openshift_gogs', 'path': 'data/repos/siamaksade/openshift_gogs/tasks/main.yml', 'download_count': '16571', 'output': 'shell: oc get service gogs -n gogs\nregister: install_gogs\nignore_errors: true\nchanged_when: false\n', 'org_name': 'siamaksade', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: assert release profile idempotency', 'repo_name': 'sonarr', 'download_link': 'https://old-galaxy.ansible.com/devopsarr/sonarr', 'path': 'data/repos/devopsarr/sonarr/integration/targets/sonarr_release_profile/tasks/main.yml', 'download_count': '688', 'output': 'assert:\n  that:\n  - result.changed == false\n  - result.ignored == ["repack", "dvdrip"]\n', 'org_name': 'devopsarr', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Start and enable anaconda', 'repo_name': 'anaconda', 'download_link': 'https://old-galaxy.ansible.com/buluma/anaconda', 'path': 'data/repos/buluma/anaconda/tasks/main.yml', 'download_count': '9401', 'output': 'ansible.builtin.service:\n  name: anaconda\n  state: started\n  enabled: true\n', 'org_name': 'buluma', 'license': 'Apache-2.0-Short,Apache-2.0'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Add hosts group temporary inventory group without pem path', 'repo_name': 'ec2_server', 'download_link': 'https://old-galaxy.ansible.com/chrismeyersfsu/ec2_server', 'path': 'data/repos/chrismeyersfsu/ec2_server/tasks/main.yml', 'download_count': '1904', 'output': "add_host:\n  name: ''\n  groups: ec2_server_hosts\n  ansible_ssh_user: ''\nwith_items: ec2.instances\nwhen: ec2_server_pem_path == ''\n", 'org_name': 'chrismeyersfsu', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Install', 'repo_name': 'nginx', 'download_link': 'https://old-galaxy.ansible.com/lifeofguenter/nginx', 'path': 'data/repos/lifeofguenter/nginx/tasks/nginx.yml', 'download_count': '561', 'output': 'ansible.builtin.command: make install\nargs:\n  chdir: /tmp/nginx-1.24.0\nchanged_when: true\nbecome: true\nnotify: Restart_nginx\n', 'org_name': 'lifeofguenter', 'license': 'MIT'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: assert | Test locale_lc_time', 'repo_name': 'locale', 'download_link': 'https://old-galaxy.ansible.com/robertdebock/locale', 'path': 'data/repos/robertdebock/locale/tasks/assert.yml', 'download_count': '34969', 'output': 'ansible.builtin.assert:\n  that:\n  - locale_lc_time is defined\n  - locale_lc_time is string\n  - locale_lc_time is not none\n  quiet: true\n', 'org_name': 'robertdebock', 'license': 'Apache-2.0-Short,Apache-2.0'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Create the APT repository (Debian)', 'repo_name': 'visual-studio-code', 'download_link': 'https://old-galaxy.ansible.com/brentwg/visual-studio-code', 'path': 'data/repos/brentwg/visual-studio-code/tasks/Debian.yml', 'download_count': '513', 'output': 'apt_repository:\n  repo: deb [arch=amd64] https://packages.microsoft.com/repos/vscode stable main\n  filename: vscode\n', 'org_name': 'brentwg', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Add MariaDB Repository Key for', 'repo_name': 'mariadb_install', 'download_link': 'https://old-galaxy.ansible.com/mahdi22/mariadb_install', 'path': 'data/repos/mahdi22/mariadb_install/tasks/Debian-install.yml', 'download_count': '801', 'output': 'apt_key:\n  url: https://mariadb.org/mariadb_release_signing_key.asc\n  state: present\nwhen: (use_proxy is not defined) or (not use_proxy)\n', 'org_name': 'mahdi22', 'license': ''}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: ensure necessary packages are installed.', 'repo_name': 'packer_rhel', 'download_link': 'https://old-galaxy.ansible.com/buluma/packer_rhel', 'path': 'data/repos/buluma/packer_rhel/tasks/main.yml', 'download_count': '747', 'output': 'ansible.builtin.yum:\n  name:\n  - wget\n  - perl\n  - cpp\n  - gcc\n  - make\n  - bzip2\n  - kernel-headers\n  - kernel-devel\n  - libselinux-python\n  - elfutils-libelf-devel\n  - cifs-utils\n  state: present\n', 'org_name': 'buluma', 'license': 'Apache-2.0-Short,Apache-2.0'}
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<FOR DEBUGGING PURPOSES ONLY!>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
{'input': 'name: Debian/Ubuntu Family | Install unzip if it is currently not in installed state', 'repo_name': 'packer', 'download_link': 'https://old-galaxy.ansible.com/darkwizard242/packer', 'path': 'data/repos/darkwizard242/packer/tasks/install_debian.yml', 'download_count': '4445', 'output': 'ansible.builtin.apt:\n  name: unzip\n  state: present\n  force_apt_get: true\n  update_cache: true\n', 'org_name': 'darkwizard242', 'license': 'MIT'}  0%|          | 0/400 [00:00<?, ?it/s]loading configuration file config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/config.json
Model config GPTBigCodeConfig {
  "_name_or_path": "bigcode/starcoderbase-1b",
  "activation_function": "gelu_pytorch_tanh",
  "architectures": [
    "GPTBigCodeForCausalLM"
  ],
  "attention_softmax_in_fp32": true,
  "attn_pdrop": 0.1,
  "bos_token_id": 0,
  "embd_pdrop": 0.1,
  "eos_token_id": 0,
  "inference_runner": 0,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "max_batch_size": null,
  "max_sequence_length": null,
  "model_type": "gpt_bigcode",
  "multi_query": true,
  "n_embd": 2048,
  "n_head": 16,
  "n_inner": 8192,
  "n_layer": 24,
  "n_positions": 8192,
  "pad_key_length": true,
  "pre_allocate_kv_cache": false,
  "resid_pdrop": 0.1,
  "scale_attention_softmax_in_fp32": true,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "torch_dtype": "float32",
  "transformers_version": "4.40.0.dev0",
  "use_cache": true,
  "validate_runner_input": true,
  "vocab_size": 49152
}
  0%|          | 1/400 [00:00<01:05,  6.06it/s]
 72%|  | 287/400 [00:00<00:00, 1330.03it/s]
100%|| 400/400 [00:00<00:00, 1310.43it/s]
The character to token ratio of the dataset is: 3.18
Loading the model
/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
loading configuration file config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/config.json
Model config GPTBigCodeConfig {
  "_name_or_path": "bigcode/starcoderbase-1b",
  "activation_function": "gelu_pytorch_tanh",
  "architectures": [
    "GPTBigCodeForCausalLM"
  ],
  "attention_softmax_in_fp32": true,
  "attn_pdrop": 0.1,
  "bos_token_id": 0,
  "embd_pdrop": 0.1,
  "eos_token_id": 0,
  "inference_runner": 0,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "max_batch_size": null,
  "max_sequence_length": null,
  "model_type": "gpt_bigcode",
  "multi_query": true,
  "n_embd": 2048,
  "n_head": 16,
  "n_inner": 8192,
  "n_layer": 24,
  "n_positions": 8192,
  "pad_key_length": true,
  "pre_allocate_kv_cache": false,
  "resid_pdrop": 0.1,
  "scale_attention_softmax_in_fp32": true,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "torch_dtype": "float32",
  "transformers_version": "4.40.0.dev0",
  "use_cache": true,
  "validate_runner_input": true,
  "vocab_size": 49152
}The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.
Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.
Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.
Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.
loading weights file model.safetensors from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/model.safetensors
loading weights file model.safetensors from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/model.safetensors
loading weights file model.safetensors from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/model.safetensors
loading weights file model.safetensors from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/model.safetensors
Instantiating GPTBigCodeForCausalLM model under default dtype torch.float16.
Instantiating GPTBigCodeForCausalLM model under default dtype torch.float16.
Instantiating GPTBigCodeForCausalLM model under default dtype torch.float16.
Instantiating GPTBigCodeForCausalLM model under default dtype torch.float16.
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}All model checkpoint weights were used when initializing GPTBigCodeForCausalLM.All the weights of GPTBigCodeForCausalLM were initialized from the model checkpoint at bigcode/starcoderbase-1b.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTBigCodeForCausalLM for predictions without further training.
loading configuration file generation_config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}Started the causalLM Thing
All model checkpoint weights were used when initializing GPTBigCodeForCausalLM.All the weights of GPTBigCodeForCausalLM were initialized from the model checkpoint at bigcode/starcoderbase-1b.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTBigCodeForCausalLM for predictions without further training.
All model checkpoint weights were used when initializing GPTBigCodeForCausalLM.All the weights of GPTBigCodeForCausalLM were initialized from the model checkpoint at bigcode/starcoderbase-1b.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTBigCodeForCausalLM for predictions without further training.
All model checkpoint weights were used when initializing GPTBigCodeForCausalLM.All the weights of GPTBigCodeForCausalLM were initialized from the model checkpoint at bigcode/starcoderbase-1b.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTBigCodeForCausalLM for predictions without further training.
loading configuration file generation_config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}loading configuration file generation_config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}loading configuration file generation_config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}Prepared model for kbit training
lora config done
Started the causalLM Thing
Started the causalLM Thing
Started the causalLM Thing
Prepared model for kbit training
lora config done
Prepared model for kbit training
lora config done
Prepared model for kbit training
lora config done
peft model prepared
peft model prepared
trainable params: 7176192 || all params: 1144383488 || trainable%: 0.6270793029827428
model printed
Starting main loop
PyTorch: setting up devices
trainable params: 7176192 || all params: 1144383488 || trainable%: 0.6270793029827428
model printed
Starting main loop
peft model prepared
PyTorch: setting up devices
peft model prepared
trainable params: 7176192 || all params: 1144383488 || trainable%: 0.6270793029827428
model printed
Starting main loop
PyTorch: setting up devices
trainable params: 7176192 || all params: 1144383488 || trainable%: 0.6270793029827428
model printed
Starting main loop
PyTorch: setting up devices
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Training...
Training...
Training...
max_steps is given, it will override any value given in num_train_epochs
Using auto half precision backend
Training...
Currently training with a batch size of: 1
***** Running training *****
  Num examples = 208,000
  Num Epochs = 9,223,372,036,854,775,807
  Instantaneous batch size per device = 1
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 16
  Total optimization steps = 3,250
  Number of trainable parameters = 7,176,192
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: hetarthvader. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /projects/bbvz/choprahetarth/wandb/run-20240407_222041-t489twg9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run FinalRuns-/projects/bbvz/choprahetarth/new_experiments
wandb:  View project at https://wandb.ai/hetarthvader/huggingface
wandb:  View run at https://wandb.ai/hetarthvader/huggingface/runs/t489twg9  0%|          | 0/3250 [00:00<?, ?it/s]{'loss': 2.1916, 'grad_norm': 0.8410884141921997, 'learning_rate': 5e-05, 'epoch': 0.0}  0%|          | 1/3250 [00:20<18:40:33, 20.69s/it]
                                                     0%|          | 1/3250 [00:20<18:40:33, 20.69s/it]{'loss': 2.2542, 'grad_norm': 0.8725332617759705, 'learning_rate': 0.0001, 'epoch': 0.0}  0%|          | 2/3250 [00:31<13:14:26, 14.68s/it]
                                                     0%|          | 2/3250 [00:31<13:14:26, 14.68s/it]{'loss': 2.1011, 'grad_norm': 0.7942493557929993, 'learning_rate': 9.999997661121407e-05, 'epoch': 0.0}  0%|          | 3/3250 [00:41<11:26:35, 12.69s/it]
                                                     0%|          | 3/3250 [00:41<11:26:35, 12.69s/it]{'loss': 2.1255, 'grad_norm': 0.8150621652603149, 'learning_rate': 9.999990644487813e-05, 'epoch': 0.0}  0%|          | 4/3250 [00:51<10:36:47, 11.77s/it]
                                                     0%|          | 4/3250 [00:51<10:36:47, 11.77s/it]{'loss': 2.0258, 'grad_norm': 0.7754359245300293, 'learning_rate': 9.999978950105786e-05, 'epoch': 0.0}  0%|          | 5/3250 [01:02<10:08:47, 11.26s/it]
                                                     0%|          | 5/3250 [01:02<10:08:47, 11.26s/it]{'loss': 2.0623, 'grad_norm': 0.6602579951286316, 'learning_rate': 9.999962577986265e-05, 'epoch': 0.0}  0%|          | 6/3250 [01:12<9:53:31, 10.98s/it] 
                                                    0%|          | 6/3250 [01:12<9:53:31, 10.98s/it]{'loss': 2.2422, 'grad_norm': 0.5101683735847473, 'learning_rate': 9.999941528144567e-05, 'epoch': 0.0}  0%|          | 7/3250 [01:22<9:40:35, 10.74s/it]
                                                    0%|          | 7/3250 [01:22<9:40:35, 10.74s/it]{'loss': 1.9009, 'grad_norm': 0.47655269503593445, 'learning_rate': 9.999915800600383e-05, 'epoch': 0.0}  0%|          | 8/3250 [01:33<9:33:25, 10.61s/it]
                                                    0%|          | 8/3250 [01:33<9:33:25, 10.61s/it]{'loss': 1.8591, 'grad_norm': 0.4523610770702362, 'learning_rate': 9.999885395377788e-05, 'epoch': 0.0}  0%|          | 9/3250 [01:43<9:28:16, 10.52s/it]
                                                    0%|          | 9/3250 [01:43<9:28:16, 10.52s/it]{'loss': 1.8723, 'grad_norm': 0.49746641516685486, 'learning_rate': 9.999850312505221e-05, 'epoch': 0.0}  0%|          | 10/3250 [01:53<9:23:53, 10.44s/it]
                                                     0%|          | 10/3250 [01:53<9:23:53, 10.44s/it]***** Running Evaluation *****
  Num examples: Unknown
  Batch size = 1
{'eval_loss': 1.7189223766326904, 'eval_runtime': 7.4532, 'eval_samples_per_second': 1.61, 'eval_steps_per_second': 0.403, 'epoch': 0.0}                                                     0%|          | 10/3250 [02:01<9:23:53, 10.44s/it]{'loss': 1.8035, 'grad_norm': 0.5270861387252808, 'learning_rate': 9.99981055201551e-05, 'epoch': 0.0}  0%|          | 11/3250 [02:11<11:25:02, 12.69s/it]
                                                      0%|          | 11/3250 [02:11<11:25:02, 12.69s/it]{'loss': 1.7004, 'grad_norm': 0.5171800255775452, 'learning_rate': 9.999766113945847e-05, 'epoch': 0.0}  0%|          | 12/3250 [02:21<10:45:44, 11.97s/it]
                                                      0%|          | 12/3250 [02:21<10:45:44, 11.97s/it]{'loss': 1.7997, 'grad_norm': 0.5609749555587769, 'learning_rate': 9.999716998337812e-05, 'epoch': 0.0}  0%|          | 13/3250 [02:32<10:19:52, 11.49s/it]
                                                      0%|          | 13/3250 [02:32<10:19:52, 11.49s/it]{'loss': 1.7658, 'grad_norm': 0.5825135707855225, 'learning_rate': 9.99966320523735e-05, 'epoch': 0.0}  0%|          | 14/3250 [02:42<10:00:42, 11.14s/it]
                                                      0%|          | 14/3250 [02:42<10:00:42, 11.14s/it]{'loss': 1.6856, 'grad_norm': 0.5542322993278503, 'learning_rate': 9.999604734694792e-05, 'epoch': 0.0}  0%|          | 15/3250 [02:52<9:46:41, 10.88s/it] 
                                                     0%|          | 15/3250 [02:52<9:46:41, 10.88s/it]{'loss': 1.6631, 'grad_norm': 0.585016131401062, 'learning_rate': 9.999541586764836e-05, 'epoch': 0.0}  0%|          | 16/3250 [03:03<9:38:45, 10.74s/it]
                                                     0%|          | 16/3250 [03:03<9:38:45, 10.74s/it]{'loss': 1.5536, 'grad_norm': 0.5539486408233643, 'learning_rate': 9.999473761506563e-05, 'epoch': 0.01}  1%|          | 17/3250 [03:15<10:00:07, 11.14s/it]
                                                      1%|          | 17/3250 [03:15<10:00:07, 11.14s/it]{'loss': 1.5668, 'grad_norm': 0.5352708697319031, 'learning_rate': 9.999401258983425e-05, 'epoch': 0.01}  1%|          | 18/3250 [03:25<9:45:45, 10.87s/it] 
                                                     1%|          | 18/3250 [03:25<9:45:45, 10.87s/it]{'loss': 1.5664, 'grad_norm': 0.46747130155563354, 'learning_rate': 9.999324079263253e-05, 'epoch': 0.01}  1%|          | 19/3250 [03:35<9:37:02, 10.72s/it]
                                                     1%|          | 19/3250 [03:35<9:37:02, 10.72s/it]{'loss': 1.5443, 'grad_norm': 0.3845086395740509, 'learning_rate': 9.999242222418252e-05, 'epoch': 0.01}  1%|          | 20/3250 [03:46<9:29:36, 10.58s/it]
                                                     1%|          | 20/3250 [03:46<9:29:36, 10.58s/it]***** Running Evaluation *****
  Num examples: Unknown
  Batch size = 1
{'eval_loss': 1.4577425718307495, 'eval_runtime': 7.1219, 'eval_samples_per_second': 1.685, 'eval_steps_per_second': 0.421, 'epoch': 0.01}                                                     1%|          | 20/3250 [03:53<9:29:36, 10.58s/it]{'loss': 1.5142, 'grad_norm': 0.35915350914001465, 'learning_rate': 9.999155688525004e-05, 'epoch': 0.01}  1%|          | 21/3250 [04:03<11:19:28, 12.63s/it]
                                                      1%|          | 21/3250 [04:03<11:19:28, 12.63s/it]{'loss': 1.5515, 'grad_norm': 0.39076587557792664, 'learning_rate': 9.999064477664466e-05, 'epoch': 0.01}  1%|          | 22/3250 [04:14<10:42:54, 11.95s/it]
                                                      1%|          | 22/3250 [04:14<10:42:54, 11.95s/it]{'loss': 1.4985, 'grad_norm': 0.37557101249694824, 'learning_rate': 9.998968589921969e-05, 'epoch': 0.01}  1%|          | 23/3250 [04:24<10:16:22, 11.46s/it]
                                                      1%|          | 23/3250 [04:24<10:16:22, 11.46s/it]{'loss': 1.484, 'grad_norm': 0.33473676443099976, 'learning_rate': 9.998868025387223e-05, 'epoch': 0.01}  1%|          | 24/3250 [04:34<9:57:32, 11.11s/it] 
                                                     1%|          | 24/3250 [04:34<9:57:32, 11.11s/it]{'loss': 1.4825, 'grad_norm': 0.34814634919166565, 'learning_rate': 9.998762784154308e-05, 'epoch': 0.01}  1%|          | 25/3250 [04:45<9:45:21, 10.89s/it]
                                                     1%|          | 25/3250 [04:45<9:45:21, 10.89s/it]{'loss': 1.4589, 'grad_norm': 0.30306920409202576, 'learning_rate': 9.998652866321687e-05, 'epoch': 0.01}  1%|          | 26/3250 [04:55<9:36:05, 10.72s/it]
                                                     1%|          | 26/3250 [04:55<9:36:05, 10.72s/it]{'loss': 1.4493, 'grad_norm': 0.28038904070854187, 'learning_rate': 9.99853827199219e-05, 'epoch': 0.01}  1%|          | 27/3250 [05:05<9:28:49, 10.59s/it]
                                                     1%|          | 27/3250 [05:05<9:28:49, 10.59s/it]{'loss': 1.461, 'grad_norm': 0.27147936820983887, 'learning_rate': 9.998419001273029e-05, 'epoch': 0.01}  1%|          | 28/3250 [05:15<9:24:35, 10.51s/it]
                                                     1%|          | 28/3250 [05:15<9:24:35, 10.51s/it]{'loss': 1.4969, 'grad_norm': 0.2699621319770813, 'learning_rate': 9.998295054275786e-05, 'epoch': 0.01}  1%|          | 29/3250 [05:26<9:22:20, 10.48s/it]
                                                     1%|          | 29/3250 [05:26<9:22:20, 10.48s/it]{'loss': 1.4938, 'grad_norm': 0.2643088102340698, 'learning_rate': 9.99816643111642e-05, 'epoch': 0.01}  1%|          | 30/3250 [05:36<9:20:20, 10.44s/it]
                                                     1%|          | 30/3250 [05:36<9:20:20, 10.44s/it]***** Running Evaluation *****
  Num examples: Unknown
  Batch size = 1
{'eval_loss': 1.3815295696258545, 'eval_runtime': 7.1677, 'eval_samples_per_second': 1.674, 'eval_steps_per_second': 0.419, 'epoch': 0.01}                                                     1%|          | 30/3250 [05:43<9:20:20, 10.44s/it]{'loss': 1.4337, 'grad_norm': 0.24808835983276367, 'learning_rate': 9.998033131915266e-05, 'epoch': 0.01}  1%|          | 31/3250 [05:54<11:13:45, 12.56s/it]
                                                      1%|          | 31/3250 [05:54<11:13:45, 12.56s/it]{'loss': 1.4379, 'grad_norm': 0.24167849123477936, 'learning_rate': 9.997895156797028e-05, 'epoch': 0.01}  1%|          | 32/3250 [06:04<10:37:41, 11.89s/it]
                                                      1%|          | 32/3250 [06:04<10:37:41, 11.89s/it]{'loss': 1.4145, 'grad_norm': 0.24041232466697693, 'learning_rate': 9.997752505890794e-05, 'epoch': 0.01}  1%|          | 33/3250 [06:16<10:39:17, 11.92s/it]
                                                      1%|          | 33/3250 [06:16<10:39:17, 11.92s/it]{'loss': 1.3881, 'grad_norm': 0.2280442714691162, 'learning_rate': 9.997605179330019e-05, 'epoch': 0.01}  1%|          | 34/3250 [06:26<10:13:16, 11.44s/it]
                                                      1%|          | 34/3250 [06:26<10:13:16, 11.44s/it]{'loss': 1.4114, 'grad_norm': 0.2284574657678604, 'learning_rate': 9.997453177252534e-05, 'epoch': 0.01}  1%|          | 35/3250 [06:37<9:55:02, 11.10s/it] 
                                                     1%|          | 35/3250 [06:37<9:55:02, 11.10s/it]{'loss': 1.4431, 'grad_norm': 0.22585327923297882, 'learning_rate': 9.997296499800545e-05, 'epoch': 0.01}  1%|          | 36/3250 [06:47<9:42:08, 10.87s/it]
                                                     1%|          | 36/3250 [06:47<9:42:08, 10.87s/it]{'loss': 1.8456, 'grad_norm': 0.21028058230876923, 'learning_rate': 9.997135147120633e-05, 'epoch': 0.01}  1%|          | 37/3250 [06:57<9:33:06, 10.70s/it]
                                                     1%|          | 37/3250 [06:57<9:33:06, 10.70s/it]{'loss': 1.3029, 'grad_norm': 0.2220139056444168, 'learning_rate': 9.99696911936375e-05, 'epoch': 0.01}  1%|          | 38/3250 [07:08<9:27:48, 10.61s/it]
                                                     1%|          | 38/3250 [07:08<9:27:48, 10.61s/it]{'loss': 1.3752, 'grad_norm': 0.2087239921092987, 'learning_rate': 9.996798416685228e-05, 'epoch': 0.01}  1%|          | 39/3250 [07:18<9:22:28, 10.51s/it]
                                                     1%|          | 39/3250 [07:18<9:22:28, 10.51s/it]{'loss': 1.4479, 'grad_norm': 0.21982835233211517, 'learning_rate': 9.99662303924476e-05, 'epoch': 0.01}  1%|          | 40/3250 [07:28<9:19:14, 10.45s/it]
                                                     1%|          | 40/3250 [07:28<9:19:14, 10.45s/it]***** Running Evaluation *****
  Num examples: Unknown
  Batch size = 1
{'eval_loss': 1.334436297416687, 'eval_runtime': 7.1894, 'eval_samples_per_second': 1.669, 'eval_steps_per_second': 0.417, 'epoch': 0.01}                                                     1%|          | 40/3250 [07:35<9:19:14, 10.45s/it]{'loss': 1.3917, 'grad_norm': 0.21361687779426575, 'learning_rate': 9.996442987206428e-05, 'epoch': 0.01}  1%|         | 41/3250 [07:46<11:11:59, 12.56s/it]
                                                      1%|         | 41/3250 [07:46<11:11:59, 12.56s/it]{'loss': 1.3705, 'grad_norm': 0.21475516259670258, 'learning_rate': 9.996258260738676e-05, 'epoch': 0.01}  1%|         | 42/3250 [07:56<10:36:00, 11.90s/it]
                                                      1%|         | 42/3250 [07:56<10:36:00, 11.90s/it]{'loss': 1.3945, 'grad_norm': 0.22896409034729004, 'learning_rate': 9.996068860014325e-05, 'epoch': 0.01}  1%|         | 43/3250 [08:06<10:10:19, 11.42s/it]
                                                      1%|         | 43/3250 [08:06<10:10:19, 11.42s/it]{'loss': 1.4132, 'grad_norm': 0.21818433701992035, 'learning_rate': 9.995874785210573e-05, 'epoch': 0.01}  1%|         | 44/3250 [08:17<9:51:32, 11.07s/it] 
                                                     1%|         | 44/3250 [08:17<9:51:32, 11.07s/it]{'loss': 1.4197, 'grad_norm': 0.20545929670333862, 'learning_rate': 9.995676036508982e-05, 'epoch': 0.01}  1%|         | 45/3250 [08:27<9:39:08, 10.84s/it]
                                                     1%|         | 45/3250 [08:27<9:39:08, 10.84s/it]{'loss': 1.3641, 'grad_norm': 0.2098705768585205, 'learning_rate': 9.995472614095495e-05, 'epoch': 0.01}  1%|         | 46/3250 [08:37<9:30:47, 10.69s/it]
                                                     1%|         | 46/3250 [08:37<9:30:47, 10.69s/it]{'loss': 1.3013, 'grad_norm': 0.2073412984609604, 'learning_rate': 9.995264518160425e-05, 'epoch': 0.01}  1%|         | 47/3250 [08:48<9:24:39, 10.58s/it]
                                                     1%|         | 47/3250 [08:48<9:24:39, 10.58s/it]{'loss': 1.3587, 'grad_norm': 0.207855686545372, 'learning_rate': 9.995051748898453e-05, 'epoch': 0.01}  1%|         | 48/3250 [08:58<9:21:42, 10.53s/it]
                                                     1%|         | 48/3250 [08:58<9:21:42, 10.53s/it]{'loss': 1.3302, 'grad_norm': 0.20793338119983673, 'learning_rate': 9.994834306508638e-05, 'epoch': 0.02}  2%|         | 49/3250 [09:08<9:17:46, 10.46s/it]
                                                     2%|         | 49/3250 [09:08<9:17:46, 10.46s/it]{'loss': 1.3608, 'grad_norm': 0.20978115499019623, 'learning_rate': 9.994612191194406e-05, 'epoch': 0.02}  2%|         | 50/3250 [09:20<9:44:08, 10.95s/it]
                                                     2%|         | 50/3250 [09:20<9:44:08, 10.95s/it]***** Running Evaluation *****
  Num examples: Unknown
  Batch size = 1
{'eval_loss': 1.2974671125411987, 'eval_runtime': 7.1872, 'eval_samples_per_second': 1.67, 'eval_steps_per_second': 0.417, 'epoch': 0.02}                                                     2%|         | 50/3250 [09:28<9:44:08, 10.95s/it]Saving model checkpoint to /projects/bbvz/choprahetarth/new_experiments/checkpoint-50
I AM HERE AND I AM SAVING THE MODEL
the checkpoint model will be saved in  /projects/bbvz/choprahetarth/new_experiments/checkpoint-50
I AM HERE AND I AM SAVING THE MODEL
the checkpoint model will be saved in  /projects/bbvz/choprahetarth/new_experiments/checkpoint-50
I AM HERE AND I AM SAVING THE MODEL
the checkpoint model will be saved in  /projects/bbvz/choprahetarth/new_experiments/checkpoint-50
Repo card metadata block was not found. Setting CardData to empty.
loading configuration file config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/config.json
Model config GPTBigCodeConfig {
  "_name_or_path": "/fsx/bigcode/experiments/pretraining/conversions/starcoder-1b",
  "activation_function": "gelu_pytorch_tanh",
  "architectures": [
    "GPTBigCodeForCausalLM"
  ],
  "attention_softmax_in_fp32": true,
  "attn_pdrop": 0.1,
  "bos_token_id": 0,
  "embd_pdrop": 0.1,
  "eos_token_id": 0,
  "inference_runner": 0,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "max_batch_size": null,
  "max_sequence_length": null,
  "model_type": "gpt_bigcode",
  "multi_query": true,
  "n_embd": 2048,
  "n_head": 16,
  "n_inner": 8192,
  "n_layer": 24,
  "n_positions": 8192,
  "pad_key_length": true,
  "pre_allocate_kv_cache": false,
  "resid_pdrop": 0.1,
  "scale_attention_softmax_in_fp32": true,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "torch_dtype": "float32",
  "transformers_version": "4.40.0.dev0",
  "use_cache": true,
  "validate_runner_input": true,
  "vocab_size": 49152
}the pytorch model path is /projects/bbvz/choprahetarth/new_experiments/checkpoint-50/pytorch_model.bin
the pytorch model path is /projects/bbvz/choprahetarth/new_experiments/checkpoint-50/pytorch_model.bin
the pytorch model path is /projects/bbvz/choprahetarth/new_experiments/checkpoint-50/pytorch_model.bin
I AM HERE AND I AM SAVING THE MODEL
the checkpoint model will be saved in  /projects/bbvz/choprahetarth/new_experiments/checkpoint-50
loading configuration file config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/config.json
Model config GPTBigCodeConfig {
  "_name_or_path": "/fsx/bigcode/experiments/pretraining/conversions/starcoder-1b",
  "activation_function": "gelu_pytorch_tanh",
  "architectures": [
    "GPTBigCodeForCausalLM"
  ],
  "attention_softmax_in_fp32": true,
  "attn_pdrop": 0.1,
  "bos_token_id": 0,
  "embd_pdrop": 0.1,
  "eos_token_id": 0,
  "inference_runner": 0,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "max_batch_size": null,
  "max_sequence_length": null,
  "model_type": "gpt_bigcode",
  "multi_query": true,
  "n_embd": 2048,
  "n_head": 16,
  "n_inner": 8192,
  "n_layer": 24,
  "n_positions": 8192,
  "pad_key_length": true,
  "pre_allocate_kv_cache": false,
  "resid_pdrop": 0.1,
  "scale_attention_softmax_in_fp32": true,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "torch_dtype": "float32",
  "transformers_version": "4.40.0.dev0",
  "use_cache": true,
  "validate_runner_input": true,
  "vocab_size": 49152
}the pytorch model path is /projects/bbvz/choprahetarth/new_experiments/checkpoint-50/pytorch_model.bin
{'loss': 1.3308, 'grad_norm': 0.215807244181633, 'learning_rate': 9.99438540316356e-05, 'epoch': 0.02}  2%|         | 51/3250 [16:19<118:16:01, 133.09s/it]
                                                        2%|         | 51/3250 [16:19<118:16:01, 133.09s/it]{'loss': 1.3436, 'grad_norm': 0.2095092386007309, 'learning_rate': 9.99415394262827e-05, 'epoch': 0.02}  2%|         | 52/3250 [16:29<85:30:31, 96.26s/it]  
                                                      2%|         | 52/3250 [16:29<85:30:31, 96.26s/it]{'loss': 1.3398, 'grad_norm': 0.218829944729805, 'learning_rate': 9.993917809805081e-05, 'epoch': 0.02}  2%|         | 53/3250 [16:39<62:36:36, 70.50s/it]
                                                      2%|         | 53/3250 [16:39<62:36:36, 70.50s/it]{'loss': 1.3378, 'grad_norm': 0.19916361570358276, 'learning_rate': 9.993677004914907e-05, 'epoch': 0.02}  2%|         | 54/3250 [16:50<46:33:12, 52.44s/it]
                                                      2%|         | 54/3250 [16:50<46:33:12, 52.44s/it]{'loss': 1.3278, 'grad_norm': 0.211306631565094, 'learning_rate': 9.993431528183032e-05, 'epoch': 0.02}  2%|         | 55/3250 [17:00<35:18:54, 39.79s/it]
                                                      2%|         | 55/3250 [17:00<35:18:54, 39.79s/it]{'loss': 1.312, 'grad_norm': 0.21077683568000793, 'learning_rate': 9.993181379839113e-05, 'epoch': 0.02}  2%|         | 56/3250 [17:10<27:29:51, 30.99s/it]
                                                      2%|         | 56/3250 [17:10<27:29:51, 30.99s/it]{'loss': 1.304, 'grad_norm': 0.20560681819915771, 'learning_rate': 9.992926560117176e-05, 'epoch': 0.02}  2%|         | 57/3250 [17:21<22:01:14, 24.83s/it]
                                                      2%|         | 57/3250 [17:21<22:01:14, 24.83s/it]{'loss': 1.3514, 'grad_norm': 0.22075290977954865, 'learning_rate': 9.992667069255619e-05, 'epoch': 0.02}  2%|         | 58/3250 [17:31<18:09:09, 20.47s/it]
                                                      2%|         | 58/3250 [17:31<18:09:09, 20.47s/it]{'loss': 1.3117, 'grad_norm': 0.21358244121074677, 'learning_rate': 9.992402907497209e-05, 'epoch': 0.02}  2%|         | 59/3250 [17:41<15:27:10, 17.43s/it]
                                                      2%|         | 59/3250 [17:41<15:27:10, 17.43s/it]{'loss': 1.3913, 'grad_norm': 0.22090429067611694, 'learning_rate': 9.992134075089084e-05, 'epoch': 0.02}  2%|         | 60/3250 [17:52<13:33:59, 15.31s/it]
                                                      2%|         | 60/3250 [17:52<13:33:59, 15.31s/it]***** Running Evaluation *****
  Num examples: Unknown
  Batch size = 1
{'eval_loss': 1.267006754875183, 'eval_runtime': 7.2597, 'eval_samples_per_second': 1.653, 'eval_steps_per_second': 0.413, 'epoch': 0.02}                                                      2%|         | 60/3250 [17:59<13:33:59, 15.31s/it]{'loss': 1.3088, 'grad_norm': 0.22419075667858124, 'learning_rate': 9.991860572282747e-05, 'epoch': 0.02}  2%|         | 61/3250 [18:09<14:10:00, 15.99s/it]
                                                      2%|         | 61/3250 [18:09<14:10:00, 15.99s/it]{'loss': 1.3376, 'grad_norm': 0.21727700531482697, 'learning_rate': 9.991582399334076e-05, 'epoch': 0.02}  2%|         | 62/3250 [18:20<12:38:32, 14.28s/it]
                                                      2%|         | 62/3250 [18:20<12:38:32, 14.28s/it]{'loss': 1.312, 'grad_norm': 0.21435095369815826, 'learning_rate': 9.991299556503318e-05, 'epoch': 0.02}  2%|         | 63/3250 [18:30<11:36:11, 13.11s/it]
                                                      2%|         | 63/3250 [18:30<11:36:11, 13.11s/it]{'loss': 1.2842, 'grad_norm': 0.21230308711528778, 'learning_rate': 9.991012044055084e-05, 'epoch': 0.02}  2%|         | 64/3250 [18:40<10:50:50, 12.26s/it]
                                                      2%|         | 64/3250 [18:40<10:50:50, 12.26s/it]{'loss': 1.2902, 'grad_norm': 0.22536396980285645, 'learning_rate': 9.990719862258358e-05, 'epoch': 0.02}  2%|         | 65/3250 [18:51<10:20:49, 11.70s/it]
                                                      2%|         | 65/3250 [18:51<10:20:49, 11.70s/it]{'loss': 1.3033, 'grad_norm': 0.23071789741516113, 'learning_rate': 9.990423011386489e-05, 'epoch': 0.02}  2%|         | 66/3250 [19:02<10:23:02, 11.74s/it]
                                                      2%|         | 66/3250 [19:02<10:23:02, 11.74s/it]{'loss': 1.2962, 'grad_norm': 0.22883784770965576, 'learning_rate': 9.990121491717201e-05, 'epoch': 0.02}  2%|         | 67/3250 [19:13<10:00:29, 11.32s/it]
                                                      2%|         | 67/3250 [19:13<10:00:29, 11.32s/it]{'loss': 1.6607, 'grad_norm': 0.21359966695308685, 'learning_rate': 9.989815303532577e-05, 'epoch': 0.02}  2%|         | 68/3250 [19:23<9:43:39, 11.01s/it] 
                                                     2%|         | 68/3250 [19:23<9:43:39, 11.01s/it]{'loss': 1.2758, 'grad_norm': 0.23897187411785126, 'learning_rate': 9.989504447119073e-05, 'epoch': 0.02}  2%|         | 69/3250 [19:33<9:32:10, 10.79s/it]
                                                     2%|         | 69/3250 [19:33<9:32:10, 10.79s/it]{'loss': 1.3299, 'grad_norm': 0.23508363962173462, 'learning_rate': 9.989188922767512e-05, 'epoch': 0.02}  2%|         | 70/3250 [19:44<9:24:02, 10.64s/it]
                                                     2%|         | 70/3250 [19:44<9:24:02, 10.64s/it]***** Running Evaluation *****
  Num examples: Unknown
  Batch size = 1
{'eval_loss': 1.2399606704711914, 'eval_runtime': 7.2586, 'eval_samples_per_second': 1.653, 'eval_steps_per_second': 0.413, 'epoch': 0.02}                                                     2%|         | 70/3250 [19:51<9:24:02, 10.64s/it]{'loss': 1.2935, 'grad_norm': 0.22689588367938995, 'learning_rate': 9.988868730773082e-05, 'epoch': 0.02}  2%|         | 71/3250 [20:01<11:15:07, 12.74s/it]
                                                      2%|         | 71/3250 [20:01<11:15:07, 12.74s/it]{'loss': 1.2785, 'grad_norm': 0.22363121807575226, 'learning_rate': 9.98854387143534e-05, 'epoch': 0.02}  2%|         | 72/3250 [20:12<10:35:36, 12.00s/it]
                                                      2%|         | 72/3250 [20:12<10:35:36, 12.00s/it]{'loss': 1.2651, 'grad_norm': 0.2296431064605713, 'learning_rate': 9.988214345058209e-05, 'epoch': 0.02}  2%|         | 73/3250 [20:22<10:09:12, 11.51s/it]
                                                      2%|         | 73/3250 [20:22<10:09:12, 11.51s/it]{'loss': 1.3312, 'grad_norm': 0.2353195995092392, 'learning_rate': 9.987880151949976e-05, 'epoch': 0.02}  2%|         | 74/3250 [20:32<9:50:12, 11.15s/it] 
                                                     2%|         | 74/3250 [20:32<9:50:12, 11.15s/it]{'loss': 1.3223, 'grad_norm': 0.2360580563545227, 'learning_rate': 9.987541292423298e-05, 'epoch': 0.02}  2%|         | 75/3250 [20:43<9:36:36, 10.90s/it]
                                                     2%|         | 75/3250 [20:43<9:36:36, 10.90s/it]{'loss': 1.2727, 'grad_norm': 0.23627153038978577, 'learning_rate': 9.987197766795193e-05, 'epoch': 0.02}  2%|         | 76/3250 [20:53<9:27:27, 10.73s/it]
                                                     2%|         | 76/3250 [20:53<9:27:27, 10.73s/it]{'loss': 1.2459, 'grad_norm': 0.21929162740707397, 'learning_rate': 9.986849575387049e-05, 'epoch': 0.02}  2%|         | 77/3250 [21:03<9:19:58, 10.59s/it]
                                                     2%|         | 77/3250 [21:03<9:19:58, 10.59s/it]{'loss': 1.2587, 'grad_norm': 0.22633734345436096, 'learning_rate': 9.986496718524616e-05, 'epoch': 0.02}  2%|         | 78/3250 [21:14<9:16:00, 10.52s/it]
                                                     2%|         | 78/3250 [21:14<9:16:00, 10.52s/it]{'loss': 1.2574, 'grad_norm': 0.2357085645198822, 'learning_rate': 9.986139196538011e-05, 'epoch': 0.02}  2%|         | 79/3250 [21:24<9:12:37, 10.46s/it]
                                                     2%|         | 79/3250 [21:24<9:12:37, 10.46s/it]{'loss': 1.2656, 'grad_norm': 0.24477247893810272, 'learning_rate': 9.985777009761713e-05, 'epoch': 0.02}  2%|         | 80/3250 [21:34<9:10:10, 10.41s/it]
                                                     2%|         | 80/3250 [21:34<9:10:10, 10.41s/it]***** Running Evaluation *****
  Num examples: Unknown
  Batch size = 1
{'eval_loss': 1.2181166410446167, 'eval_runtime': 7.0925, 'eval_samples_per_second': 1.692, 'eval_steps_per_second': 0.423, 'epoch': 0.02}                                                     2%|         | 80/3250 [21:41<9:10:10, 10.41s/it]{'loss': 1.2543, 'grad_norm': 0.23900733888149261, 'learning_rate': 9.985410158534567e-05, 'epoch': 0.02}  2%|         | 81/3250 [21:51<11:00:05, 12.50s/it]
                                                      2%|         | 81/3250 [21:51<11:00:05, 12.50s/it]{'loss': 1.2507, 'grad_norm': 0.236544668674469, 'learning_rate': 9.98503864319978e-05, 'epoch': 0.03}  3%|         | 82/3250 [22:04<11:03:51, 12.57s/it]
                                                      3%|         | 82/3250 [22:04<11:03:51, 12.57s/it]{'loss': 1.2483, 'grad_norm': 0.24598921835422516, 'learning_rate': 9.984662464104926e-05, 'epoch': 0.03}  3%|         | 83/3250 [22:15<10:27:32, 11.89s/it]
                                                      3%|         | 83/3250 [22:15<10:27:32, 11.89s/it]{'loss': 1.2547, 'grad_norm': 0.22411420941352844, 'learning_rate': 9.984281621601938e-05, 'epoch': 0.03}  3%|         | 84/3250 [22:25<10:02:07, 11.41s/it]
                                                      3%|         | 84/3250 [22:25<10:02:07, 11.41s/it]{'loss': 1.2539, 'grad_norm': 0.2545796036720276, 'learning_rate': 9.983896116047113e-05, 'epoch': 0.03}  3%|         | 85/3250 [22:35<9:43:14, 11.06s/it] 
                                                     3%|         | 85/3250 [22:35<9:43:14, 11.06s/it]{'loss': 1.2245, 'grad_norm': 0.23364880681037903, 'learning_rate': 9.983505947801115e-05, 'epoch': 0.03}  3%|         | 86/3250 [22:45<9:32:51, 10.86s/it]
                                                     3%|         | 86/3250 [22:45<9:32:51, 10.86s/it]{'loss': 1.2648, 'grad_norm': 0.2364492565393448, 'learning_rate': 9.983111117228961e-05, 'epoch': 0.03}  3%|         | 87/3250 [22:56<9:23:36, 10.69s/it]
                                                     3%|         | 87/3250 [22:56<9:23:36, 10.69s/it]{'loss': 1.2422, 'grad_norm': 0.2532540261745453, 'learning_rate': 9.982711624700041e-05, 'epoch': 0.03}  3%|         | 88/3250 [23:06<9:17:44, 10.58s/it]
                                                     3%|         | 88/3250 [23:06<9:17:44, 10.58s/it]{'loss': 1.2614, 'grad_norm': 0.24103859066963196, 'learning_rate': 9.982307470588098e-05, 'epoch': 0.03}  3%|         | 89/3250 [23:16<9:12:56, 10.50s/it]
                                                     3%|         | 89/3250 [23:16<9:12:56, 10.50s/it]{'loss': 1.3169, 'grad_norm': 0.2535165250301361, 'learning_rate': 9.981898655271235e-05, 'epoch': 0.03}  3%|         | 90/3250 [23:27<9:09:41, 10.44s/it]
                                                     3%|         | 90/3250 [23:27<9:09:41, 10.44s/it]***** Running Evaluation *****
  Num examples: Unknown
  Batch size = 1
{'eval_loss': 1.19922935962677, 'eval_runtime': 7.1953, 'eval_samples_per_second': 1.668, 'eval_steps_per_second': 0.417, 'epoch': 0.03}                                                     3%|         | 90/3250 [23:34<9:09:41, 10.44s/it]{'loss': 1.2661, 'grad_norm': 0.25468096137046814, 'learning_rate': 9.981485179131929e-05, 'epoch': 0.03}  3%|         | 91/3250 [23:44<11:00:48, 12.55s/it]
                                                      3%|         | 91/3250 [23:44<11:00:48, 12.55s/it]{'loss': 1.2463, 'grad_norm': 0.25250738859176636, 'learning_rate': 9.981067042557e-05, 'epoch': 0.03}  3%|         | 92/3250 [23:54<10:24:41, 11.87s/it]
                                                      3%|         | 92/3250 [23:54<10:24:41, 11.87s/it]{'loss': 1.2714, 'grad_norm': 0.2530086934566498, 'learning_rate': 9.980644245937639e-05, 'epoch': 0.03}  3%|         | 93/3250 [24:05<10:00:17, 11.41s/it]
                                                      3%|         | 93/3250 [24:05<10:00:17, 11.41s/it]{'loss': 1.1869, 'grad_norm': 0.25444450974464417, 'learning_rate': 9.980216789669395e-05, 'epoch': 0.03}  3%|         | 94/3250 [24:15<9:41:49, 11.06s/it] 
                                                     3%|         | 94/3250 [24:15<9:41:49, 11.06s/it]{'loss': 1.2517, 'grad_norm': 0.24752072989940643, 'learning_rate': 9.979784674152175e-05, 'epoch': 0.03}  3%|         | 95/3250 [24:25<9:29:05, 10.82s/it]
                                                     3%|         | 95/3250 [24:25<9:29:05, 10.82s/it]{'loss': 1.2068, 'grad_norm': 0.2516157329082489, 'learning_rate': 9.979347899790246e-05, 'epoch': 0.03}  3%|         | 96/3250 [24:36<9:21:02, 10.67s/it]
                                                     3%|         | 96/3250 [24:36<9:21:02, 10.67s/it]{'loss': 1.2694, 'grad_norm': 0.24047039449214935, 'learning_rate': 9.978906466992229e-05, 'epoch': 0.03}  3%|         | 97/3250 [24:46<9:15:49, 10.58s/it]
                                                     3%|         | 97/3250 [24:46<9:15:49, 10.58s/it]{'loss': 1.6196, 'grad_norm': 0.2537512183189392, 'learning_rate': 9.978460376171112e-05, 'epoch': 0.03}  3%|         | 98/3250 [24:56<9:10:45, 10.48s/it]
                                                     3%|         | 98/3250 [24:56<9:10:45, 10.48s/it]{'loss': 1.2046, 'grad_norm': 0.2700938880443573, 'learning_rate': 9.978009627744234e-05, 'epoch': 0.03}  3%|         | 99/3250 [25:08<9:35:39, 10.96s/it]
                                                     3%|         | 99/3250 [25:08<9:35:39, 10.96s/it]{'loss': 1.2393, 'grad_norm': 0.2615945637226105, 'learning_rate': 9.977554222133292e-05, 'epoch': 0.03}  3%|         | 100/3250 [25:19<9:26:06, 10.78s/it]
                                                      3%|         | 100/3250 [25:19<9:26:06, 10.78s/it]***** Running Evaluation *****
  Num examples: Unknown
  Batch size = 1
{'eval_loss': 1.1844165325164795, 'eval_runtime': 7.138, 'eval_samples_per_second': 1.681, 'eval_steps_per_second': 0.42, 'epoch': 0.03}                                                      3%|         | 100/3250 [25:26<9:26:06, 10.78s/it]Saving model checkpoint to /projects/bbvz/choprahetarth/new_experiments/checkpoint-100
I AM HERE AND I AM SAVING THE MODEL
the checkpoint model will be saved in  /projects/bbvz/choprahetarth/new_experiments/checkpoint-100
I AM HERE AND I AM SAVING THE MODEL
the checkpoint model will be saved in  /projects/bbvz/choprahetarth/new_experiments/checkpoint-100
I AM HERE AND I AM SAVING THE MODEL
the checkpoint model will be saved in  /projects/bbvz/choprahetarth/new_experiments/checkpoint-100
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
loading configuration file config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/config.json
Model config GPTBigCodeConfig {
  "_name_or_path": "/fsx/bigcode/experiments/pretraining/conversions/starcoder-1b",
  "activation_function": "gelu_pytorch_tanh",
  "architectures": [
    "GPTBigCodeForCausalLM"
  ],
  "attention_softmax_in_fp32": true,
  "attn_pdrop": 0.1,
  "bos_token_id": 0,
  "embd_pdrop": 0.1,
  "eos_token_id": 0,
  "inference_runner": 0,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "max_batch_size": null,
  "max_sequence_length": null,
  "model_type": "gpt_bigcode",
  "multi_query": true,
  "n_embd": 2048,
  "n_head": 16,
  "n_inner": 8192,
  "n_layer": 24,
  "n_positions": 8192,
  "pad_key_length": true,
  "pre_allocate_kv_cache": false,
  "resid_pdrop": 0.1,
  "scale_attention_softmax_in_fp32": true,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "torch_dtype": "float32",
  "transformers_version": "4.40.0.dev0",
  "use_cache": true,
  "validate_runner_input": true,
  "vocab_size": 49152
}the pytorch model path is /projects/bbvz/choprahetarth/new_experiments/checkpoint-100/pytorch_model.bin
the pytorch model path is /projects/bbvz/choprahetarth/new_experiments/checkpoint-100/pytorch_model.bin
the pytorch model path is /projects/bbvz/choprahetarth/new_experiments/checkpoint-100/pytorch_model.bin
I AM HERE AND I AM SAVING THE MODEL
the checkpoint model will be saved in  /projects/bbvz/choprahetarth/new_experiments/checkpoint-100
loading configuration file config.json from cache at /projects/bbvz/choprahetarth/hub/models--bigcode--starcoderbase-1b/snapshots/182f0165fdf8da9c9935901eec65c94337f01c11/config.json
Model config GPTBigCodeConfig {
  "_name_or_path": "/fsx/bigcode/experiments/pretraining/conversions/starcoder-1b",
  "activation_function": "gelu_pytorch_tanh",
  "architectures": [
    "GPTBigCodeForCausalLM"
  ],
  "attention_softmax_in_fp32": true,
  "attn_pdrop": 0.1,
  "bos_token_id": 0,
  "embd_pdrop": 0.1,
  "eos_token_id": 0,
  "inference_runner": 0,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "max_batch_size": null,
  "max_sequence_length": null,
  "model_type": "gpt_bigcode",
  "multi_query": true,
  "n_embd": 2048,
  "n_head": 16,
  "n_inner": 8192,
  "n_layer": 24,
  "n_positions": 8192,
  "pad_key_length": true,
  "pre_allocate_kv_cache": false,
  "resid_pdrop": 0.1,
  "scale_attention_softmax_in_fp32": true,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "torch_dtype": "float32",
  "transformers_version": "4.40.0.dev0",
  "use_cache": true,
  "validate_runner_input": true,
  "vocab_size": 49152
}[rank3]:[E ProcessGroupNCCL.cpp:523] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=7634, OpType=BROADCAST, NumelIn=2048, NumelOut=2048, Timeout(ms)=600000) ran for 600125 milliseconds before timing out.
[rank2]:[E ProcessGroupNCCL.cpp:523] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=7634, OpType=BROADCAST, NumelIn=2048, NumelOut=2048, Timeout(ms)=600000) ran for 600039 milliseconds before timing out.
[rank1]:[E ProcessGroupNCCL.cpp:523] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=7634, OpType=BROADCAST, NumelIn=2048, NumelOut=2048, Timeout(ms)=600000) ran for 600990 milliseconds before timing out.
[rank2]:[E ProcessGroupNCCL.cpp:537] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank2]:[E ProcessGroupNCCL.cpp:543] To avoid data inconsistency, we are taking the entire process down.
[rank2]:[E ProcessGroupNCCL.cpp:1182] [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=7634, OpType=BROADCAST, NumelIn=2048, NumelOut=2048, Timeout(ms)=600000) ran for 600039 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7ff8857fad87 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7ff8869a26e6 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7ff8869a5c3d in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7ff8869a6839 in /u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdbbf4 (0x7ff8d6bafbf4 in /u/choprahetarth/.conda/envs/hetarth_py10/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x81ca (0x7ff8e8cfc1ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x7ff8e81dee73 in /lib64/libc.so.6)[2024-04-07 23:00:34,615] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3755579 closing signal SIGTERM
[2024-04-07 23:00:34,615] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3755580 closing signal SIGTERM
[2024-04-07 23:00:34,615] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3755582 closing signal SIGTERM
[2024-04-07 23:01:04,615] torch.distributed.elastic.multiprocessing.api: [WARNING] Unable to shutdown process 3755579 via Signals.SIGTERM, forcefully exiting via Signals.SIGKILL
[2024-04-07 23:05:32,297] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -6) local_rank: 2 (pid: 3755581) of binary: /u/choprahetarth/.conda/envs/hetarth_py10/bin/python3
Traceback (most recent call last):
  File "/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/u/choprahetarth/.conda/envs/hetarth_py10/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
finetune/custom_fine_tune.py FAILED
--------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-07_23:00:34
  host      : gpub070.delta.ncsa.illinois.edu
  rank      : 2 (local_rank: 2)
  exitcode  : -6 (pid: 3755581)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 3755581
========================================================
srun: error: gpub070: task 0: Exited with exit code 1
